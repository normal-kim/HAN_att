{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_han import *\n",
    "from data_loader_han import * \n",
    "from data_process_han import *\n",
    "from test_module_han import *\n",
    "from train_han import * \n",
    "from utils_han import *\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:\n",
      " 1    2700\n",
      "0    2700\n",
      "Name: polarity, dtype: int64\n",
      "test_size:\n",
      " 1    300\n",
      "0    300\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with open('df_in.pkl', 'rb') as file:\n",
    "    df_in1 = pickle.load(file)\n",
    "\n",
    "df_train, df_test = train_test_split(df_in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "\n",
    "params_dict['embed_dim'] = 100\n",
    "params_dict['word_gru_h_dim'] = 100\n",
    "params_dict['sent_gru_h_dim'] = 100\n",
    "params_dict['word_gru_n_layers'] = 2\n",
    "params_dict['sent_gru_n_layers'] = 2\n",
    "params_dict['word_att_dim'] = 200\n",
    "params_dict['sent_att_dim'] = 200\n",
    "params_dict['dropgru_s'] = 0.2 \n",
    "params_dict['dropgru_w'] = 0.2\n",
    "params_dict['dropval'] = 0.2\n",
    "\n",
    "params_dict['tan_a'] = 0.5\n",
    "params_dict['alpha_de'] = 0.5\n",
    "params_dict['beta_de'] = 1\n",
    "\n",
    "params_dict['batch_size'] = 30\n",
    "\n",
    "params_dict['fc1'] = 100\n",
    "params_dict['fc2'] = 20\n",
    "params_dict['drop_fc'] = 0.3\n",
    "params_dict['fc'] = create_fc(params_dict['fc1'],\n",
    "                              params_dict['fc2'], params_dict['drop_fc'])\n",
    "params_dict['epochs'] = 20 \n",
    "params_dict['output_size'] = 1 \n",
    "params_dict['lr'] = 7e-5\n",
    "params_dict['print_every'] = 39\n",
    "params_dict['clip_val'] = 1.5\n",
    "params_dict['attention'] = 'de_attention'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### experiment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_lst = [100, 160, 200] \n",
    "fc2_lst = [15, 30] \n",
    "dropval_lst = [0.1, 0.4] \n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. test softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 15, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6530902328399512 hm:0.6227720714204404\n",
      " ==> New best value..loss:0.6020962584477204 hm:0.6443930417603478\n",
      " ==> New best value..loss:0.5817971670856843 hm:0.686620683120366\n",
      " ==> New best value..loss:0.5616801340992634 hm:0.7238453454825321\n",
      " ==> New best value..loss:0.527322432742669 hm:0.7410731513415807\n",
      " ==> New best value..loss:0.5136758776811453 hm:0.7493519427678029\n",
      " ==> New best value..loss:0.5115373449829909 hm:0.7503448309772163\n",
      " ==> New best value..loss:0.5090382832747239 hm:0.7581169743620831\n",
      " ==> New best value..loss:0.5048960854227726 hm:0.758835774603993\n",
      " ==> New best value..loss:0.5006178892575778 hm:0.7623508917853247\n",
      " ==> New best value..loss:0.497215021115083 hm:0.7699001636393895\n",
      " ==> New best value..loss:0.49542754143476486 hm:0.7757505071431694\n",
      " ==> New best value..loss:0.4917902969397031 hm:0.7763141104459602\n",
      " ==> New best value..loss:0.48585974597013915 hm:0.7839721283757819\n",
      " ==> New best value..loss:0.47764853216134584 hm:0.7889305666081012\n",
      " ==> New best value..loss:0.47516478311557037 hm:0.7917907413198971\n",
      " ==> New best value..loss:0.47307599163972414 hm:0.7944827876262222\n",
      " ==> New best value..loss:0.4679173050591579 hm:0.7950983312678159\n",
      " ==> New best value..loss:0.46464550351867306 hm:0.7975177567023827\n",
      " ==> New best value..loss:0.46253771134294 hm:0.7980328663590207\n",
      " ==> New best value..loss:0.46215555473015857 hm:0.8045534032382515\n",
      " ==> New best value..loss:0.45388537588027805 hm:0.8045751750285037\n",
      " ==> New best value..loss:0.4531269703920071 hm:0.8078736822101084\n",
      " ==> New best value..loss:0.45302952711398786 hm:0.8109967050151697\n",
      " ==> New best value..loss:0.44860841906987703 hm:0.8118951337857206\n",
      " ==> New best value..loss:0.44403217560969865 hm:0.8130535807694608\n",
      " ==> New best value..loss:0.4423110310274821 hm:0.8153888633268502\n",
      " ==> New best value..loss:0.43958097982865113 hm:0.8169441128813055\n",
      " ==> New best value..loss:0.43819293924249136 hm:0.8187987532963173\n",
      " ==> New best value..loss:0.433171942543525 hm:0.8230104266218479\n",
      " ==> New best value..loss:0.4278889178083493 hm:0.8249835489117693\n",
      " ==> New best value..loss:0.4241836088208052 hm:0.8261576982318446\n",
      " ==> New best value..loss:0.42154354172257275 hm:0.8265883787006003\n",
      " ==> New best value..loss:0.42008915772804845 hm:0.8274956341217786\n",
      " ==> New best value..loss:0.41325929818245083 hm:0.8334361971413019\n",
      "BEST SCORE:  0.8334361971413019\n",
      "TRAINING TOOK:  247  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 15, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6711747312545776 hm:0.607538881641584\n",
      " ==> New best value..loss:0.60448237657547 hm:0.622534120184119\n",
      " ==> New best value..loss:0.5950011587142945 hm:0.6617041582068329\n",
      " ==> New best value..loss:0.5696035933494568 hm:0.7051230909585381\n",
      " ==> New best value..loss:0.5405776625871659 hm:0.7338633546184716\n",
      " ==> New best value..loss:0.5140693747997284 hm:0.7535947423597759\n",
      " ==> New best value..loss:0.5047105276584625 hm:0.7606469859769408\n",
      " ==> New best value..loss:0.5029634493589401 hm:0.7638446014519412\n",
      " ==> New best value..loss:0.5015419697761536 hm:0.7639598289505435\n",
      " ==> New best value..loss:0.5010914307832718 hm:0.766444945045118\n",
      " ==> New best value..loss:0.49760957300662995 hm:0.7678380316454375\n",
      " ==> New best value..loss:0.4920413565635681 hm:0.7709763070558628\n",
      " ==> New best value..loss:0.4896338367462158 hm:0.7752454037214104\n",
      " ==> New best value..loss:0.4842421120405197 hm:0.7767248936048297\n",
      " ==> New best value..loss:0.48199560821056364 hm:0.7798415660901226\n",
      " ==> New best value..loss:0.4804618537425995 hm:0.7814082215325308\n",
      " ==> New best value..loss:0.4773321640491486 hm:0.7830372678459816\n",
      " ==> New best value..loss:0.4762910455465317 hm:0.7894287819970875\n",
      " ==> New best value..loss:0.4711977380514145 hm:0.7929869685010041\n",
      " ==> New best value..loss:0.4630597084760666 hm:0.7956944798973494\n",
      " ==> New best value..loss:0.4567536735534668 hm:0.7975701194409087\n",
      " ==> New best value..loss:0.453687464594841 hm:0.8028781066851084\n",
      " ==> New best value..loss:0.4517297506332397 hm:0.8033736844908371\n",
      " ==> New best value..loss:0.4505982321500778 hm:0.8040434077053644\n",
      " ==> New best value..loss:0.4487926205992699 hm:0.8084560621687611\n",
      " ==> New best value..loss:0.447177195250988 hm:0.8105525991717925\n",
      " ==> New best value..loss:0.44583495080471036 hm:0.8117069472728892\n",
      " ==> New best value..loss:0.44330700397491457 hm:0.8128583353260287\n",
      " ==> New best value..loss:0.4361823868751526 hm:0.816571152594739\n",
      " ==> New best value..loss:0.4291958612203598 hm:0.8170399234631726\n",
      " ==> New best value..loss:0.42485842525959017 hm:0.8192800274842758\n",
      " ==> New best value..loss:0.4208002233505249 hm:0.821618650944227\n",
      " ==> New best value..loss:0.4200391983985901 hm:0.8241938486476866\n",
      " ==> New best value..loss:0.4167052894830704 hm:0.8284827971497928\n",
      " ==> New best value..loss:0.4114947259426117 hm:0.8340889801277585\n",
      " ==> New best value..loss:0.40790814489126204 hm:0.8355338365617694\n",
      " ==> New best value..loss:0.40627396702766416 hm:0.8362031437512721\n",
      " ==> New best value..loss:0.40100536406040194 hm:0.8387763255944699\n",
      " ==> New best value..loss:0.3940056198835373 hm:0.842203308800474\n",
      " ==> New best value..loss:0.3931815859675407 hm:0.8445976296301475\n",
      " ==> New best value..loss:0.3930922544002533 hm:0.8484333383512555\n",
      " ==> New best value..loss:0.3904800871014595 hm:0.8491151284964374\n",
      " ==> New best value..loss:0.3887613296508789 hm:0.851319606919436\n",
      " ==> New best value..loss:0.37967191487550733 hm:0.8518946857339256\n",
      "BEST SCORE:  0.8518946857339256\n",
      "TRAINING TOOK:  238  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 30, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6872625022518392 hm:0.5443411948730205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5984147051159217 hm:0.6286383719033645\n",
      " ==> New best value..loss:0.5819223985380056 hm:0.6662856242285715\n",
      " ==> New best value..loss:0.5636214924101927 hm:0.7041059744715393\n",
      " ==> New best value..loss:0.5372360804859473 hm:0.7357826286828542\n",
      " ==> New best value..loss:0.5159118631664588 hm:0.743821276105155\n",
      " ==> New best value..loss:0.5117243114782839 hm:0.7454186972592636\n",
      " ==> New best value..loss:0.5113284052634726 hm:0.7505504423986272\n",
      " ==> New best value..loss:0.5048616668399499 hm:0.7523027551535798\n",
      " ==> New best value..loss:0.5021822470791486 hm:0.7552095358356561\n",
      " ==> New best value..loss:0.49838875811927175 hm:0.7589289318197187\n",
      " ==> New best value..loss:0.49616597136672663 hm:0.7607873947526075\n",
      " ==> New best value..loss:0.49054928580108953 hm:0.7663750397641844\n",
      " ==> New best value..loss:0.48933585140169883 hm:0.767085689084916\n",
      " ==> New best value..loss:0.48612719166035556 hm:0.7693666537579242\n",
      " ==> New best value..loss:0.48270112701824736 hm:0.7756652492148308\n",
      " ==> New best value..loss:0.4817809091538799 hm:0.7825221630362186\n",
      " ==> New best value..loss:0.47717353640770427 hm:0.7842019767232253\n",
      " ==> New best value..loss:0.4767644180327046 hm:0.7879291935994981\n",
      " ==> New best value..loss:0.47286352880147037 hm:0.7884405837172145\n",
      " ==> New best value..loss:0.47088832879553033 hm:0.7901285157410876\n",
      " ==> New best value..loss:0.4688846627060248 hm:0.7911812465157854\n",
      " ==> New best value..loss:0.466193752325311 hm:0.7950697404680993\n",
      " ==> New best value..loss:0.46126276619580325 hm:0.8014501273039727\n",
      " ==> New best value..loss:0.4560542514129561 hm:0.8022227772251516\n",
      " ==> New best value..loss:0.45526260320021184 hm:0.8028129995880182\n",
      " ==> New best value..loss:0.4526676493031638 hm:0.8046809701276463\n",
      " ==> New best value..loss:0.4498227445446715 hm:0.807259985204937\n",
      " ==> New best value..loss:0.44732904495025166 hm:0.8075454752327225\n",
      " ==> New best value..loss:0.4440697261265346 hm:0.808298843234024\n",
      " ==> New best value..loss:0.4434948767326316 hm:0.8093210242892365\n",
      " ==> New best value..loss:0.4415575940998233 hm:0.8110350142042181\n",
      " ==> New best value..loss:0.44099242103343106 hm:0.8130520177580605\n",
      " ==> New best value..loss:0.43398125135168736 hm:0.8164251682395511\n",
      " ==> New best value..loss:0.431091843210921 hm:0.8182384212393422\n",
      " ==> New best value..loss:0.4282988008795952 hm:0.824202187910015\n",
      " ==> New best value..loss:0.4239511669290309 hm:0.8261210099513216\n",
      " ==> New best value..loss:0.4206165452392734 hm:0.8275100982571306\n",
      " ==> New best value..loss:0.4197337524015076 hm:0.8306717714876048\n",
      " ==> New best value..loss:0.41514841695221105 hm:0.8320101681214241\n",
      " ==> New best value..loss:0.41322605129407375 hm:0.8322127605202203\n",
      " ==> New best value..loss:0.4129694651584236 hm:0.8349955503389969\n",
      " ==> New best value..loss:0.41036516154298974 hm:0.8374606884206167\n",
      " ==> New best value..loss:0.40514727697080494 hm:0.838779054312253\n",
      "BEST SCORE:  0.838779054312253\n",
      "TRAINING TOOK:  238  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6536764001846314 hm:0.6226940044001273\n",
      " ==> New best value..loss:0.610439623594284 hm:0.6519635783185921\n",
      " ==> New best value..loss:0.5885831129550934 hm:0.6908270776405128\n",
      " ==> New best value..loss:0.5701806843280792 hm:0.7143746243362734\n",
      " ==> New best value..loss:0.541705162525177 hm:0.734641178403218\n",
      " ==> New best value..loss:0.5302845954895019 hm:0.7460691394366402\n",
      " ==> New best value..loss:0.52595141351223 hm:0.7533084354195579\n",
      " ==> New best value..loss:0.518120943903923 hm:0.7570223890992585\n",
      " ==> New best value..loss:0.5179432243108749 hm:0.7594093338722552\n",
      " ==> New best value..loss:0.5145047849416733 hm:0.7624307254900274\n",
      " ==> New best value..loss:0.51064348757267 hm:0.7660951085769732\n",
      " ==> New best value..loss:0.50932059943676 hm:0.7713861662798243\n",
      " ==> New best value..loss:0.5011953485012054 hm:0.773346200847649\n",
      " ==> New best value..loss:0.4980292326211929 hm:0.7770405270512082\n",
      " ==> New best value..loss:0.49623075664043426 hm:0.7791374932971938\n",
      " ==> New best value..loss:0.4904199653863907 hm:0.7804911945676551\n",
      " ==> New best value..loss:0.48653790950775144 hm:0.7841855158245921\n",
      " ==> New best value..loss:0.482848202586174 hm:0.7902342418027746\n",
      " ==> New best value..loss:0.48271948754787447 hm:0.7954006110902508\n",
      " ==> New best value..loss:0.4729129135608673 hm:0.8007513050222637\n",
      " ==> New best value..loss:0.47148468136787414 hm:0.8008233280816346\n",
      " ==> New best value..loss:0.46943255007267 hm:0.8034124963644209\n",
      " ==> New best value..loss:0.46589938044548035 hm:0.8064411543864608\n",
      " ==> New best value..loss:0.46232068419456485 hm:0.8093998698010453\n",
      " ==> New best value..loss:0.4565715992450714 hm:0.810405918714526\n",
      " ==> New best value..loss:0.4542849859595299 hm:0.8112567312712796\n",
      " ==> New best value..loss:0.44929572343826296 hm:0.8141102158135708\n",
      " ==> New best value..loss:0.4470836618542671 hm:0.8152425478607166\n",
      " ==> New best value..loss:0.44526762545108794 hm:0.8183297271462735\n",
      " ==> New best value..loss:0.4426878452301025 hm:0.8190301438860751\n",
      " ==> New best value..loss:0.4365627981722355 hm:0.8201247161098472\n",
      " ==> New best value..loss:0.4350918561220169 hm:0.8242274814901277\n",
      " ==> New best value..loss:0.43084401190280913 hm:0.8258682900191295\n",
      " ==> New best value..loss:0.4307168421149254 hm:0.8261186759271899\n",
      " ==> New best value..loss:0.42955916047096254 hm:0.8292695021151001\n",
      " ==> New best value..loss:0.42815147250890734 hm:0.8300899742338395\n",
      " ==> New best value..loss:0.4248669824004173 hm:0.8314622478060295\n",
      " ==> New best value..loss:0.4216514030098915 hm:0.8333015889638489\n",
      " ==> New best value..loss:0.41784871637821197 hm:0.8405029020017147\n",
      " ==> New best value..loss:0.41401483714580534 hm:0.8465873569816784\n",
      " ==> New best value..loss:0.40332880437374113 hm:0.8475809406020819\n",
      "BEST SCORE:  0.8475809406020819\n",
      "TRAINING TOOK:  242  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 15, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6550415579010459 hm:0.6111825630824302\n",
      " ==> New best value..loss:0.6083035580083436 hm:0.6360441622936477\n",
      " ==> New best value..loss:0.5872871776421865 hm:0.6884988456994006\n",
      " ==> New best value..loss:0.5595342061098885 hm:0.7229196659699275\n",
      " ==> New best value..loss:0.5200911719425052 hm:0.756779721708488\n",
      " ==> New best value..loss:0.512239374366461 hm:0.7610124341190955\n",
      " ==> New best value..loss:0.5067964096864065 hm:0.7640649755799652\n",
      " ==> New best value..loss:0.4998207063067193 hm:0.7668238361891911\n",
      " ==> New best value..loss:0.4956738551457723 hm:0.7732913118221271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.48568378944022983 hm:0.7765300640809573\n",
      " ==> New best value..loss:0.48552821488941417 hm:0.7813593242924094\n",
      " ==> New best value..loss:0.48326856014775293 hm:0.7827215670859899\n",
      " ==> New best value..loss:0.4798414309819539 hm:0.7892028900970851\n",
      " ==> New best value..loss:0.4769187809205523 hm:0.7896886103916986\n",
      " ==> New best value..loss:0.4686136730745727 hm:0.791618641223685\n",
      " ==> New best value..loss:0.4642084316880095 hm:0.7946813102026751\n",
      " ==> New best value..loss:0.4621594594974144 hm:0.8016286601762537\n",
      " ==> New best value..loss:0.45866869652972503 hm:0.8025085009145473\n",
      " ==> New best value..loss:0.4561673075545068 hm:0.805725276919759\n",
      " ==> New best value..loss:0.44582407147276637 hm:0.8086549088553687\n",
      " ==> New best value..loss:0.4454115766520594 hm:0.8086644415980321\n",
      " ==> New best value..loss:0.44106509288152057 hm:0.8116431096957152\n",
      " ==> New best value..loss:0.4405072050936082 hm:0.8150890234094936\n",
      " ==> New best value..loss:0.4306328921925788 hm:0.8198466201643856\n",
      " ==> New best value..loss:0.4292560476882785 hm:0.8242851789155733\n",
      " ==> New best value..loss:0.42323944264767216 hm:0.8259985819165381\n",
      " ==> New best value..loss:0.41469747120258854 hm:0.8279562658005373\n",
      " ==> New best value..loss:0.40991517667676886 hm:0.8311256629248623\n",
      " ==> New best value..loss:0.40860577599675046 hm:0.8363005614397458\n",
      " ==> New best value..loss:0.4038521562721215 hm:0.8366094289428077\n",
      " ==> New best value..loss:0.3983372014527227 hm:0.8378957538835093\n",
      " ==> New best value..loss:0.3969145601286608 hm:0.8406299421475987\n",
      " ==> New best value..loss:0.3962608412200329 hm:0.841669010107562\n",
      " ==> New best value..loss:0.3934095685972887 hm:0.8437522154717118\n",
      " ==> New best value..loss:0.3871753589779723 hm:0.8438556881092697\n",
      "BEST SCORE:  0.8438556881092697\n",
      "TRAINING TOOK:  237  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 15, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6480992114543915 hm:0.622371237028165\n",
      " ==> New best value..loss:0.612699259519577 hm:0.6511013895732083\n",
      " ==> New best value..loss:0.5863311111927032 hm:0.6960078162131695\n",
      " ==> New best value..loss:0.5574065572023392 hm:0.7247028390735432\n",
      " ==> New best value..loss:0.5351092237234115 hm:0.7462675177974964\n",
      " ==> New best value..loss:0.5335481894016266 hm:0.7485950198645326\n",
      " ==> New best value..loss:0.5217798632383347 hm:0.7590172185240536\n",
      " ==> New best value..loss:0.5198928582668304 hm:0.7627249178058896\n",
      " ==> New best value..loss:0.5156230163574219 hm:0.7656774048945928\n",
      " ==> New best value..loss:0.5053130251169204 hm:0.7678107675948377\n",
      " ==> New best value..loss:0.501202175617218 hm:0.7766671528781608\n",
      " ==> New best value..loss:0.49357733249664304 hm:0.782377133225368\n",
      " ==> New best value..loss:0.49195988416671754 hm:0.7842487855898399\n",
      " ==> New best value..loss:0.48636712789535524 hm:0.7885535983201979\n",
      " ==> New best value..loss:0.47845384657382967 hm:0.794986318999523\n",
      " ==> New best value..loss:0.46765393316745757 hm:0.7997358923600463\n",
      " ==> New best value..loss:0.46089833170175554 hm:0.8007316719116819\n",
      " ==> New best value..loss:0.4606237933039665 hm:0.8052020699243749\n",
      " ==> New best value..loss:0.4579494398832321 hm:0.807248950486703\n",
      " ==> New best value..loss:0.45216918230056763 hm:0.8112520741868507\n",
      " ==> New best value..loss:0.4518143022060394 hm:0.8157455902752134\n",
      " ==> New best value..loss:0.4462032741308212 hm:0.8175013400182782\n",
      " ==> New best value..loss:0.44487117558717726 hm:0.8189706977720249\n",
      " ==> New best value..loss:0.44063944011926653 hm:0.8196338367910079\n",
      " ==> New best value..loss:0.4332344219088554 hm:0.8239640586576009\n",
      " ==> New best value..loss:0.4315842390060425 hm:0.8289763300465973\n",
      " ==> New best value..loss:0.42832172334194185 hm:0.8300025946531828\n",
      " ==> New best value..loss:0.42659672141075133 hm:0.8339833358795534\n",
      " ==> New best value..loss:0.41796708047389985 hm:0.8349447326012988\n",
      " ==> New best value..loss:0.4149830138683319 hm:0.836631524734102\n",
      " ==> New best value..loss:0.41354025691747665 hm:0.8388853883381796\n",
      " ==> New best value..loss:0.4124399098753929 hm:0.8414221386944574\n",
      " ==> New best value..loss:0.40698223292827607 hm:0.8444583852909704\n",
      " ==> New best value..loss:0.40602168560028074 hm:0.8452329483713158\n",
      " ==> New best value..loss:0.40527040988206864 hm:0.8488119684769146\n",
      " ==> New best value..loss:0.39825514137744905 hm:0.8496619779479718\n",
      " ==> New best value..loss:0.3967507517337799 hm:0.8545251811622872\n",
      "BEST SCORE:  0.8545251811622872\n",
      "TRAINING TOOK:  237  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 30, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6603206092236089 hm:0.6087513951411104\n",
      " ==> New best value..loss:0.6151684084359337 hm:0.6311227949615515\n",
      " ==> New best value..loss:0.5998022439433079 hm:0.6722957769236092\n",
      " ==> New best value..loss:0.5763021444573122 hm:0.6980318971604309\n",
      " ==> New best value..loss:0.5538810964892892 hm:0.7214899581938687\n",
      " ==> New best value..loss:0.5526354832976472 hm:0.7266285050808374\n",
      " ==> New best value..loss:0.5495951362684661 hm:0.728471235661604\n",
      " ==> New best value..loss:0.5439560769819746 hm:0.7347538209854264\n",
      " ==> New best value..loss:0.54229869445165 hm:0.7409839718354916\n",
      " ==> New best value..loss:0.5415646702635522 hm:0.7411015160287577\n",
      " ==> New best value..loss:0.5285768719280467 hm:0.748744189934506\n",
      " ==> New best value..loss:0.5266980353523704 hm:0.7510051189770203\n",
      " ==> New best value..loss:0.5243400832017263 hm:0.7522713653119351\n",
      " ==> New best value..loss:0.5224326942481247 hm:0.7577958530619958\n",
      " ==> New best value..loss:0.5181054718354169 hm:0.7605189155139637\n",
      " ==> New best value..loss:0.5148772994677225 hm:0.7637531656970765\n",
      " ==> New best value..loss:0.5138527236732782 hm:0.765919332812626\n",
      " ==> New best value..loss:0.5126445310957292 hm:0.7703018069176298\n",
      " ==> New best value..loss:0.5080004223421508 hm:0.7724813338881207\n",
      " ==> New best value..loss:0.5062199234962463 hm:0.7750545198431632\n",
      " ==> New best value..loss:0.5026213003724229 hm:0.7779110369558345\n",
      " ==> New best value..loss:0.49730083287930954 hm:0.7795237377794367\n",
      " ==> New best value..loss:0.4931963121189791 hm:0.7828281804530124\n",
      " ==> New best value..loss:0.4898650874109829 hm:0.7851040599774071\n",
      " ==> New best value..loss:0.48570086208044316 hm:0.7872183320242706\n",
      " ==> New best value..loss:0.47976895903839784 hm:0.7898554525113921\n",
      " ==> New best value..loss:0.47483253654311686 hm:0.7948246780960845\n",
      " ==> New best value..loss:0.47361835895800125 hm:0.7950565926810071\n",
      " ==> New best value..loss:0.4715159389318204 hm:0.7986279263308051\n",
      " ==> New best value..loss:0.46531618576423794 hm:0.8022307998208282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.4642558962691064 hm:0.8022794327648388\n",
      " ==> New best value..loss:0.4635326722088982 hm:0.8036705687402622\n",
      " ==> New best value..loss:0.4602990460162069 hm:0.8039899530860304\n",
      " ==> New best value..loss:0.4573768400678448 hm:0.8098461974705686\n",
      " ==> New best value..loss:0.4560995242174934 hm:0.8115788162745384\n",
      " ==> New best value..loss:0.45049624086595047 hm:0.8119576913224581\n",
      " ==> New best value..loss:0.44793426347713844 hm:0.8128241250796763\n",
      " ==> New best value..loss:0.446470847901176 hm:0.8130612128408634\n",
      " ==> New best value..loss:0.4459822429161446 hm:0.816442979303614\n",
      " ==> New best value..loss:0.4423145420995413 hm:0.8178335505525335\n",
      " ==> New best value..loss:0.4358934713344948 hm:0.8216294141857113\n",
      " ==> New best value..loss:0.4349305156399222 hm:0.8247132280117633\n",
      " ==> New best value..loss:0.43150214646376817 hm:0.8247811011881236\n",
      " ==> New best value..loss:0.4308576242012136 hm:0.8264072660188192\n",
      " ==> New best value..loss:0.42995215046639534 hm:0.8269387316382735\n",
      " ==> New best value..loss:0.42840079232758166 hm:0.8290978534972315\n",
      " ==> New best value..loss:0.4203281154235204 hm:0.8317925713136392\n",
      "BEST SCORE:  0.8317925713136392\n",
      "TRAINING TOOK:  234  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6694060909748077 hm:0.614384017843937\n",
      " ==> New best value..loss:0.6107885992527008 hm:0.6305571577481903\n",
      " ==> New best value..loss:0.5936910825967788 hm:0.6788938556384555\n",
      " ==> New best value..loss:0.5656278139352798 hm:0.7108128702399078\n",
      " ==> New best value..loss:0.536857932806015 hm:0.744820682299345\n",
      " ==> New best value..loss:0.5334532153606415 hm:0.7478186045124469\n",
      " ==> New best value..loss:0.5249460256099701 hm:0.7519435285009519\n",
      " ==> New best value..loss:0.5231372195482255 hm:0.7552177566352167\n",
      " ==> New best value..loss:0.5192506992816925 hm:0.7618139254851422\n",
      " ==> New best value..loss:0.5154095959663391 hm:0.7633537842958286\n",
      " ==> New best value..loss:0.5133607810735703 hm:0.7648934131969307\n",
      " ==> New best value..loss:0.5118557250499726 hm:0.7688026733517727\n",
      " ==> New best value..loss:0.5105209887027741 hm:0.7715476436152026\n",
      " ==> New best value..loss:0.5050565665960312 hm:0.7758100661517641\n",
      " ==> New best value..loss:0.5006428396701813 hm:0.778577730790356\n",
      " ==> New best value..loss:0.4993640917539597 hm:0.7828183443050103\n",
      " ==> New best value..loss:0.49489302217960357 hm:0.7839021026680355\n",
      " ==> New best value..loss:0.4905474925041199 hm:0.7877763214475739\n",
      " ==> New best value..loss:0.48940700948238375 hm:0.791332848576298\n",
      " ==> New best value..loss:0.4838472682237625 hm:0.7922023690387793\n",
      " ==> New best value..loss:0.4834016621112823 hm:0.7957571386851764\n",
      " ==> New best value..loss:0.47885959208011625 hm:0.7987096187941943\n",
      " ==> New best value..loss:0.4752071177959442 hm:0.7998499306852457\n",
      " ==> New best value..loss:0.4703592509031296 hm:0.800052552011609\n",
      " ==> New best value..loss:0.468289635181427 hm:0.8002063310209909\n",
      " ==> New best value..loss:0.46810452818870546 hm:0.8018276658095005\n",
      " ==> New best value..loss:0.46358774840831757 hm:0.8049436576969187\n",
      " ==> New best value..loss:0.4590634536743164 hm:0.8086663033687848\n",
      " ==> New best value..loss:0.456954750418663 hm:0.8105180755592697\n",
      " ==> New best value..loss:0.4530485528707504 hm:0.8113949552895723\n",
      " ==> New best value..loss:0.44793997406959535 hm:0.811779364923941\n",
      " ==> New best value..loss:0.4476386672258377 hm:0.8150988043434038\n",
      " ==> New best value..loss:0.4453649967908859 hm:0.8172688685407008\n",
      " ==> New best value..loss:0.4436512812972069 hm:0.8176765734394643\n",
      " ==> New best value..loss:0.4386860990524292 hm:0.822585832244288\n",
      " ==> New best value..loss:0.4365514436364174 hm:0.8244232432869817\n",
      " ==> New best value..loss:0.43119542896747587 hm:0.8260210920376883\n",
      " ==> New best value..loss:0.4269804334640503 hm:0.8271541718558889\n",
      " ==> New best value..loss:0.42427766740322115 hm:0.8272894093138634\n",
      " ==> New best value..loss:0.42340145975351334 hm:0.829224107029007\n",
      " ==> New best value..loss:0.4216813749074936 hm:0.8338524648827376\n",
      " ==> New best value..loss:0.4167197570204735 hm:0.8352191063184259\n",
      "BEST SCORE:  0.8352191063184259\n",
      "TRAINING TOOK:  233  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 15, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6479352864564634 hm:0.6380797072729423\n",
      " ==> New best value..loss:0.6030128311877158 hm:0.6656155791587507\n",
      " ==> New best value..loss:0.5809135115614125 hm:0.7079647031463453\n",
      " ==> New best value..loss:0.5510951461745244 hm:0.7356368267351276\n",
      " ==> New best value..loss:0.5145048621822806 hm:0.7547503538298401\n",
      " ==> New best value..loss:0.5080027849066491 hm:0.7586571034333269\n",
      " ==> New best value..loss:0.505221110348608 hm:0.764434107503924\n",
      " ==> New best value..loss:0.4989301311034782 hm:0.7674338538804186\n",
      " ==> New best value..loss:0.4956909833001156 hm:0.770580358257237\n",
      " ==> New best value..loss:0.49506936704411225 hm:0.7713517330162271\n",
      " ==> New best value..loss:0.48791686518519534 hm:0.7774975112671285\n",
      " ==> New best value..loss:0.48452476485102786 hm:0.7814541091873892\n",
      " ==> New best value..loss:0.48204320143250856 hm:0.7837794574446771\n",
      " ==> New best value..loss:0.4725717820373236 hm:0.7886951440370858\n",
      " ==> New best value..loss:0.4687137188864689 hm:0.793539549509879\n",
      " ==> New best value..loss:0.4629886775624518 hm:0.7975016306394412\n",
      " ==> New best value..loss:0.45775455061127157 hm:0.8007721893512888\n",
      " ==> New best value..loss:0.4560038803839216 hm:0.8072991064703506\n",
      " ==> New best value..loss:0.4469411507541058 hm:0.8129722442873774\n",
      " ==> New best value..loss:0.43710436306747735 hm:0.8138216907088192\n",
      " ==> New best value..loss:0.43221427763209624 hm:0.818203735726978\n",
      " ==> New best value..loss:0.4264303930834228 hm:0.8218284177333198\n",
      " ==> New best value..loss:0.4233551183167626 hm:0.8232360125454861\n",
      " ==> New best value..loss:0.4199640791790158 hm:0.8293323421655757\n",
      " ==> New best value..loss:0.4179042361530603 hm:0.831814833473988\n",
      " ==> New best value..loss:0.415446389539569 hm:0.8323873682530754\n",
      " ==> New best value..loss:0.4124097292329751 hm:0.833331355471742\n",
      " ==> New best value..loss:0.4088403874752568 hm:0.834662304390978\n",
      " ==> New best value..loss:0.40650266671881957 hm:0.8353204612219978\n",
      " ==> New best value..loss:0.4026438176047568 hm:0.8358519823534741\n",
      " ==> New best value..loss:0.40113018540775075 hm:0.8397041210185906\n",
      " ==> New best value..loss:0.3995099535175398 hm:0.8399760344253814\n",
      " ==> New best value..loss:0.3930376259719624 hm:0.8410523690302907\n",
      "BEST SCORE:  0.8410523690302907\n",
      "TRAINING TOOK:  246  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 15, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.6653191074728966 hm:0.6331857666679885\n",
      " ==> New best value..loss:0.5979626203576723 hm:0.6502835762885122\n",
      " ==> New best value..loss:0.5816616769880056 hm:0.6919041882968414\n",
      " ==> New best value..loss:0.5551579693953196 hm:0.7194168625461655\n",
      " ==> New best value..loss:0.5265154764056206 hm:0.746998098854891\n",
      " ==> New best value..loss:0.5205829069018364 hm:0.7498542558653251\n",
      " ==> New best value..loss:0.520446772997578 hm:0.7529414181173378\n",
      " ==> New best value..loss:0.5148810346921285 hm:0.7586474166380037\n",
      " ==> New best value..loss:0.5070524973173937 hm:0.7686409919366916\n",
      " ==> New best value..loss:0.5033651012927294 hm:0.7688564733885238\n",
      " ==> New best value..loss:0.49973851318160695 hm:0.7710348894543323\n",
      " ==> New best value..loss:0.49730021009842557 hm:0.7744536736874784\n",
      " ==> New best value..loss:0.49062127713114023 hm:0.7773388876722247\n",
      " ==> New best value..loss:0.49027921073138714 hm:0.7791913739148519\n",
      " ==> New best value..loss:0.48987832355002564 hm:0.7802282829725516\n",
      " ==> New best value..loss:0.48211179363230866 hm:0.7853713740084612\n",
      " ==> New best value..loss:0.4815564335634311 hm:0.7859397234420972\n",
      " ==> New best value..loss:0.4773839817692836 hm:0.7930868624770728\n",
      " ==> New best value..loss:0.47518622192243737 hm:0.7930951272907211\n",
      " ==> New best value..loss:0.46977332793176174 hm:0.7958326187660174\n",
      " ==> New best value..loss:0.46640726923942566 hm:0.8001927238130117\n",
      " ==> New best value..loss:0.46374954655766487 hm:0.8017661722257305\n",
      " ==> New best value..loss:0.4596860601256291 hm:0.8018924126249635\n",
      " ==> New best value..loss:0.4590273567785819 hm:0.8037396258358114\n",
      " ==> New best value..loss:0.4530679701517026 hm:0.8091568054812234\n",
      " ==> New best value..loss:0.45293219356487197 hm:0.8112477000151743\n",
      " ==> New best value..loss:0.45120026357471943 hm:0.8134137056843698\n",
      " ==> New best value..loss:0.4502080638582508 hm:0.8136127818859689\n",
      " ==> New best value..loss:0.445050610229373 hm:0.8138943635807202\n",
      " ==> New best value..loss:0.442835308611393 hm:0.8147025549421235\n",
      " ==> New best value..loss:0.44018045626580715 hm:0.818347338924598\n",
      " ==> New best value..loss:0.43759271036833525 hm:0.8208384741782702\n",
      " ==> New best value..loss:0.4330700517942508 hm:0.8219085118646208\n",
      " ==> New best value..loss:0.4272666967784365 hm:0.8262443352425317\n",
      " ==> New best value..loss:0.42551785117636126 hm:0.8262730644117056\n",
      " ==> New best value..loss:0.4219560641795397 hm:0.8282493236965597\n",
      " ==> New best value..loss:0.4199871827537815 hm:0.829942894198714\n",
      " ==> New best value..loss:0.4194849006210764 hm:0.835010301047468\n",
      " ==> New best value..loss:0.4162514600902796 hm:0.8359079987001591\n",
      " ==> New best value..loss:0.41519855087002117 hm:0.8361090091502771\n",
      " ==> New best value..loss:0.4122801451012492 hm:0.8362323853137743\n",
      " ==> New best value..loss:0.4077433692291379 hm:0.8433562966013228\n",
      " ==> New best value..loss:0.40393687536319095 hm:0.8467650616361009\n",
      " ==> New best value..loss:0.3971572431425254 hm:0.8495039057435292\n",
      " ==> New best value..loss:0.3957460783421993 hm:0.8505626553510389\n",
      " ==> New best value..loss:0.39478133898228407 hm:0.8513019046256456\n",
      " ==> New best value..loss:0.38673877622932196 hm:0.8517273913930795\n",
      "BEST SCORE:  0.8517273913930795\n",
      "TRAINING TOOK:  237  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6519576370716095 hm:0.6148286418272109\n",
      " ==> New best value..loss:0.6022430866956711 hm:0.6414788027891885\n",
      " ==> New best value..loss:0.5838501727581025 hm:0.6854070897831034\n",
      " ==> New best value..loss:0.56159019947052 hm:0.7154690838486674\n",
      " ==> New best value..loss:0.5265266156196594 hm:0.7456613830538638\n",
      " ==> New best value..loss:0.5178415924310684 hm:0.7525203206867781\n",
      " ==> New best value..loss:0.5123444849252701 hm:0.7604835325538235\n",
      " ==> New best value..loss:0.5097519159317017 hm:0.7617258764795328\n",
      " ==> New best value..loss:0.5061511898040771 hm:0.7644022573673216\n",
      " ==> New best value..loss:0.5022624337673187 hm:0.7676638863099347\n",
      " ==> New best value..loss:0.5008952069282532 hm:0.7720329385121646\n",
      " ==> New best value..loss:0.4978009402751923 hm:0.7780096828656512\n",
      " ==> New best value..loss:0.49047301411628724 hm:0.7813320916714181\n",
      " ==> New best value..loss:0.4882111144065857 hm:0.7819569791152762\n",
      " ==> New best value..loss:0.4869398540258408 hm:0.7835412078906826\n",
      " ==> New best value..loss:0.4843272787332535 hm:0.7853462707991763\n",
      " ==> New best value..loss:0.4840764886140823 hm:0.7878455896208502\n",
      " ==> New best value..loss:0.48138897597789765 hm:0.7893940819739851\n",
      " ==> New best value..loss:0.4786223363876343 hm:0.7898988098937869\n",
      " ==> New best value..loss:0.47813898682594297 hm:0.7914222769682215\n",
      " ==> New best value..loss:0.4772568887472153 hm:0.7921025035602185\n",
      " ==> New best value..loss:0.47467020094394685 hm:0.794201667987784\n",
      " ==> New best value..loss:0.47401824057102204 hm:0.7981451191751324\n",
      " ==> New best value..loss:0.471475727558136 hm:0.7990259330041556\n",
      " ==> New best value..loss:0.46902630567550657 hm:0.801732820285712\n",
      " ==> New best value..loss:0.4654617464542389 hm:0.8024331120425037\n",
      " ==> New best value..loss:0.464789000749588 hm:0.8035722936142368\n",
      " ==> New best value..loss:0.4627667552232742 hm:0.8057623813542875\n",
      " ==> New best value..loss:0.45913102447986603 hm:0.807184778829528\n",
      " ==> New best value..loss:0.4560586988925934 hm:0.8122675507249131\n",
      " ==> New best value..loss:0.45192701160907744 hm:0.8143958406445673\n",
      " ==> New best value..loss:0.44932428896427157 hm:0.8169428662999643\n",
      " ==> New best value..loss:0.44615563333034514 hm:0.8183347013543943\n",
      " ==> New best value..loss:0.44508690118789673 hm:0.8199489923562467\n",
      " ==> New best value..loss:0.4444992834329605 hm:0.8202095198438414\n",
      " ==> New best value..loss:0.4431678760051727 hm:0.8224861416062159\n",
      " ==> New best value..loss:0.4379981908202171 hm:0.8241695456846213\n",
      " ==> New best value..loss:0.4346790510416031 hm:0.8257819248166872\n",
      " ==> New best value..loss:0.4340301150083542 hm:0.8278938438468371\n",
      " ==> New best value..loss:0.42564783096313474 hm:0.8303698852020126\n",
      " ==> New best value..loss:0.41999311149120333 hm:0.8316824003199321\n",
      " ==> New best value..loss:0.41837832778692247 hm:0.8337799333249132\n",
      " ==> New best value..loss:0.41728302001953127 hm:0.8357972699523879\n",
      " ==> New best value..loss:0.41378101021051406 hm:0.8362491492696319\n",
      " ==> New best value..loss:0.4082679370045662 hm:0.8375133858860396\n",
      " ==> New best value..loss:0.4080575558543205 hm:0.8384463238306433\n",
      " ==> New best value..loss:0.40567570596933367 hm:0.83925007899654\n",
      " ==> New best value..loss:0.40509928673505785 hm:0.8409808658604385\n",
      " ==> New best value..loss:0.4038496485352516 hm:0.8435156315910145\n",
      " ==> New best value..loss:0.40240806877613067 hm:0.8443908532874336\n",
      " ==> New best value..loss:0.4012194228172302 hm:0.8453007097557874\n",
      " ==> New best value..loss:0.39784235298633575 hm:0.8454124242217795\n",
      "BEST SCORE:  0.8454124242217795\n",
      "TRAINING TOOK:  238  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.663026967048645 hm:0.6385019009360973\n",
      " ==> New best value..loss:0.5864562112092971 hm:0.6574620294875555\n",
      " ==> New best value..loss:0.5690643799304962 hm:0.7015497758860607\n",
      " ==> New best value..loss:0.5417865389585494 hm:0.7303227023696208\n",
      " ==> New best value..loss:0.5120329761505127 hm:0.7546193694865798\n",
      " ==> New best value..loss:0.5009598562121391 hm:0.7621923293798628\n",
      " ==> New best value..loss:0.49209857404232027 hm:0.768773780588451\n",
      " ==> New best value..loss:0.49144320011138914 hm:0.772790319336704\n",
      " ==> New best value..loss:0.4873995852470398 hm:0.7758647373755305\n",
      " ==> New best value..loss:0.4858922475576401 hm:0.7761697543903279\n",
      " ==> New best value..loss:0.48338143408298495 hm:0.777695752105049\n",
      " ==> New best value..loss:0.4833384996652603 hm:0.7786603211715579\n",
      " ==> New best value..loss:0.4802502989768982 hm:0.781349501615187\n",
      " ==> New best value..loss:0.47723802506923674 hm:0.7840469831508775\n",
      " ==> New best value..loss:0.47343736946582793 hm:0.7874696964798237\n",
      " ==> New best value..loss:0.47159528017044067 hm:0.7938345123128421\n",
      " ==> New best value..loss:0.46506294548511506 hm:0.7958826635959544\n",
      " ==> New best value..loss:0.46088017642498014 hm:0.7965846682576082\n",
      " ==> New best value..loss:0.456905454993248 hm:0.8025204444347412\n",
      " ==> New best value..loss:0.45124183148145675 hm:0.8034839740566202\n",
      " ==> New best value..loss:0.44805253118276595 hm:0.8046696652644812\n",
      " ==> New best value..loss:0.4425737768411636 hm:0.8081962404242551\n",
      " ==> New best value..loss:0.4406217038631439 hm:0.8116668280355654\n",
      " ==> New best value..loss:0.4380559664964676 hm:0.8119964053313892\n",
      " ==> New best value..loss:0.43311887472867966 hm:0.8140403624707069\n",
      " ==> New best value..loss:0.43074687391519545 hm:0.8194322363274325\n",
      " ==> New best value..loss:0.4261113503575325 hm:0.8229156181028271\n",
      " ==> New best value..loss:0.42162743270397185 hm:0.8252159522506785\n",
      " ==> New best value..loss:0.41897934168577194 hm:0.8308168839265675\n",
      " ==> New best value..loss:0.4138704016804695 hm:0.8313830896028952\n",
      " ==> New best value..loss:0.411891034245491 hm:0.8324353542407433\n",
      " ==> New best value..loss:0.41067891955375674 hm:0.8330862986715597\n",
      " ==> New best value..loss:0.40872097939252855 hm:0.8338955663731783\n",
      " ==> New best value..loss:0.40536001563072205 hm:0.836852234105984\n",
      " ==> New best value..loss:0.40228470623493195 hm:0.8389850484861748\n",
      " ==> New best value..loss:0.40173170655965806 hm:0.841084574003937\n",
      " ==> New best value..loss:0.39797478944063186 hm:0.8439443474117635\n",
      " ==> New best value..loss:0.39705566883087157 hm:0.8467707040854437\n",
      "BEST SCORE:  0.8467707040854437\n",
      "TRAINING TOOK:  235  s\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'softmax'\n",
    "\n",
    "nn_softmax = []\n",
    "scores_softmax = []\n",
    "\n",
    "for fc1 in fc1_lst:\n",
    "    params_dict['fc1'] = fc1\n",
    "    \n",
    "    for fc2 in fc2_lst:\n",
    "        params_dict['fc2'] = fc2\n",
    "        \n",
    "        for dropval in dropval_lst:\n",
    "            params_dict['drop_fc'] = dropval\n",
    "            params_dict['fc'] = create_fc( params_dict['fc1'],\n",
    "                                params_dict['fc2'],params_dict['drop_fc'])\n",
    "            \n",
    "            print('='*80)\n",
    "            d_start = datetime.now() \n",
    "            best_score, classifier = do_training( df_in1, params_dict, criterion)\n",
    "            nn_softmax.append(classifier)\n",
    "            scores_softmax.append(best_score)\n",
    "            print('BEST SCORE: ', best_score)\n",
    "            print('TRAINING TOOK: ', ( datetime.now() - d_start ).seconds, ' s'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax( scores_softmax )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed_dim': 100,\n",
       " 'word_gru_h_dim': 100,\n",
       " 'sent_gru_h_dim': 100,\n",
       " 'word_gru_n_layers': 2,\n",
       " 'sent_gru_n_layers': 2,\n",
       " 'word_att_dim': 200,\n",
       " 'sent_att_dim': 200,\n",
       " 'dropgru_s': 0.2,\n",
       " 'dropgru_w': 0.2,\n",
       " 'dropval': 0.2,\n",
       " 'tan_a': 0.5,\n",
       " 'alpha_de': 0.5,\n",
       " 'beta_de': 1,\n",
       " 'batch_size': 30,\n",
       " 'fc1': 200,\n",
       " 'fc2': 30,\n",
       " 'drop_fc': 0.4,\n",
       " 'fc': Sequential(\n",
       "   (0): Dropout(p=0.4, inplace=False)\n",
       "   (1): Linear(in_features=200, out_features=200, bias=True)\n",
       "   (2): Dropout(p=0.2, inplace=False)\n",
       "   (3): Linear(in_features=200, out_features=30, bias=True)\n",
       "   (4): Dropout(p=0.2, inplace=False)\n",
       "   (5): Linear(in_features=30, out_features=1, bias=True)\n",
       "   (6): Sigmoid()\n",
       " ),\n",
       " 'epochs': 20,\n",
       " 'output_size': 1,\n",
       " 'lr': 7e-05,\n",
       " 'print_every': 39,\n",
       " 'clip_val': 1.5,\n",
       " 'attention': 'softmax'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_softmax[5].encoder.params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = 200, fc2 = 30, drop_fc = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. test tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6664791834354401 hm:0.5878378834779499\n",
      " ==> New best value..loss:0.6296174311637879 hm:0.5965293112486563\n",
      " ==> New best value..loss:0.6165251219272614 hm:0.6182575276426481\n",
      " ==> New best value..loss:0.6014027237892151 hm:0.6513705232433251\n",
      " ==> New best value..loss:0.5904790610074997 hm:0.6642190373033595\n",
      " ==> New best value..loss:0.5585851705074311 hm:0.7069198657675154\n",
      " ==> New best value..loss:0.5545915549993515 hm:0.7134826566368886\n",
      " ==> New best value..loss:0.544029415845871 hm:0.7326002075180679\n",
      " ==> New best value..loss:0.5407909959554672 hm:0.7397654157852409\n",
      " ==> New best value..loss:0.5324717307090759 hm:0.7406084765544214\n",
      " ==> New best value..loss:0.5266994464397431 hm:0.7453466187374462\n",
      " ==> New best value..loss:0.5254883432388305 hm:0.7516612048095083\n",
      " ==> New best value..loss:0.5223809540271759 hm:0.7538066949414792\n",
      " ==> New best value..loss:0.5121807760000229 hm:0.755125162722011\n",
      " ==> New best value..loss:0.5096887564659118 hm:0.7602238474877734\n",
      " ==> New best value..loss:0.508708878159523 hm:0.7604443409624504\n",
      " ==> New best value..loss:0.5071539515256882 hm:0.7613581888531916\n",
      " ==> New best value..loss:0.502832202911377 hm:0.7690190747462944\n",
      " ==> New best value..loss:0.5011054944992065 hm:0.7698350985919646\n",
      " ==> New best value..loss:0.49325754404067995 hm:0.7715284012926915\n",
      " ==> New best value..loss:0.486736536026001 hm:0.7795456479168539\n",
      " ==> New best value..loss:0.48258889496326446 hm:0.7812242556787626\n",
      " ==> New best value..loss:0.47768153369426725 hm:0.7834902064257163\n",
      " ==> New best value..loss:0.476991211771965 hm:0.7861903355581773\n",
      " ==> New best value..loss:0.47254512429237366 hm:0.78714387404978\n",
      " ==> New best value..loss:0.4720674830675125 hm:0.7890105470542547\n",
      " ==> New best value..loss:0.4686919414997101 hm:0.7907534030436503\n",
      " ==> New best value..loss:0.46346032083034516 hm:0.7919234498586346\n",
      " ==> New best value..loss:0.4621620547771454 hm:0.7936729296450448\n",
      " ==> New best value..loss:0.45791759610176086 hm:0.7964442759888454\n",
      " ==> New best value..loss:0.457869656085968 hm:0.7967386933816865\n",
      " ==> New best value..loss:0.4563790440559387 hm:0.7976113876538717\n",
      " ==> New best value..loss:0.45222581684589386 hm:0.7979485968466737\n",
      " ==> New best value..loss:0.4486157900094986 hm:0.7994450591865119\n",
      " ==> New best value..loss:0.44544620752334596 hm:0.800511666304515\n",
      " ==> New best value..loss:0.44396506309509276 hm:0.8063700641358593\n",
      " ==> New best value..loss:0.44340735077857973 hm:0.8103667260173071\n",
      " ==> New best value..loss:0.4430533856153488 hm:0.810429834005513\n",
      " ==> New best value..loss:0.44166062474250795 hm:0.8104810267023235\n",
      " ==> New best value..loss:0.4383360922336578 hm:0.8107998245804948\n",
      " ==> New best value..loss:0.43782277971506117 hm:0.8114210765322692\n",
      " ==> New best value..loss:0.4369100937247276 hm:0.8139088433865559\n",
      " ==> New best value..loss:0.43139119386672975 hm:0.8144093415488538\n",
      " ==> New best value..loss:0.42994044333696363 hm:0.815266889233517\n",
      " ==> New best value..loss:0.4297210437059402 hm:0.817408768777313\n",
      " ==> New best value..loss:0.4296920019388199 hm:0.8208610436663819\n",
      " ==> New best value..loss:0.42845204621553423 hm:0.8209521274288757\n",
      " ==> New best value..loss:0.4261484265327454 hm:0.8212972858561659\n",
      " ==> New best value..loss:0.4242794677615166 hm:0.8230678402157265\n",
      " ==> New best value..loss:0.4228668862581253 hm:0.8258198497107694\n",
      "BEST SCORE:  0.8258198497107694\n",
      "TRAINING TOOK:  466  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6342595658212338 hm:0.5988859619692324\n",
      " ==> New best value..loss:0.617776132417175 hm:0.6106028160378348\n",
      " ==> New best value..loss:0.6004412269817209 hm:0.6371078043676504\n",
      " ==> New best value..loss:0.5945928271086711 hm:0.67979657101065\n",
      " ==> New best value..loss:0.5740800752954663 hm:0.6895945308387361\n",
      " ==> New best value..loss:0.5739973013131123 hm:0.6951422440376236\n",
      " ==> New best value..loss:0.5635377950263474 hm:0.6996863686335976\n",
      " ==> New best value..loss:0.5532553077868696 hm:0.703041533596948\n",
      " ==> New best value..loss:0.5510448667238343 hm:0.7104145686428701\n",
      " ==> New best value..loss:0.5487360588784488 hm:0.7114512381185609\n",
      " ==> New best value..loss:0.5433606078039925 hm:0.7164497116103078\n",
      " ==> New best value..loss:0.5410666027159061 hm:0.7312686812853854\n",
      " ==> New best value..loss:0.5404320297376165 hm:0.732594118465107\n",
      " ==> New best value..loss:0.5348076904719731 hm:0.7354655774331644\n",
      " ==> New best value..loss:0.5270346813606765 hm:0.7359592470534131\n",
      " ==> New best value..loss:0.5256703119232969 hm:0.7428774189360904\n",
      " ==> New best value..loss:0.5178727012760235 hm:0.7482953064425396\n",
      " ==> New best value..loss:0.5122149603546791 hm:0.7496880440317303\n",
      " ==> New best value..loss:0.5095329745760504 hm:0.7525281342004578\n",
      " ==> New best value..loss:0.5079289775974346 hm:0.7541195445332262\n",
      " ==> New best value..loss:0.5078071007188761 hm:0.7552993668968484\n",
      " ==> New best value..loss:0.5031627753995499 hm:0.7557063406079642\n",
      " ==> New best value..loss:0.5031329084117457 hm:0.7636837693870739\n",
      " ==> New best value..loss:0.49324459568509516 hm:0.7687707960312284\n",
      " ==> New best value..loss:0.4893990991250524 hm:0.7732288188017412\n",
      " ==> New best value..loss:0.48921134786785775 hm:0.7791881625546292\n",
      " ==> New best value..loss:0.48745764426465304 hm:0.7804087138192384\n",
      " ==> New best value..loss:0.48079336645468224 hm:0.7827086056142318\n",
      " ==> New best value..loss:0.47038265444197747 hm:0.7827182052241997\n",
      " ==> New best value..loss:0.47013208101380544 hm:0.7850578502562169\n",
      " ==> New best value..loss:0.4686517619861747 hm:0.7870409085827035\n",
      " ==> New best value..loss:0.46180949458536114 hm:0.7878738384724677\n",
      " ==> New best value..loss:0.4587064587844993 hm:0.794084689148355\n",
      " ==> New best value..loss:0.4565327319334138 hm:0.796001145265923\n",
      " ==> New best value..loss:0.4547834236104533 hm:0.7970241556657826\n",
      " ==> New best value..loss:0.4536370078347764 hm:0.7993606580495228\n",
      " ==> New best value..loss:0.45259136692532953 hm:0.8008663726200649\n",
      " ==> New best value..loss:0.4494724672920299 hm:0.8026090113151048\n",
      " ==> New best value..loss:0.44911440194777724 hm:0.8078608520004362\n",
      " ==> New best value..loss:0.44487830996513367 hm:0.809483287851249\n",
      " ==> New best value..loss:0.44458195173515463 hm:0.8128866156691782\n",
      "BEST SCORE:  0.8128866156691782\n",
      "TRAINING TOOK:  474  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.7232798057443955 hm:0.3824529900708221\n",
      " ==> New best value..loss:0.6822634865255917 hm:0.525807043001758\n",
      " ==> New best value..loss:0.6422199969198189 hm:0.5882623832435938\n",
      " ==> New best value..loss:0.6339348858478022 hm:0.5981170302027651\n",
      " ==> New best value..loss:0.6276407656716365 hm:0.6094348814278819\n",
      " ==> New best value..loss:0.6188785556484672 hm:0.6225741125405987\n",
      " ==> New best value..loss:0.6101183938045128 hm:0.6382592116410082\n",
      " ==> New best value..loss:0.6030491724902508 hm:0.6517144503595111\n",
      " ==> New best value..loss:0.5978973805904388 hm:0.659599934222208\n",
      " ==> New best value..loss:0.593979559692682 hm:0.6660916419465391\n",
      " ==> New best value..loss:0.5930772347777498 hm:0.6705608953438214\n",
      " ==> New best value..loss:0.5908186932404836 hm:0.6792917365801264\n",
      " ==> New best value..loss:0.5867615283704272 hm:0.6833873030320333\n",
      " ==> New best value..loss:0.5775840212317074 hm:0.6959273482906183\n",
      " ==> New best value..loss:0.5746367123781466 hm:0.701022998250027\n",
      " ==> New best value..loss:0.5716691811879476 hm:0.7071178073242402\n",
      " ==> New best value..loss:0.5713878887541154 hm:0.7129795642530239\n",
      " ==> New best value..loss:0.5646863608968025 hm:0.7212763735929983\n",
      " ==> New best value..loss:0.563904207126767 hm:0.7243284015434089\n",
      " ==> New best value..loss:0.5537136793136597 hm:0.7261791513110357\n",
      " ==> New best value..loss:0.5528575772163915 hm:0.7292206756243448\n",
      " ==> New best value..loss:0.5436530241779253 hm:0.7303280382971543\n",
      " ==> New best value..loss:0.5391450448363435 hm:0.7439198796210207\n",
      " ==> New best value..loss:0.5241080487475676 hm:0.7452426457244179\n",
      " ==> New best value..loss:0.5226801329968023 hm:0.7461161670028013\n",
      " ==> New best value..loss:0.5208918510698805 hm:0.7493984402424494\n",
      " ==> New best value..loss:0.5184923387041279 hm:0.7543116453803292\n",
      " ==> New best value..loss:0.5145343273293739 hm:0.7549337601023719\n",
      " ==> New best value..loss:0.5118474247408848 hm:0.7585598475283415\n",
      " ==> New best value..loss:0.5068186842927745 hm:0.7594050741756273\n",
      " ==> New best value..loss:0.5041933235000161 hm:0.7638935264162128\n",
      " ==> New best value..loss:0.501161061665591 hm:0.7680331337662388\n",
      " ==> New best value..loss:0.4971763555910073 hm:0.7709257035761613\n",
      " ==> New best value..loss:0.4969475251786849 hm:0.771378740668113\n",
      " ==> New best value..loss:0.49654555963534935 hm:0.7735759887495248\n",
      " ==> New best value..loss:0.4918596954906688 hm:0.77545424993043\n",
      " ==> New best value..loss:0.48935844442423654 hm:0.7785072265636886\n",
      " ==> New best value..loss:0.4869726124931784 hm:0.7798560046025935\n",
      " ==> New best value..loss:0.48493470572957803 hm:0.7803662520686745\n",
      " ==> New best value..loss:0.4828033540763107 hm:0.7824082126598434\n",
      " ==> New best value..loss:0.4802711278784509 hm:0.7845777882159584\n",
      " ==> New best value..loss:0.4792818497208988 hm:0.7869082920404779\n",
      " ==> New best value..loss:0.4752650301830441 hm:0.7872920495536971\n",
      " ==> New best value..loss:0.47396255240720864 hm:0.7922157227690871\n",
      " ==> New best value..loss:0.47316113640280333 hm:0.792946314889275\n",
      " ==> New best value..loss:0.47283683980212493 hm:0.7933670171198409\n",
      " ==> New best value..loss:0.46747518024023843 hm:0.7942049258774013\n",
      " ==> New best value..loss:0.46716169633117377 hm:0.7949999904233234\n",
      " ==> New best value..loss:0.46325357638153375 hm:0.7978517321157959\n",
      " ==> New best value..loss:0.46247730973888845 hm:0.8000317040630696\n",
      " ==> New best value..loss:0.4609304952855204 hm:0.8038299526780616\n",
      " ==> New best value..loss:0.45459747022273495 hm:0.8067074422167527\n",
      " ==> New best value..loss:0.4542808030165878 hm:0.8089423652172381\n",
      " ==> New best value..loss:0.45126522756090354 hm:0.8096289148157821\n",
      " ==> New best value..loss:0.45011401936119677 hm:0.8105893071559616\n",
      " ==> New best value..loss:0.4492597667609944 hm:0.8110369686942814\n",
      " ==> New best value..loss:0.44701045284084245 hm:0.8137841941992957\n",
      " ==> New best value..loss:0.4456922400231455 hm:0.8152752233581825\n",
      " ==> New best value..loss:0.44423742563116786 hm:0.8177660501444772\n",
      " ==> New best value..loss:0.44269927956309973 hm:0.8183418452821228\n",
      " ==> New best value..loss:0.44074223847950206 hm:0.8185761086268174\n",
      " ==> New best value..loss:0.43974121411641437 hm:0.82066804606914\n",
      " ==> New best value..loss:0.43771417117586325 hm:0.8212819412577352\n",
      " ==> New best value..loss:0.43659035832274196 hm:0.8215629380664751\n",
      " ==> New best value..loss:0.4352053596692927 hm:0.8237550267174981\n",
      " ==> New best value..loss:0.43476027600905476 hm:0.8255543129443582\n",
      "BEST SCORE:  0.8255543129443582\n",
      "TRAINING TOOK:  501  s\n",
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6054440995057424 hm:0.635647173631272\n",
      " ==> New best value..loss:0.577740952372551 hm:0.6820345938979745\n",
      " ==> New best value..loss:0.5621006349722545 hm:0.7067622489263115\n",
      " ==> New best value..loss:0.5565478126207988 hm:0.716726749410952\n",
      " ==> New best value..loss:0.5366880853970846 hm:0.7410181519405682\n",
      " ==> New best value..loss:0.5263075808684031 hm:0.7438700190267158\n",
      " ==> New best value..loss:0.5199094345172246 hm:0.7461627535970113\n",
      " ==> New best value..loss:0.5169825603564581 hm:0.7519863432183903\n",
      " ==> New best value..loss:0.5159215937058131 hm:0.7563948978513698\n",
      " ==> New best value..loss:0.5140996327002844 hm:0.7612118274206149\n",
      " ==> New best value..loss:0.5045557071765264 hm:0.7647540815923191\n",
      " ==> New best value..loss:0.49501008888085685 hm:0.7670343681304717\n",
      " ==> New best value..loss:0.4924602856238683 hm:0.7680933264612151\n",
      " ==> New best value..loss:0.4867687384287516 hm:0.7691133330189387\n",
      " ==> New best value..loss:0.48423062860965727 hm:0.7741616554170903\n",
      " ==> New best value..loss:0.47776000102361044 hm:0.7812230667836452\n",
      " ==> New best value..loss:0.47744102279345196 hm:0.783503297541728\n",
      " ==> New best value..loss:0.47652551233768464 hm:0.7879564378009317\n",
      " ==> New best value..loss:0.47250117858250934 hm:0.7911418576346664\n",
      " ==> New best value..loss:0.4644849826892217 hm:0.7924506294847641\n",
      " ==> New best value..loss:0.46414132515589396 hm:0.7955776403461088\n",
      " ==> New best value..loss:0.4579424132903417 hm:0.7958760844494783\n",
      " ==> New best value..loss:0.45653496285279593 hm:0.7969913105407727\n",
      " ==> New best value..loss:0.45512310167153675 hm:0.798387723883032\n",
      " ==> New best value..loss:0.4526553819576899 hm:0.7993119262203285\n",
      " ==> New best value..loss:0.45107504924138386 hm:0.8017371189273841\n",
      " ==> New best value..loss:0.44813508093357085 hm:0.8021571406164125\n",
      " ==> New best value..loss:0.446881032983462 hm:0.8047788051155287\n",
      " ==> New best value..loss:0.4441217571496964 hm:0.8068398292660505\n",
      " ==> New best value..loss:0.44177671869595847 hm:0.8069111589042992\n",
      " ==> New best value..loss:0.44138497710227964 hm:0.8071422699652407\n",
      " ==> New best value..loss:0.4411663144826889 hm:0.8073564312085811\n",
      " ==> New best value..loss:0.4399312218030294 hm:0.8082702969961242\n",
      " ==> New best value..loss:0.4392409394184748 hm:0.8094087873206228\n",
      " ==> New best value..loss:0.43672079145908355 hm:0.8106621178725859\n",
      " ==> New best value..loss:0.4345136513312658 hm:0.8107800693827393\n",
      " ==> New best value..loss:0.43116908172766366 hm:0.8108217315279644\n",
      "BEST SCORE:  0.8108217315279644\n",
      "TRAINING TOOK:  292  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.648840396568693 hm:0.5876122786908373\n",
      " ==> New best value..loss:0.615687697098173 hm:0.6363070200644877\n",
      " ==> New best value..loss:0.5893647321339311 hm:0.6769949661458073\n",
      " ==> New best value..loss:0.5766269914035139 hm:0.6967923833600822\n",
      " ==> New best value..loss:0.5692527304435598 hm:0.7244783557615856\n",
      " ==> New best value..loss:0.5510093055922409 hm:0.7397859555383538\n",
      " ==> New best value..loss:0.5385761548732889 hm:0.7438699967606153\n",
      " ==> New best value..loss:0.5339270706834465 hm:0.7484599877110042\n",
      " ==> New best value..loss:0.528983814962979 hm:0.7545473195421284\n",
      " ==> New best value..loss:0.5252290018673601 hm:0.7549408497262333\n",
      " ==> New best value..loss:0.5200431603809883 hm:0.7579741941422851\n",
      " ==> New best value..loss:0.5143281241943096 hm:0.7590002718514739\n",
      " ==> New best value..loss:0.5132111968665287 hm:0.7633510682527794\n",
      " ==> New best value..loss:0.5062797275082819 hm:0.7660727896290908\n",
      " ==> New best value..loss:0.505086717934444 hm:0.7705972103802519\n",
      " ==> New best value..loss:0.5037613839938723 hm:0.7723821778137024\n",
      " ==> New best value..loss:0.5026811597676113 hm:0.774915992715613\n",
      " ==> New best value..loss:0.4903585160600728 hm:0.776670662246247\n",
      " ==> New best value..loss:0.48792238893180057 hm:0.7797748285506826\n",
      " ==> New best value..loss:0.4847282140419401 hm:0.7820080573034682\n",
      " ==> New best value..loss:0.4811597055402295 hm:0.7825929657991479\n",
      " ==> New best value..loss:0.48105604484163483 hm:0.7860267285956289\n",
      " ==> New best value..loss:0.4772281985858391 hm:0.7875958573842197\n",
      " ==> New best value..loss:0.47295455172144135 hm:0.7919700587603066\n",
      " ==> New best value..loss:0.4725434656800895 hm:0.7954813876823817\n",
      " ==> New best value..loss:0.4645052881076418 hm:0.7981954105705517\n",
      " ==> New best value..loss:0.4561535510523566 hm:0.7989169757534524\n",
      " ==> New best value..loss:0.4560772632730418 hm:0.8006731178967107\n",
      " ==> New best value..loss:0.45527650261747427 hm:0.8016200647529829\n",
      " ==> New best value..loss:0.45061286461764366 hm:0.8023825769917096\n",
      " ==> New best value..loss:0.44778123292429695 hm:0.8054322440679929\n",
      " ==> New best value..loss:0.4473662366127146 hm:0.8056234053905297\n",
      " ==> New best value..loss:0.44577463536426937 hm:0.807621867094064\n",
      " ==> New best value..loss:0.44492549937346887 hm:0.809620245404381\n",
      " ==> New best value..loss:0.4431374586861709 hm:0.8120404171385293\n",
      " ==> New best value..loss:0.438249245799821 hm:0.8134001258890513\n",
      " ==> New best value..loss:0.4340177558619401 hm:0.8158091487583882\n",
      " ==> New best value..loss:0.43099960890309563 hm:0.8170397628628235\n",
      " ==> New best value..loss:0.4293370534633768 hm:0.8175436345332755\n",
      " ==> New best value..loss:0.42360938520267094 hm:0.8190251299994448\n",
      " ==> New best value..loss:0.4211011405648856 hm:0.8215549086114448\n",
      " ==> New best value..loss:0.419637438552133 hm:0.8242232530318184\n",
      "BEST SCORE:  0.8242232530318184\n",
      "TRAINING TOOK:  282  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6357984792801642 hm:0.5915121383398609\n",
      " ==> New best value..loss:0.6185555784933029 hm:0.5926808087516479\n",
      " ==> New best value..loss:0.6146717283033556 hm:0.6124946031685323\n",
      " ==> New best value..loss:0.6124196504392931 hm:0.6308300785140722\n",
      " ==> New best value..loss:0.5858872532844543 hm:0.6525203837841762\n",
      " ==> New best value..loss:0.5829899830202903 hm:0.6743774016641465\n",
      " ==> New best value..loss:0.5738066107996048 hm:0.692934541446219\n",
      " ==> New best value..loss:0.5727693640416668 hm:0.7046884007233033\n",
      " ==> New best value..loss:0.5565627409565833 hm:0.7096181696635516\n",
      " ==> New best value..loss:0.5483198175507207 hm:0.7096303276477296\n",
      " ==> New best value..loss:0.5363116966139886 hm:0.7148905013846173\n",
      " ==> New best value..loss:0.530518772140626 hm:0.7153771700162048\n",
      " ==> New best value..loss:0.5188945022321516 hm:0.7282457186626642\n",
      " ==> New best value..loss:0.5144160111104289 hm:0.7402871359954896\n",
      " ==> New best value..loss:0.5129711695255772 hm:0.7492143374984331\n",
      " ==> New best value..loss:0.5128701973345972 hm:0.7527941725129854\n",
      " ==> New best value..loss:0.5095474508500868 hm:0.7556516356923266\n",
      " ==> New best value..loss:0.49942907594865366 hm:0.763918251586335\n",
      " ==> New best value..loss:0.4939505736674032 hm:0.7692507148583977\n",
      " ==> New best value..loss:0.4892663124107545 hm:0.7740425482427232\n",
      " ==> New best value..loss:0.48662644913119657 hm:0.7771787444032644\n",
      " ==> New best value..loss:0.4855743415894047 hm:0.781832344022188\n",
      " ==> New best value..loss:0.4851609035845726 hm:0.7819155250185039\n",
      " ==> New best value..loss:0.47857070930542484 hm:0.7825355178294013\n",
      " ==> New best value..loss:0.47605047975817033 hm:0.7873996188241303\n",
      " ==> New best value..loss:0.47443333652711683 hm:0.7876713600309837\n",
      " ==> New best value..loss:0.47348532753606 hm:0.7894193289066573\n",
      " ==> New best value..loss:0.4624084219817192 hm:0.7911737943357654\n",
      " ==> New best value..loss:0.4553688658821967 hm:0.7962547377641682\n",
      " ==> New best value..loss:0.4512678596281236 hm:0.7993800942302477\n",
      " ==> New best value..loss:0.4470434208070078 hm:0.8060274884797932\n",
      " ==> New best value..loss:0.44656986671109355 hm:0.807086480310704\n",
      " ==> New best value..loss:0.43587561143982795 hm:0.8082569821517438\n",
      " ==> New best value..loss:0.4323227794901017 hm:0.8116327041291924\n",
      " ==> New best value..loss:0.42751258034859935 hm:0.8210144513323135\n",
      " ==> New best value..loss:0.42579566615243114 hm:0.8212995568301291\n",
      "BEST SCORE:  0.8212995568301291\n",
      "TRAINING TOOK:  279  s\n",
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6280569922924042 hm:0.5682427644811207\n",
      " ==> New best value..loss:0.6264836037158966 hm:0.5856051869136685\n",
      " ==> New best value..loss:0.6261751186847687 hm:0.5968643268372916\n",
      " ==> New best value..loss:0.6202579581737518 hm:0.5999794296045143\n",
      " ==> New best value..loss:0.6179302859306336 hm:0.6060398266126725\n",
      " ==> New best value..loss:0.6150525087118148 hm:0.6104949484070689\n",
      " ==> New best value..loss:0.61025252699852 hm:0.6174803043282937\n",
      " ==> New best value..loss:0.6099736207723617 hm:0.6291646271105453\n",
      " ==> New best value..loss:0.6059710615873337 hm:0.6337545824536335\n",
      " ==> New best value..loss:0.6016857600212098 hm:0.650332903575587\n",
      " ==> New best value..loss:0.5963795918226242 hm:0.6667207422497731\n",
      " ==> New best value..loss:0.5826153600215912 hm:0.6966553008539649\n",
      " ==> New best value..loss:0.5792285722494125 hm:0.7059267284943614\n",
      " ==> New best value..loss:0.5614854884147644 hm:0.7094700648864516\n",
      " ==> New best value..loss:0.559729529619217 hm:0.7122684988461715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5547122019529342 hm:0.7170247793737565\n",
      " ==> New best value..loss:0.5482956725358963 hm:0.7240858482981474\n",
      " ==> New best value..loss:0.5451044523715973 hm:0.7261402184184552\n",
      " ==> New best value..loss:0.5441886895895004 hm:0.7283016889065016\n",
      " ==> New best value..loss:0.5380273574590683 hm:0.7352364163346325\n",
      " ==> New best value..loss:0.5363202369213105 hm:0.7381879539205298\n",
      " ==> New best value..loss:0.533107727766037 hm:0.7411174599220953\n",
      " ==> New best value..loss:0.530920895934105 hm:0.7444233563312551\n",
      " ==> New best value..loss:0.5298384273052216 hm:0.7460405728493206\n",
      " ==> New best value..loss:0.5298167389631271 hm:0.7463652558971852\n",
      " ==> New best value..loss:0.5276361286640168 hm:0.7474631005293891\n",
      " ==> New best value..loss:0.5269643360376358 hm:0.7488410850982793\n",
      " ==> New best value..loss:0.523317312002182 hm:0.7501878508536345\n",
      " ==> New best value..loss:0.5228390502929687 hm:0.7506850283369486\n",
      " ==> New best value..loss:0.5216810929775239 hm:0.7513277167177637\n",
      " ==> New best value..loss:0.5215960657596588 hm:0.7529774983289088\n",
      " ==> New best value..loss:0.5197929525375367 hm:0.7567960463467744\n",
      " ==> New best value..loss:0.5179256993532181 hm:0.7576586148623594\n",
      " ==> New best value..loss:0.5151496666669846 hm:0.759103778923002\n",
      " ==> New best value..loss:0.5150193387269973 hm:0.7599174463154251\n",
      " ==> New best value..loss:0.5123762774467469 hm:0.7604871428506712\n",
      " ==> New best value..loss:0.5093069505691529 hm:0.761745284438152\n",
      " ==> New best value..loss:0.5070246712863445 hm:0.7630294531430027\n",
      " ==> New best value..loss:0.5058072704076767 hm:0.7639454636953654\n",
      " ==> New best value..loss:0.5052425813674927 hm:0.76609683652754\n",
      " ==> New best value..loss:0.5043907177448272 hm:0.7673382298024916\n",
      " ==> New best value..loss:0.5036218869686127 hm:0.7695638283946297\n",
      " ==> New best value..loss:0.5027790534496307 hm:0.7704179200532869\n",
      " ==> New best value..loss:0.5017543578147888 hm:0.7740862606914192\n",
      " ==> New best value..loss:0.4982738995552063 hm:0.7743720781948904\n",
      " ==> New best value..loss:0.49808039247989655 hm:0.775338476331189\n",
      " ==> New best value..loss:0.49746854960918424 hm:0.7780500451349871\n",
      " ==> New best value..loss:0.49482855677604676 hm:0.7788707423346063\n",
      " ==> New best value..loss:0.4926391887664795 hm:0.7794652962616527\n",
      " ==> New best value..loss:0.48943192601203916 hm:0.780755505161316\n",
      " ==> New best value..loss:0.48562848299741745 hm:0.782149610363564\n",
      " ==> New best value..loss:0.48210294663906095 hm:0.7831438994517824\n",
      " ==> New best value..loss:0.4815928828716278 hm:0.7837123521476729\n",
      " ==> New best value..loss:0.47942553102970126 hm:0.7870463436344012\n",
      " ==> New best value..loss:0.47846255004405974 hm:0.7874161265676353\n",
      " ==> New best value..loss:0.4771611189842224 hm:0.789075816754958\n",
      " ==> New best value..loss:0.4758513063192368 hm:0.7904084553263098\n",
      " ==> New best value..loss:0.47523790717124936 hm:0.790742001835422\n",
      " ==> New best value..loss:0.470893959403038 hm:0.7911674710715721\n",
      "BEST SCORE:  0.7911674710715721\n",
      "TRAINING TOOK:  482  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6320694595575332 hm:0.5750714586337867\n",
      " ==> New best value..loss:0.6310499387979508 hm:0.577794086584093\n",
      " ==> New best value..loss:0.6292457711696625 hm:0.5797088945982534\n",
      " ==> New best value..loss:0.6200827467441559 hm:0.5838061525150192\n",
      " ==> New best value..loss:0.6169397383928299 hm:0.6015898344289842\n",
      " ==> New best value..loss:0.6150885373353958 hm:0.6211942785805415\n",
      " ==> New best value..loss:0.6117982459068299 hm:0.6319369271044848\n",
      " ==> New best value..loss:0.6081708127260208 hm:0.6441980286601808\n",
      " ==> New best value..loss:0.6075848281383515 hm:0.6574224745034888\n",
      " ==> New best value..loss:0.5989570981264114 hm:0.6674883777490486\n",
      " ==> New best value..loss:0.594266881942749 hm:0.6767675653885726\n",
      " ==> New best value..loss:0.5877467089891434 hm:0.6943974352645247\n",
      " ==> New best value..loss:0.5780623644590378 hm:0.7003866641417293\n",
      " ==> New best value..loss:0.5678075245022773 hm:0.708272327118054\n",
      " ==> New best value..loss:0.5657708537578583 hm:0.7115385475737599\n",
      " ==> New best value..loss:0.5576704919338227 hm:0.713240722575445\n",
      " ==> New best value..loss:0.5566825157403946 hm:0.7182639681158313\n",
      " ==> New best value..loss:0.5558904987573624 hm:0.7224299094132021\n",
      " ==> New best value..loss:0.5509613305330276 hm:0.7247039905887979\n",
      " ==> New best value..loss:0.5505407345294953 hm:0.7283109922519878\n",
      " ==> New best value..loss:0.5492832815647125 hm:0.7302615915562173\n",
      " ==> New best value..loss:0.5478673765063286 hm:0.7323301138168489\n",
      " ==> New best value..loss:0.5458313864469528 hm:0.7352299317924833\n",
      " ==> New best value..loss:0.5415931022167206 hm:0.7368404142769345\n",
      " ==> New best value..loss:0.538922112584114 hm:0.7377260685910928\n",
      " ==> New best value..loss:0.534087887108326 hm:0.7396280860448888\n",
      " ==> New best value..loss:0.5302430576086045 hm:0.7467832816903686\n",
      " ==> New best value..loss:0.5283899801969528 hm:0.7506528184778454\n",
      " ==> New best value..loss:0.5253252273797989 hm:0.7511506557794883\n",
      " ==> New best value..loss:0.5235508194565773 hm:0.7543430511473854\n",
      " ==> New best value..loss:0.5203996521234512 hm:0.7567215914660812\n",
      " ==> New best value..loss:0.5179417750239372 hm:0.7605379980182349\n",
      " ==> New best value..loss:0.5154677376151084 hm:0.7609867553917901\n",
      " ==> New best value..loss:0.5153046908974648 hm:0.7629585464680168\n",
      " ==> New best value..loss:0.512359756231308 hm:0.7637815919357241\n",
      " ==> New best value..loss:0.5089524000883102 hm:0.7707615718300043\n",
      " ==> New best value..loss:0.5084052681922913 hm:0.7719493484381771\n",
      " ==> New best value..loss:0.5067189222574234 hm:0.7746124367799787\n",
      " ==> New best value..loss:0.5053526645898819 hm:0.7771622609460186\n",
      " ==> New best value..loss:0.5026037454605102 hm:0.7795814751010404\n",
      " ==> New best value..loss:0.4982254606485367 hm:0.7812794121193521\n",
      " ==> New best value..loss:0.496661217212677 hm:0.7828350015765478\n",
      " ==> New best value..loss:0.4949891927838326 hm:0.7853113932599564\n",
      " ==> New best value..loss:0.4912292391061783 hm:0.7871313051065144\n",
      " ==> New best value..loss:0.4903951680660248 hm:0.7911838079034902\n",
      " ==> New best value..loss:0.48859581887722014 hm:0.7934669570107499\n",
      " ==> New best value..loss:0.4861824572086334 hm:0.7936398793409817\n",
      " ==> New best value..loss:0.4800091689825058 hm:0.7942919420544178\n",
      " ==> New best value..loss:0.47505647748708724 hm:0.7977539906008778\n",
      " ==> New best value..loss:0.4750523778796196 hm:0.7989838802556117\n",
      " ==> New best value..loss:0.4716500985622406 hm:0.8015873554940139\n",
      "BEST SCORE:  0.8015873554940139\n",
      "TRAINING TOOK:  484  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.6276988520914194 hm:0.5567581963608192\n",
      " ==> New best value..loss:0.6267333857867182 hm:0.5673119691339493\n",
      " ==> New best value..loss:0.6260517215242192 hm:0.5760937284822486\n",
      " ==> New best value..loss:0.6211165335713601 hm:0.5796048893907549\n",
      " ==> New best value..loss:0.6201267789821235 hm:0.5841859194394223\n",
      " ==> New best value..loss:0.6190491428180617 hm:0.5892771751446585\n",
      " ==> New best value..loss:0.6177925747268054 hm:0.5937824712796098\n",
      " ==> New best value..loss:0.616709019456591 hm:0.5984397307458954\n",
      " ==> New best value..loss:0.6156938209825632 hm:0.6017015353250754\n",
      " ==> New best value..loss:0.6142612561887625 hm:0.603047727414238\n",
      " ==> New best value..loss:0.6135754360228168 hm:0.6041028767180919\n",
      " ==> New best value..loss:0.6129688590156789 hm:0.6095346089528685\n",
      " ==> New best value..loss:0.6126526338713509 hm:0.6162396319872389\n",
      " ==> New best value..loss:0.6123486708621589 hm:0.6200442581711638\n",
      " ==> New best value..loss:0.6114269750458854 hm:0.6232502559218943\n",
      " ==> New best value..loss:0.6103865479936406 hm:0.6235428081182888\n",
      " ==> New best value..loss:0.6093217450745252 hm:0.6254609768952012\n",
      " ==> New best value..loss:0.6082260918860533 hm:0.6280228294608124\n",
      " ==> New best value..loss:0.6071386166981289 hm:0.630249157040954\n",
      " ==> New best value..loss:0.6060103050300053 hm:0.6333976858221136\n",
      " ==> New best value..loss:0.6048019187791007 hm:0.6379316082602813\n",
      " ==> New best value..loss:0.6034683013448909 hm:0.6409333762589959\n",
      " ==> New best value..loss:0.6017752551302618 hm:0.647126795572751\n",
      " ==> New best value..loss:0.599491938644526 hm:0.6545054547279617\n",
      " ==> New best value..loss:0.596985828511569 hm:0.6616468796944793\n",
      " ==> New best value..loss:0.5950962000963639 hm:0.6657824162220704\n",
      " ==> New best value..loss:0.5925225706733003 hm:0.6699252192768907\n",
      " ==> New best value..loss:0.5898449846676418 hm:0.6769500829235229\n",
      " ==> New best value..loss:0.5870282418873846 hm:0.68566858568035\n",
      " ==> New best value..loss:0.5844394753173906 hm:0.687217222499138\n",
      " ==> New best value..loss:0.5817166347892917 hm:0.6914103033583385\n",
      " ==> New best value..loss:0.5788593474699526 hm:0.6962515651314621\n",
      " ==> New best value..loss:0.5761790202588452 hm:0.6982858354100338\n",
      " ==> New best value..loss:0.5728765586201026 hm:0.7029080763709609\n",
      " ==> New best value..loss:0.5701315798321549 hm:0.7059950509751743\n",
      " ==> New best value..loss:0.5681551159644613 hm:0.7080315865037836\n",
      " ==> New best value..loss:0.5650849062569288 hm:0.709227158150784\n",
      " ==> New best value..loss:0.562430841582162 hm:0.7097448669628602\n",
      " ==> New best value..loss:0.5603370775981825 hm:0.7103763272887468\n",
      " ==> New best value..loss:0.5571698698462272 hm:0.7118208747028659\n",
      " ==> New best value..loss:0.5555209480986303 hm:0.712067424763314\n",
      " ==> New best value..loss:0.5539654456839269 hm:0.7125108779917123\n",
      " ==> New best value..loss:0.5509551970326171 hm:0.713929131876215\n",
      " ==> New best value..loss:0.5503038818738899 hm:0.7144566974805758\n",
      " ==> New best value..loss:0.5478023381865754 hm:0.7163949863733393\n",
      " ==> New best value..loss:0.5468042103611693 hm:0.7183901255579068\n",
      " ==> New best value..loss:0.5466440739680309 hm:0.7190875355056864\n",
      " ==> New best value..loss:0.5451394374273262 hm:0.719838599550231\n",
      " ==> New best value..loss:0.5432022797818087 hm:0.7209092070276192\n",
      " ==> New best value..loss:0.5425687918857652 hm:0.7219612016505915\n",
      " ==> New best value..loss:0.541866557938712 hm:0.7240444431298352\n",
      " ==> New best value..loss:0.5413182542032126 hm:0.7244439040603818\n",
      " ==> New best value..loss:0.5407905402232189 hm:0.7254564857661172\n",
      " ==> New best value..loss:0.5403374901839665 hm:0.7263671871833933\n",
      " ==> New best value..loss:0.539175919732269 hm:0.7270201099323436\n",
      " ==> New best value..loss:0.5383396781220728 hm:0.727595873512723\n",
      " ==> New best value..loss:0.5371685368674142 hm:0.7286029307075697\n",
      " ==> New best value..loss:0.5367598053143949 hm:0.7299526999151725\n",
      " ==> New best value..loss:0.535140545392523 hm:0.7307211379459739\n",
      " ==> New best value..loss:0.5346328968904457 hm:0.7317180974349964\n",
      " ==> New best value..loss:0.5335681833782975 hm:0.7321884435491929\n",
      " ==> New best value..loss:0.5330857476409601 hm:0.7326634123095529\n",
      " ==> New best value..loss:0.5329948335277791 hm:0.7328942633403809\n",
      " ==> New best value..loss:0.5327628254890442 hm:0.7332760110522321\n",
      " ==> New best value..loss:0.5326346560400359 hm:0.734012132861029\n",
      " ==> New best value..loss:0.5324434887389747 hm:0.7341692015856676\n",
      " ==> New best value..loss:0.5319534479355326 hm:0.734407854663114\n",
      " ==> New best value..loss:0.5312123031032329 hm:0.7346677364063707\n",
      " ==> New best value..loss:0.5307103492775742 hm:0.7358069693163312\n",
      " ==> New best value..loss:0.5302013055402406 hm:0.7359757131545379\n",
      " ==> New best value..loss:0.5300384899791406 hm:0.7362712170532499\n",
      " ==> New best value..loss:0.5297013673247123 hm:0.736545586893757\n",
      " ==> New best value..loss:0.5289638139763657 hm:0.736752268412404\n",
      " ==> New best value..loss:0.5282631346157619 hm:0.7380253772789067\n",
      " ==> New best value..loss:0.5278123611090134 hm:0.7381254597643488\n",
      " ==> New best value..loss:0.5274897120436843 hm:0.7384297465280919\n",
      " ==> New best value..loss:0.5273313887265264 hm:0.7393801124535458\n",
      " ==> New best value..loss:0.5261266146387372 hm:0.7397039111491717\n",
      " ==> New best value..loss:0.5258163365782523 hm:0.7406905826194631\n",
      " ==> New best value..loss:0.5238231761114938 hm:0.7414294325548355\n",
      " ==> New best value..loss:0.5224164760842616 hm:0.7417980263615441\n",
      " ==> New best value..loss:0.5220928903745146 hm:0.742933603831564\n",
      " ==> New best value..loss:0.5218357127539965 hm:0.7431953454420077\n",
      " ==> New best value..loss:0.5212574290985964 hm:0.7432184664225504\n",
      " ==> New best value..loss:0.5205700561708334 hm:0.7434727055816127\n",
      " ==> New best value..loss:0.5201251512887527 hm:0.7439804458621592\n",
      " ==> New best value..loss:0.519507364959133 hm:0.7451458124994992\n",
      " ==> New best value..loss:0.5192816403447366 hm:0.7452229754332759\n",
      " ==> New best value..loss:0.518495688633043 hm:0.7456793506669743\n",
      " ==> New best value..loss:0.5183089235607459 hm:0.7466708639670535\n",
      " ==> New best value..loss:0.5177298376754839 hm:0.7472042148934175\n",
      " ==> New best value..loss:0.5174344267163958 hm:0.748254746793739\n",
      " ==> New best value..loss:0.5153180896019449 hm:0.7490545978177579\n",
      " ==> New best value..loss:0.5144148943375568 hm:0.7496162533679636\n",
      " ==> New best value..loss:0.5141143713678632 hm:0.7501921361310342\n",
      " ==> New best value..loss:0.5135491368721943 hm:0.7515088106443351\n",
      " ==> New best value..loss:0.5131633999396343 hm:0.7527758408077923\n",
      " ==> New best value..loss:0.5113867576024971 hm:0.7534494344352051\n",
      " ==> New best value..loss:0.5106472634539312 hm:0.753995898167872\n",
      " ==> New best value..loss:0.5102529045270414 hm:0.7569846465918296\n",
      " ==> New best value..loss:0.509942144763713 hm:0.7576224236451408\n",
      " ==> New best value..loss:0.5095184366313779 hm:0.7576408851971371\n",
      " ==> New best value..loss:0.5087017179751883 hm:0.7587640802759872\n",
      " ==> New best value..loss:0.5083436978106596 hm:0.7597971966017105\n",
      " ==> New best value..loss:0.507374066479352 hm:0.760034196886417\n",
      " ==> New best value..loss:0.5069207774133099 hm:0.7605873993070402\n",
      " ==> New best value..loss:0.5066869252798508 hm:0.7606399386279055\n",
      " ==> New best value..loss:0.5058895884727945 hm:0.7620504598191166\n",
      " ==> New best value..loss:0.5057555935820754 hm:0.7625960157409337\n",
      " ==> New best value..loss:0.5050780937379721 hm:0.7628210663254577\n",
      " ==> New best value..loss:0.5048504374465164 hm:0.7633745040016738\n",
      " ==> New best value..loss:0.5037063335885807 hm:0.7636076424357591\n",
      " ==> New best value..loss:0.5031907327321111 hm:0.7656151750211206\n",
      " ==> New best value..loss:0.5015002276216235 hm:0.7665322097689172\n",
      " ==> New best value..loss:0.5011141324529842 hm:0.7684363362258496\n",
      " ==> New best value..loss:0.5002959692964748 hm:0.7708689410698781\n",
      " ==> New best value..loss:0.49790441320866957 hm:0.7712154262661595\n",
      " ==> New best value..loss:0.49760972419563604 hm:0.7714392894571088\n",
      " ==> New best value..loss:0.49681092342551875 hm:0.7730613039663666\n",
      " ==> New best value..loss:0.49633900608335224 hm:0.7736133177195841\n",
      " ==> New best value..loss:0.4954794116166173 hm:0.7742700005231522\n",
      " ==> New best value..loss:0.49460738471576143 hm:0.7743369176338238\n",
      " ==> New best value..loss:0.4945619696257066 hm:0.7758139676183358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.4932785289628165 hm:0.7772533243229985\n",
      " ==> New best value..loss:0.49306043921684733 hm:0.7779862823411358\n",
      " ==> New best value..loss:0.49216672413203183 hm:0.7785503614843162\n",
      " ==> New best value..loss:0.4904333012444632 hm:0.7787643770350225\n",
      " ==> New best value..loss:0.490157062910041 hm:0.7794391738617678\n",
      " ==> New best value..loss:0.4900599547794887 hm:0.7800227013546385\n",
      " ==> New best value..loss:0.4896466032582886 hm:0.7804510457605328\n",
      " ==> New best value..loss:0.48838090774964316 hm:0.7805043307279097\n",
      " ==> New best value..loss:0.48816825358235105 hm:0.7810541872273534\n",
      " ==> New best value..loss:0.48765527897951555 hm:0.7817013128918775\n",
      " ==> New best value..loss:0.486982737876931 hm:0.7827916264046467\n",
      " ==> New best value..loss:0.48620471358299255 hm:0.7842357087559381\n",
      " ==> New best value..loss:0.4861243592233074 hm:0.7845939564140071\n",
      " ==> New best value..loss:0.48564026002981225 hm:0.784915184907291\n",
      "BEST SCORE:  0.784915184907291\n",
      "TRAINING TOOK:  481  s\n",
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6350804050763448 hm:0.569770155566366\n",
      " ==> New best value..loss:0.6328102846940359 hm:0.6363725043285635\n",
      " ==> New best value..loss:0.6262987156709036 hm:0.6545699470671925\n",
      " ==> New best value..loss:0.6052418529987336 hm:0.6615445154632322\n",
      " ==> New best value..loss:0.6020926813284556 hm:0.6758328724914525\n",
      " ==> New best value..loss:0.5961944212516149 hm:0.6780830796464554\n",
      " ==> New best value..loss:0.592661048968633 hm:0.6822288032426365\n",
      " ==> New best value..loss:0.5888828893502553 hm:0.6844056120868336\n",
      " ==> New best value..loss:0.58761651913325 hm:0.6877103344597766\n",
      " ==> New best value..loss:0.5838796933492024 hm:0.6918944279425222\n",
      " ==> New best value..loss:0.5817851920922598 hm:0.6937696857961735\n",
      " ==> New best value..loss:0.5780261327823003 hm:0.6957358499509738\n",
      " ==> New best value..loss:0.5779529541730881 hm:0.6965240727134748\n",
      " ==> New best value..loss:0.5770750015974044 hm:0.6981695580605978\n",
      " ==> New best value..loss:0.574145519733429 hm:0.7039220196017927\n",
      " ==> New best value..loss:0.5725881854693095 hm:0.7084047329054209\n",
      " ==> New best value..loss:0.5709431837002437 hm:0.7094952355526487\n",
      " ==> New best value..loss:0.5695906708637873 hm:0.7130083933611281\n",
      " ==> New best value..loss:0.5685931911071141 hm:0.7139246598214867\n",
      " ==> New best value..loss:0.5672233939170838 hm:0.7150690193788373\n",
      " ==> New best value..loss:0.5660005847613017 hm:0.7163425934845001\n",
      " ==> New best value..loss:0.5652151674032211 hm:0.7181072579487755\n",
      " ==> New best value..loss:0.5628907740116119 hm:0.719627556016394\n",
      " ==> New best value..loss:0.5608762592077255 hm:0.7196283791325055\n",
      " ==> New best value..loss:0.5589998871088028 hm:0.7202443830222572\n",
      " ==> New best value..loss:0.5576466610034306 hm:0.7247529207237415\n",
      " ==> New best value..loss:0.5562579284111658 hm:0.7261937776140751\n",
      " ==> New best value..loss:0.5554142067829768 hm:0.7285678887599677\n",
      " ==> New best value..loss:0.5542769571145375 hm:0.7289515897375693\n",
      " ==> New best value..loss:0.5537549883127213 hm:0.7302678692465762\n",
      " ==> New best value..loss:0.5530885408322016 hm:0.7306724163814822\n",
      " ==> New best value..loss:0.5530268311500549 hm:0.7328524579138567\n",
      " ==> New best value..loss:0.5524293820063273 hm:0.7335508815548927\n",
      " ==> New best value..loss:0.5517073810100556 hm:0.7348328246185009\n",
      " ==> New best value..loss:0.5510883261760076 hm:0.7364762837876779\n",
      " ==> New best value..loss:0.5485850632190704 hm:0.7367940139245738\n",
      " ==> New best value..loss:0.5475887914498647 hm:0.737887130816879\n",
      " ==> New best value..loss:0.5464688917001088 hm:0.73839389999422\n",
      " ==> New best value..loss:0.5459513862927755 hm:0.7404523312778817\n",
      " ==> New best value..loss:0.5451618323723475 hm:0.7427107790461762\n",
      " ==> New best value..loss:0.5439582020044327 hm:0.7432717695965586\n",
      " ==> New best value..loss:0.5437457491954167 hm:0.7457075015748895\n",
      " ==> New best value..loss:0.5418762077887853 hm:0.7460771484157627\n",
      " ==> New best value..loss:0.5403291215499242 hm:0.7461165600995513\n",
      " ==> New best value..loss:0.5391174455483755 hm:0.7464329373159673\n",
      " ==> New best value..loss:0.5362793693939845 hm:0.7466370608784155\n",
      " ==> New best value..loss:0.534803663690885 hm:0.7466409054133303\n",
      " ==> New best value..loss:0.5347126315037409 hm:0.7499060008826283\n",
      " ==> New best value..loss:0.5326410641272863 hm:0.7511388737058408\n",
      " ==> New best value..loss:0.5319177548090617 hm:0.7517809028960782\n",
      " ==> New best value..loss:0.5303202410538991 hm:0.7518156282508079\n",
      " ==> New best value..loss:0.5298368682463964 hm:0.7530976240497623\n",
      " ==> New best value..loss:0.5282316615184148 hm:0.7543150523680273\n",
      " ==> New best value..loss:0.5270500659942627 hm:0.7548056931281267\n",
      " ==> New best value..loss:0.5266457170248031 hm:0.7578201287737726\n",
      " ==> New best value..loss:0.5261678000291189 hm:0.7589188541766064\n",
      " ==> New best value..loss:0.5248803357283275 hm:0.7593913710321509\n",
      " ==> New best value..loss:0.5233219365278879 hm:0.7600487810249823\n",
      " ==> New best value..loss:0.5207928667465845 hm:0.7637862812453694\n",
      "BEST SCORE:  0.7637862812453694\n",
      "TRAINING TOOK:  274  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6193368992497844 hm:0.5484761670188356\n",
      " ==> New best value..loss:0.6182974519268158 hm:0.6455427529389485\n",
      " ==> New best value..loss:0.6153794430917309 hm:0.6635493999002303\n",
      " ==> New best value..loss:0.6130538275164943 hm:0.6651385586321874\n",
      " ==> New best value..loss:0.5915271534073737 hm:0.6662366810379482\n",
      " ==> New best value..loss:0.5878239158661135 hm:0.6724102078837142\n",
      " ==> New best value..loss:0.5809527347164769 hm:0.6813335595586205\n",
      " ==> New best value..loss:0.5801047019420131 hm:0.6882077487086814\n",
      " ==> New best value..loss:0.5692619239130328 hm:0.7006928057589173\n",
      " ==> New best value..loss:0.560182987682281 hm:0.7090277683106303\n",
      " ==> New best value..loss:0.554530680179596 hm:0.7151336931288462\n",
      " ==> New best value..loss:0.5517924793304936 hm:0.715322025957067\n",
      " ==> New best value..loss:0.5452045894438221 hm:0.7205508461010922\n",
      " ==> New best value..loss:0.5441760372730994 hm:0.7209545757895484\n",
      " ==> New best value..loss:0.54282372613107 hm:0.7228983761500466\n",
      " ==> New best value..loss:0.5411300005451325 hm:0.7236783004307081\n",
      " ==> New best value..loss:0.5408624477924839 hm:0.7248128486049756\n",
      " ==> New best value..loss:0.5369274020195007 hm:0.7255287876477252\n",
      " ==> New best value..loss:0.5362507950875067 hm:0.7272502981989979\n",
      " ==> New best value..loss:0.5307728398230768 hm:0.729998504738465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5292888495229906 hm:0.7307452349147441\n",
      " ==> New best value..loss:0.5274026326594814 hm:0.730975335835922\n",
      " ==> New best value..loss:0.5259808926813064 hm:0.7324666335682937\n",
      " ==> New best value..loss:0.5237509223722643 hm:0.733236165051303\n",
      " ==> New best value..loss:0.5226631020345995 hm:0.7342272165935702\n",
      " ==> New best value..loss:0.5183992933842444 hm:0.7345331504927083\n",
      " ==> New best value..loss:0.5179132434629625 hm:0.7382051635849037\n",
      " ==> New best value..loss:0.5175130367279053 hm:0.7392376939659852\n",
      " ==> New best value..loss:0.515199464175009 hm:0.7401151283792993\n",
      " ==> New best value..loss:0.5140825596547896 hm:0.7410368737997044\n",
      " ==> New best value..loss:0.5131816681354276 hm:0.7438220999904304\n",
      " ==> New best value..loss:0.5127527021592663 hm:0.744052538630957\n",
      " ==> New best value..loss:0.5102287386694262 hm:0.7448801881460936\n",
      " ==> New best value..loss:0.5098763848504713 hm:0.74511892728112\n",
      " ==> New best value..loss:0.5097091351785967 hm:0.7485131590178444\n",
      " ==> New best value..loss:0.5082678362246482 hm:0.7485336540367628\n",
      " ==> New best value..loss:0.507921342888186 hm:0.7486794701049136\n",
      " ==> New best value..loss:0.5069125794595287 hm:0.7491781126710526\n",
      " ==> New best value..loss:0.5044237307963833 hm:0.7492673370626167\n",
      " ==> New best value..loss:0.5030888838152732 hm:0.7521424284949757\n",
      " ==> New best value..loss:0.5026772618293762 hm:0.7522541439744624\n",
      " ==> New best value..loss:0.500003061948284 hm:0.7535473893902856\n",
      " ==> New best value..loss:0.49822524862904705 hm:0.7571679234654564\n",
      " ==> New best value..loss:0.4979286809121409 hm:0.7596789818387243\n",
      " ==> New best value..loss:0.49708595679652307 hm:0.7596912741569546\n",
      " ==> New best value..loss:0.49661960044214803 hm:0.7616944780426068\n",
      " ==> New best value..loss:0.49494696047998243 hm:0.7626791844593003\n",
      " ==> New best value..loss:0.49481557357695793 hm:0.7632130466680753\n",
      " ==> New best value..loss:0.4937622287581044 hm:0.7639053309110333\n",
      " ==> New best value..loss:0.49289539264094445 hm:0.7653169332924763\n",
      " ==> New best value..loss:0.4920785763571339 hm:0.7656055347015693\n",
      " ==> New best value..loss:0.4916731330656236 hm:0.766597133464238\n",
      " ==> New best value..loss:0.49117575633910393 hm:0.7668107722702486\n",
      " ==> New best value..loss:0.4910182770221464 hm:0.7684870816073214\n",
      "BEST SCORE:  0.7684870816073214\n",
      "TRAINING TOOK:  276  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6402035295963288 hm:0.5966753844815877\n",
      " ==> New best value..loss:0.6389243245124817 hm:0.5991045955061279\n",
      " ==> New best value..loss:0.616589163740476 hm:0.6015687650477661\n",
      " ==> New best value..loss:0.6155850867430369 hm:0.6053113022353842\n",
      " ==> New best value..loss:0.6147951344648998 hm:0.6077785793444165\n",
      " ==> New best value..loss:0.6134632011254628 hm:0.6121842504786541\n",
      " ==> New best value..loss:0.6118740230798722 hm:0.6168818607429846\n",
      " ==> New best value..loss:0.6111761291821798 hm:0.621647536199661\n",
      " ==> New best value..loss:0.6097910702228546 hm:0.6245560299981895\n",
      " ==> New best value..loss:0.6082600831985474 hm:0.6283972290964657\n",
      " ==> New best value..loss:0.6077539503574372 hm:0.6311629304667753\n",
      " ==> New best value..loss:0.6062464018662771 hm:0.6352454111159113\n",
      " ==> New best value..loss:0.6049850205580394 hm:0.6391355280148028\n",
      " ==> New best value..loss:0.6035536269346873 hm:0.6438128905053276\n",
      " ==> New best value..loss:0.6020892679691314 hm:0.6485505340399088\n",
      " ==> New best value..loss:0.6007323265075684 hm:0.6519987536207851\n",
      " ==> New best value..loss:0.6003907879193624 hm:0.6539623454552851\n",
      " ==> New best value..loss:0.5983859697977701 hm:0.6579841325838928\n",
      " ==> New best value..loss:0.5970768958330155 hm:0.6611003554010056\n",
      " ==> New best value..loss:0.5953912625710169 hm:0.6644420975839457\n",
      " ==> New best value..loss:0.5952670246362686 hm:0.6660225371596944\n",
      " ==> New best value..loss:0.5950545986493428 hm:0.6672019134736459\n",
      " ==> New best value..loss:0.5949931422869364 hm:0.6687849384432126\n",
      " ==> New best value..loss:0.5929852922757467 hm:0.6719357326943699\n",
      " ==> New best value..loss:0.5905111600955327 hm:0.6757158932247043\n",
      " ==> New best value..loss:0.5894164214531581 hm:0.6783578966167448\n",
      " ==> New best value..loss:0.5890719085931778 hm:0.6794113862682299\n",
      " ==> New best value..loss:0.5882236043612162 hm:0.6806192436599484\n",
      " ==> New best value..loss:0.5874984472990036 hm:0.6827270075039955\n",
      " ==> New best value..loss:0.5866576333840688 hm:0.6835838777752218\n",
      " ==> New best value..loss:0.5865374058485031 hm:0.6851133518425703\n",
      " ==> New best value..loss:0.5859086106220881 hm:0.6865108212005246\n",
      " ==> New best value..loss:0.5852881769339243 hm:0.6875594092100021\n",
      " ==> New best value..loss:0.5846699684858322 hm:0.6884290562444042\n",
      " ==> New best value..loss:0.5834473162889481 hm:0.6902376778058751\n",
      " ==> New best value..loss:0.5823864738146464 hm:0.6912021796315415\n",
      " ==> New best value..loss:0.5817886809508006 hm:0.6919773421458877\n",
      " ==> New best value..loss:0.5809464395046234 hm:0.693702549792043\n",
      " ==> New best value..loss:0.5806836108366649 hm:0.6943239143053197\n",
      " ==> New best value..loss:0.580452545483907 hm:0.6947380608692766\n",
      " ==> New best value..loss:0.5788977901140849 hm:0.6956896042860324\n",
      " ==> New best value..loss:0.5785665849844615 hm:0.6969189030537724\n",
      " ==> New best value..loss:0.578114660580953 hm:0.6973102112740406\n",
      " ==> New best value..loss:0.5774752030769984 hm:0.6979095616059944\n",
      " ==> New best value..loss:0.5771882017453511 hm:0.6981982260119404\n",
      " ==> New best value..loss:0.5755680859088897 hm:0.6995760111060846\n",
      " ==> New best value..loss:0.575421804189682 hm:0.7003907690021726\n",
      " ==> New best value..loss:0.5747861564159393 hm:0.7007010114244572\n",
      " ==> New best value..loss:0.5738450249036153 hm:0.7014089363859813\n",
      " ==> New best value..loss:0.5733162532250087 hm:0.7022208845076631\n",
      " ==> New best value..loss:0.5731117079655329 hm:0.7022884598642503\n",
      " ==> New best value..loss:0.5707074761390686 hm:0.7045857230267271\n",
      " ==> New best value..loss:0.5696072399616241 hm:0.7054723165735509\n",
      " ==> New best value..loss:0.5686741709709168 hm:0.7061633314166615\n",
      " ==> New best value..loss:0.5686617960532506 hm:0.7064451090572638\n",
      " ==> New best value..loss:0.5674410283565521 hm:0.7070468339055643\n",
      " ==> New best value..loss:0.5670497685670852 hm:0.7075461972299467\n",
      " ==> New best value..loss:0.5653895109891891 hm:0.7088403191004656\n",
      " ==> New best value..loss:0.5640935639540354 hm:0.7110501085611353\n",
      " ==> New best value..loss:0.5630295604467392 hm:0.7118056253837621\n",
      " ==> New best value..loss:0.5626727958520253 hm:0.7125389368977887\n",
      " ==> New best value..loss:0.5611618598302205 hm:0.713401540865843\n",
      " ==> New best value..loss:0.5599152038494746 hm:0.7139833696063379\n",
      " ==> New best value..loss:0.5582585275173187 hm:0.7155234280499089\n",
      " ==> New best value..loss:0.5576618234316508 hm:0.7164003382849615\n",
      " ==> New best value..loss:0.5535969833532969 hm:0.7198247961236149\n",
      " ==> New best value..loss:0.5527732819318771 hm:0.7198268113434896\n",
      " ==> New best value..loss:0.5507639229297638 hm:0.72127119577014\n",
      " ==> New best value..loss:0.5491629709800084 hm:0.7232359506880216\n",
      " ==> New best value..loss:0.5482209612925847 hm:0.7241082380425077\n",
      " ==> New best value..loss:0.5479137053092321 hm:0.7251921358311177\n",
      " ==> New best value..loss:0.5460023383299509 hm:0.730551666358852\n",
      " ==> New best value..loss:0.5443822145462036 hm:0.7313395108586246\n",
      " ==> New best value..loss:0.5440682778755824 hm:0.7324984007373119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5439172049363454 hm:0.7339652183312204\n",
      " ==> New best value..loss:0.5418542792399724 hm:0.7380138271040745\n",
      " ==> New best value..loss:0.5374140828847885 hm:0.7382444229990928\n",
      " ==> New best value..loss:0.5350431551535925 hm:0.7387800532551344\n",
      " ==> New best value..loss:0.5347143799066544 hm:0.7389524863406146\n",
      " ==> New best value..loss:0.5345651706059774 hm:0.7403051364646972\n",
      " ==> New best value..loss:0.5327365775903066 hm:0.7410033869670408\n",
      " ==> New best value..loss:0.5323325842618942 hm:0.741885936000431\n",
      " ==> New best value..loss:0.5321142146984736 hm:0.7420397775495922\n",
      " ==> New best value..loss:0.5311592052380244 hm:0.7422313629065803\n",
      " ==> New best value..loss:0.530291736125946 hm:0.7424523052687827\n",
      " ==> New best value..loss:0.5297740558783214 hm:0.742494479770574\n",
      " ==> New best value..loss:0.5284297317266464 hm:0.7446234057816955\n",
      " ==> New best value..loss:0.5264718184868494 hm:0.7448124514755204\n",
      " ==> New best value..loss:0.5262720435857773 hm:0.7453111719450679\n",
      " ==> New best value..loss:0.5255629519621531 hm:0.7479898446851134\n",
      " ==> New best value..loss:0.5246637493371964 hm:0.7481105422378582\n",
      " ==> New best value..loss:0.5236953785022099 hm:0.7497578469808889\n",
      " ==> New best value..loss:0.5233632306257884 hm:0.7502131570462564\n",
      " ==> New best value..loss:0.5233594387769699 hm:0.7503646811747207\n",
      " ==> New best value..loss:0.5212510913610459 hm:0.7514475785766744\n",
      " ==> New best value..loss:0.5211122890313467 hm:0.7516792388444089\n",
      " ==> New best value..loss:0.51944540143013 hm:0.7544005011172228\n",
      " ==> New best value..loss:0.5193881114323934 hm:0.7551373417551294\n",
      " ==> New best value..loss:0.5189538151025772 hm:0.756349810931084\n",
      " ==> New best value..loss:0.5175893723964691 hm:0.7569071090309998\n",
      " ==> New best value..loss:0.517186297972997 hm:0.7572427256489476\n",
      " ==> New best value..loss:0.5163067738215129 hm:0.7588369444968986\n",
      " ==> New best value..loss:0.5160777707894643 hm:0.7628209504762761\n",
      " ==> New best value..loss:0.5142716258764267 hm:0.7633095591839805\n",
      " ==> New best value..loss:0.5134340027968088 hm:0.763348378604034\n",
      " ==> New best value..loss:0.5125938067833583 hm:0.764627461404929\n",
      " ==> New best value..loss:0.5125637988249461 hm:0.7666017395561608\n",
      " ==> New best value..loss:0.5111046582460403 hm:0.7666301419768509\n",
      " ==> New best value..loss:0.510113196571668 hm:0.7670228059899382\n",
      " ==> New best value..loss:0.5093364636103312 hm:0.7683406347012873\n",
      " ==> New best value..loss:0.5084691007932027 hm:0.768862662495468\n",
      " ==> New best value..loss:0.5074338525533676 hm:0.7693893552578207\n",
      " ==> New best value..loss:0.5072990616162618 hm:0.7695739455687026\n",
      " ==> New best value..loss:0.5055958678325018 hm:0.7717843022556171\n",
      " ==> New best value..loss:0.5053828100363413 hm:0.7735043919121564\n",
      "BEST SCORE:  0.7735043919121564\n",
      "TRAINING TOOK:  283  s\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'tanh'\n",
    "\n",
    "params_dict['epochs'] = 30 \n",
    "params_dict['print_every'] = 19\n",
    "\n",
    "params_dict['fc1'] = 200\n",
    "params_dict['fc2'] = 30\n",
    "params_dict['drop_fc'] = 0.4\n",
    "params_dict['fc'] = create_fc( params_dict['fc1'],\n",
    "                    params_dict['fc2'],params_dict['drop_fc'])\n",
    "        \n",
    "\n",
    "alpha_lst = [1, 0.5, 0.05]\n",
    "lr_lst = [7e-5, 7e-6]\n",
    "bs_lst = [30, 50]\n",
    "\n",
    "nn_tanh= []\n",
    "scores_tanh = []\n",
    "\n",
    "for lr in lr_lst:\n",
    "    params_dict['lr'] = lr\n",
    "    \n",
    "    for bs in bs_lst:\n",
    "        params_dict['batch_size'] = bs\n",
    "\n",
    "        for alpha in alpha_lst:\n",
    "            params_dict['tan_a'] = alpha\n",
    "\n",
    "            print('='*80)\n",
    "            print('alpha:', alpha, 'bs', )\n",
    "            d_start = datetime.now() \n",
    "            best_score, classifier = do_training( df_in1, params_dict, criterion)\n",
    "            nn_tanh.append(classifier)\n",
    "            scores_tanh.append(best_score)\n",
    "\n",
    "            print('BEST SCORE: ', best_score)\n",
    "            print('TRAINING TOOK: ', ( datetime.now() - d_start ).seconds, ' s'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11,  8,  6,  7,  3,  1,  5,  4,  2,  0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(scores_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. test de-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6187478620178846 hm:0.582793437686237\n",
      " ==> New best value..loss:0.6075767375984971 hm:0.6120527624427844\n",
      " ==> New best value..loss:0.5969545464126431 hm:0.652552547068315\n",
      " ==> New best value..loss:0.5943502345863654 hm:0.6644549155597278\n",
      " ==> New best value..loss:0.5888529061054697 hm:0.6723466264083655\n",
      " ==> New best value..loss:0.579917236250274 hm:0.6801194284307024\n",
      " ==> New best value..loss:0.5753704704800431 hm:0.685400100376497\n",
      " ==> New best value..loss:0.5685809412781073 hm:0.6954779077448645\n",
      " ==> New best value..loss:0.5601949843825126 hm:0.7007892182740623\n",
      " ==> New best value..loss:0.5594322833479667 hm:0.7016362007371897\n",
      " ==> New best value..loss:0.5522294299943107 hm:0.7101138402954598\n",
      " ==> New best value..loss:0.550817000622652 hm:0.7103132612065239\n",
      " ==> New best value..loss:0.5496511222148428 hm:0.7162479070289564\n",
      " ==> New best value..loss:0.5451856170381818 hm:0.729344984903187\n",
      " ==> New best value..loss:0.5411443746819788 hm:0.7318230931642218\n",
      " ==> New best value..loss:0.5270441107603968 hm:0.7324980423283037\n",
      " ==> New best value..loss:0.525659655429879 hm:0.7343933804711323\n",
      " ==> New best value..loss:0.5243529704760532 hm:0.739797757384085\n",
      " ==> New best value..loss:0.5206806860408004 hm:0.7400436153030467\n",
      " ==> New best value..loss:0.5203743681919818 hm:0.741476220075184\n",
      " ==> New best value..loss:0.5142016155379159 hm:0.743344513358202\n",
      " ==> New best value..loss:0.5121891389087755 hm:0.749428026291451\n",
      " ==> New best value..loss:0.5088366580252744 hm:0.7525552442766164\n",
      "BEST SCORE:  0.7525552442766164\n",
      "TRAINING TOOK:  533  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6017604531074057 hm:0.6117247257690227\n",
      " ==> New best value..loss:0.6007047514526211 hm:0.6180544573014747\n",
      " ==> New best value..loss:0.5832266083785466 hm:0.685762167845667\n",
      " ==> New best value..loss:0.5697155357623587 hm:0.6990591317583611\n",
      " ==> New best value..loss:0.5602421079363141 hm:0.7129398976613491\n",
      " ==> New best value..loss:0.5352476847415067 hm:0.7166915196956412\n",
      " ==> New best value..loss:0.529677439252941 hm:0.7214476323961053\n",
      " ==> New best value..loss:0.5245675547998778 hm:0.7310418299067996\n",
      " ==> New best value..loss:0.5207015640881597 hm:0.7379911643534474\n",
      " ==> New best value..loss:0.5155406390525856 hm:0.7408222396758464\n",
      " ==> New best value..loss:0.5139680769370527 hm:0.7408271508120349\n",
      " ==> New best value..loss:0.5075573483291937 hm:0.745779646543022\n",
      " ==> New best value..loss:0.4995781992162977 hm:0.7552352458388145\n",
      " ==> New best value..loss:0.4990990751860093 hm:0.7592585926116886\n",
      " ==> New best value..loss:0.49730874993363205 hm:0.7593250440497153\n",
      " ==> New best value..loss:0.4833920569140084 hm:0.7608981491230565\n",
      " ==> New best value..loss:0.48291052786671385 hm:0.766404818506085\n",
      " ==> New best value..loss:0.4759387281932393 hm:0.7673813336081616\n",
      " ==> New best value..loss:0.4739987227913676 hm:0.7700862116166055\n",
      " ==> New best value..loss:0.46762629078549084 hm:0.7781728250304266\n",
      "BEST SCORE:  0.7781728250304266\n",
      "TRAINING TOOK:  535  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6096282573241107 hm:0.6188960993535562\n",
      " ==> New best value..loss:0.6082971337831246 hm:0.6191291724677483\n",
      " ==> New best value..loss:0.6047762283739054 hm:0.6246316762658657\n",
      " ==> New best value..loss:0.6000907713512205 hm:0.6588127699875734\n",
      " ==> New best value..loss:0.587922770459697 hm:0.6756168290726434\n",
      " ==> New best value..loss:0.5755756441152321 hm:0.6840328453079566\n",
      " ==> New best value..loss:0.5686933043992745 hm:0.6956013070425964\n",
      " ==> New best value..loss:0.5607460461697489 hm:0.6972937000658475\n",
      " ==> New best value..loss:0.5567566954864646 hm:0.7008949415223545\n",
      " ==> New best value..loss:0.554794080414862 hm:0.7026802391395366\n",
      " ==> New best value..loss:0.5538744712775608 hm:0.7099419590319178\n",
      " ==> New best value..loss:0.553216556895454 hm:0.7155631137059008\n",
      " ==> New best value..loss:0.5487847457516868 hm:0.7171750239367888\n",
      " ==> New best value..loss:0.5483177776606578 hm:0.7177306929860536\n",
      " ==> New best value..loss:0.5410042556951631 hm:0.7220009910897025\n",
      " ==> New best value..loss:0.5358970727560655 hm:0.7233456562678854\n",
      " ==> New best value..loss:0.5342421857815869 hm:0.729529440281528\n",
      " ==> New best value..loss:0.5325782552080335 hm:0.730943497203119\n",
      " ==> New best value..loss:0.5298123961349703 hm:0.736498576636589\n",
      " ==> New best value..loss:0.5277831841189906 hm:0.7390263609202148\n",
      " ==> New best value..loss:0.5239846037243897 hm:0.7407119822134173\n",
      " ==> New best value..loss:0.5233494296388806 hm:0.7413632635805414\n",
      " ==> New best value..loss:0.5171324048402175 hm:0.7433198621174277\n",
      " ==> New best value..loss:0.5138780013570245 hm:0.7450501756115833\n",
      " ==> New best value..loss:0.513547273177021 hm:0.747755413922078\n",
      " ==> New best value..loss:0.5117693408480231 hm:0.7508685910081339\n",
      " ==> New best value..loss:0.5055869938629978 hm:0.751507212841736\n",
      " ==> New best value..loss:0.5031029627008258 hm:0.7541630644108732\n",
      " ==> New best value..loss:0.501593383977998 hm:0.7569093179671288\n",
      " ==> New best value..loss:0.49931724847487685 hm:0.758229136538608\n",
      " ==> New best value..loss:0.49296371948044254 hm:0.7602385347976769\n",
      " ==> New best value..loss:0.4929470906280122 hm:0.7610008083045503\n",
      " ==> New best value..loss:0.4926927382091306 hm:0.7626000887674191\n",
      "BEST SCORE:  0.7626000887674191\n",
      "TRAINING TOOK:  546  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.613550102593852 hm:0.6044089609031805\n",
      " ==> New best value..loss:0.6116615884444293 hm:0.6731448505366545\n",
      " ==> New best value..loss:0.6027237971623739 hm:0.6770354899870906\n",
      " ==> New best value..loss:0.5862043686941558 hm:0.6781152260406227\n",
      " ==> New best value..loss:0.578347220140345 hm:0.6863044525468047\n",
      " ==> New best value..loss:0.5736643192814845 hm:0.6888243133367293\n",
      " ==> New best value..loss:0.5694618587400399 hm:0.6918407734053228\n",
      " ==> New best value..loss:0.562798311605173 hm:0.6965861960972253\n",
      " ==> New best value..loss:0.5578353679647633 hm:0.6994636033018661\n",
      " ==> New best value..loss:0.5567359801600961 hm:0.705568190382913\n",
      " ==> New best value..loss:0.5567174325971043 hm:0.7059622149830624\n",
      " ==> New best value..loss:0.5551821571939132 hm:0.7099460182936602\n",
      " ==> New best value..loss:0.54975579123871 hm:0.7130024625277165\n",
      " ==> New best value..loss:0.5481579882257125 hm:0.7132726271038293\n",
      " ==> New best value..loss:0.5463222060717788 hm:0.7151892811908257\n",
      " ==> New best value..loss:0.5443677136711046 hm:0.7224080965016768\n",
      " ==> New best value..loss:0.5408041880411261 hm:0.7227346373077222\n",
      " ==> New best value..loss:0.5393046362727296 hm:0.7241217273127477\n",
      " ==> New best value..loss:0.5369039674599966 hm:0.7242989585015903\n",
      " ==> New best value..loss:0.5315946474963543 hm:0.7282745699951265\n",
      " ==> New best value..loss:0.5315004931945427 hm:0.7344499452120679\n",
      " ==> New best value..loss:0.5251733917816013 hm:0.7385411952578615\n",
      " ==> New best value..loss:0.523173814310747 hm:0.7392894900160927\n",
      " ==> New best value..loss:0.5195227227374619 hm:0.7409220595582142\n",
      " ==> New best value..loss:0.5162152285669365 hm:0.7424071584276241\n",
      " ==> New best value..loss:0.5160511580168032 hm:0.7470995067410303\n",
      " ==> New best value..loss:0.515672919212603 hm:0.7482048007828507\n",
      " ==> New best value..loss:0.5146944183929294 hm:0.748694931671655\n",
      " ==> New best value..loss:0.5123605833334082 hm:0.7498306538619034\n",
      " ==> New best value..loss:0.5113091392844331 hm:0.7499573636340281\n",
      " ==> New best value..loss:0.5080155756543664 hm:0.75177434993952\n",
      " ==> New best value..loss:0.5062398115793864 hm:0.7534848511933819\n",
      " ==> New best value..loss:0.5058625077500063 hm:0.7544409442063472\n",
      " ==> New best value..loss:0.5051910754512338 hm:0.7583492513218333\n",
      " ==> New best value..loss:0.5027041636845645 hm:0.7596582200059973\n",
      " ==> New best value..loss:0.4988207951480267 hm:0.7602839067299564\n",
      " ==> New best value..loss:0.4960266959433462 hm:0.7610259263725652\n",
      "BEST SCORE:  0.7610259263725652\n",
      "TRAINING TOOK:  551  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.609291078413234 hm:0.5858415706887488\n",
      " ==> New best value..loss:0.6087973117828369 hm:0.6004826154998543\n",
      " ==> New best value..loss:0.6087317811507805 hm:0.6202654117638501\n",
      " ==> New best value..loss:0.5920127285461799 hm:0.6670831690666251\n",
      " ==> New best value..loss:0.5846764071314943 hm:0.6743498193006136\n",
      " ==> New best value..loss:0.5781412580434013 hm:0.6853107643961095\n",
      " ==> New best value..loss:0.573919052586836 hm:0.6895168746613859\n",
      " ==> New best value..loss:0.5738269283491022 hm:0.692681787755463\n",
      " ==> New best value..loss:0.5654050894812042 hm:0.7018530633050539\n",
      " ==> New best value..loss:0.5607852778014015 hm:0.7060902396509406\n",
      " ==> New best value..loss:0.5587664211497587 hm:0.7074289121087943\n",
      " ==> New best value..loss:0.5577714998348087 hm:0.7083144945937399\n",
      " ==> New best value..loss:0.5568423610107571 hm:0.7085469529304941\n",
      " ==> New best value..loss:0.555912034184325 hm:0.7110635623395146\n",
      " ==> New best value..loss:0.5523975719423855 hm:0.7180204079406166\n",
      " ==> New best value..loss:0.5521559949014702 hm:0.7189185415332783\n",
      " ==> New best value..loss:0.5447886650468788 hm:0.7221433194566033\n",
      " ==> New best value..loss:0.5379791855812073 hm:0.7276289670286848\n",
      " ==> New best value..loss:0.5349078756921432 hm:0.728400545942171\n",
      " ==> New best value..loss:0.5340657748428046 hm:0.7299529635182945\n",
      " ==> New best value..loss:0.5325239949366626 hm:0.7308204205408299\n",
      " ==> New best value..loss:0.5305273971136879 hm:0.731012375588671\n",
      " ==> New best value..loss:0.5303051372369131 hm:0.7335659810894091\n",
      " ==> New best value..loss:0.526288686429753 hm:0.7363443863578537\n",
      " ==> New best value..loss:0.5249982832693586 hm:0.73942784019265\n",
      " ==> New best value..loss:0.5244218718771841 hm:0.7407189214809928\n",
      "BEST SCORE:  0.7407189214809928\n",
      "TRAINING TOOK:  552  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6029468356416776 hm:0.5747645231647882\n",
      " ==> New best value..loss:0.6028406471014023 hm:0.6416665143217694\n",
      " ==> New best value..loss:0.5902030370556391 hm:0.6477777222024111\n",
      " ==> New best value..loss:0.5899068461014674 hm:0.656509372431127\n",
      " ==> New best value..loss:0.5891034700549566 hm:0.6606030474774952\n",
      " ==> New best value..loss:0.5817783274329625 hm:0.6734317067852589\n",
      " ==> New best value..loss:0.5756483169702383 hm:0.6879234134609122\n",
      " ==> New best value..loss:0.5680663740405669 hm:0.6952386351146554\n",
      " ==> New best value..loss:0.5647840247704432 hm:0.7004940113505682\n",
      " ==> New best value..loss:0.5619637140860925 hm:0.7011437399191632\n",
      " ==> New best value..loss:0.5614980040834501 hm:0.7014345493649353\n",
      " ==> New best value..loss:0.5596185744954989 hm:0.708462391726585\n",
      " ==> New best value..loss:0.5576907281692212 hm:0.7089582456487434\n",
      " ==> New best value..loss:0.5567543088243558 hm:0.7134806233946581\n",
      " ==> New best value..loss:0.5531005412340164 hm:0.7156720242874243\n",
      " ==> New best value..loss:0.5459410296036646 hm:0.7161999710606097\n",
      " ==> New best value..loss:0.5376447221407523 hm:0.724952229681629\n",
      " ==> New best value..loss:0.5340336400728959 hm:0.7275180061973672\n",
      " ==> New best value..loss:0.5309236445105993 hm:0.7323528707833467\n",
      " ==> New best value..loss:0.5262363673402712 hm:0.7330464966762543\n",
      " ==> New best value..loss:0.5254126265645027 hm:0.7376430537808455\n",
      " ==> New best value..loss:0.5201956773033509 hm:0.7395993688555662\n",
      " ==> New best value..loss:0.5192155299278406 hm:0.7448494305325347\n",
      " ==> New best value..loss:0.5104928698677283 hm:0.7481997524878732\n",
      " ==> New best value..loss:0.5073262069087762 hm:0.7496548306972182\n",
      " ==> New best value..loss:0.5048291780627691 hm:0.7521205116118113\n",
      " ==> New best value..loss:0.5045985419016618 hm:0.7551598541394583\n",
      " ==> New best value..loss:0.5045733990577551 hm:0.7555792543919395\n",
      " ==> New best value..loss:0.5010636787001903 hm:0.7619947034186886\n",
      " ==> New best value..loss:0.49925870448350906 hm:0.7634017431605478\n",
      " ==> New best value..loss:0.4919098506753261 hm:0.7638602091826726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.4915426493837283 hm:0.7643927879595057\n",
      " ==> New best value..loss:0.48961145889300567 hm:0.7657019144730779\n",
      " ==> New best value..loss:0.4860831338625688 hm:0.7678971583032422\n",
      " ==> New best value..loss:0.4827446026297716 hm:0.7718059190553199\n",
      " ==> New best value..loss:0.48230829949562365 hm:0.7726253244346873\n",
      "BEST SCORE:  0.7726253244346873\n",
      "TRAINING TOOK:  555  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6093855422735214 hm:0.5761128699562006\n",
      " ==> New best value..loss:0.6089081960916519 hm:0.5824308801167848\n",
      " ==> New best value..loss:0.6046192353963852 hm:0.5959818661121121\n",
      " ==> New best value..loss:0.6022622060775756 hm:0.6558760261412725\n",
      " ==> New best value..loss:0.5901980954408645 hm:0.6771517822205327\n",
      " ==> New best value..loss:0.5787377482652665 hm:0.6827774659138983\n",
      " ==> New best value..loss:0.5655543148517609 hm:0.6837479788915406\n",
      " ==> New best value..loss:0.5653776717185974 hm:0.6849837767552344\n",
      " ==> New best value..loss:0.5652387148141861 hm:0.6922785377004972\n",
      " ==> New best value..loss:0.5649502503871918 hm:0.6967809758388026\n",
      " ==> New best value..loss:0.56076191842556 hm:0.6990930790510888\n",
      " ==> New best value..loss:0.5528947740793229 hm:0.7008282495565216\n",
      " ==> New best value..loss:0.5521609461307526 hm:0.7085814505273875\n",
      " ==> New best value..loss:0.5470606362819672 hm:0.7112022406053672\n",
      " ==> New best value..loss:0.5443501478433609 hm:0.7128403131861563\n",
      " ==> New best value..loss:0.5425484770536423 hm:0.7131457993837482\n",
      " ==> New best value..loss:0.5424461430311203 hm:0.7181942805904622\n",
      " ==> New best value..loss:0.5396381717920303 hm:0.7204492843094269\n",
      " ==> New best value..loss:0.5374905508756638 hm:0.7242016858126896\n",
      " ==> New best value..loss:0.5346057862043381 hm:0.72579560925463\n",
      " ==> New best value..loss:0.5309111052751541 hm:0.7302954950221836\n",
      " ==> New best value..loss:0.5306285279989242 hm:0.7317852436376737\n",
      " ==> New best value..loss:0.530423315167427 hm:0.7344208595545308\n",
      " ==> New best value..loss:0.5256965154409409 hm:0.7357409474148998\n",
      " ==> New best value..loss:0.5216557067632676 hm:0.7359615845393273\n",
      " ==> New best value..loss:0.5182363268733025 hm:0.7390704737676385\n",
      "BEST SCORE:  0.7390704737676385\n",
      "TRAINING TOOK:  545  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5986877305834901 hm:0.5763171438972647\n",
      " ==> New best value..loss:0.5985476631744235 hm:0.5976228934049728\n",
      " ==> New best value..loss:0.5976401818733589 hm:0.6132812762691071\n",
      " ==> New best value..loss:0.594348867149914 hm:0.662874767865372\n",
      " ==> New best value..loss:0.5797601944091273 hm:0.675804513774966\n",
      " ==> New best value..loss:0.5721778670946757 hm:0.6789767379732583\n",
      " ==> New best value..loss:0.5706505588456696 hm:0.6825624749770055\n",
      " ==> New best value..loss:0.5690860123026604 hm:0.6857705195738653\n",
      " ==> New best value..loss:0.5688872202938678 hm:0.6907581831440034\n",
      " ==> New best value..loss:0.5679087007746977 hm:0.6916404288370979\n",
      " ==> New best value..loss:0.566271551099478 hm:0.6967454955203285\n",
      " ==> New best value..loss:0.5653031836537754 hm:0.6977842659230055\n",
      " ==> New best value..loss:0.5630461766439325 hm:0.6980551664320308\n",
      " ==> New best value..loss:0.5622437111302918 hm:0.702200563085954\n",
      " ==> New best value..loss:0.558390703271417 hm:0.7051866252720917\n",
      " ==> New best value..loss:0.5568337551518983 hm:0.7073558899643193\n",
      " ==> New best value..loss:0.5525840596825469 hm:0.7106192813404505\n",
      " ==> New best value..loss:0.5502338064651863 hm:0.713587474847774\n",
      " ==> New best value..loss:0.5488236569890789 hm:0.7163489771175978\n",
      " ==> New best value..loss:0.5479484591998306 hm:0.7211621768580071\n",
      " ==> New best value..loss:0.5456290011312447 hm:0.7236663306422979\n",
      " ==> New best value..loss:0.5451406287211998 hm:0.7246698352416527\n",
      " ==> New best value..loss:0.5450278532271292 hm:0.7303326129761134\n",
      " ==> New best value..loss:0.5343376392242956 hm:0.734168522263884\n",
      " ==> New best value..loss:0.5341025655176125 hm:0.7344387206686168\n",
      " ==> New best value..loss:0.5295914674506468 hm:0.7356083954205672\n",
      " ==> New best value..loss:0.5269947624674031 hm:0.7372630301525805\n",
      " ==> New best value..loss:0.5238684567750669 hm:0.7411918691401452\n",
      "BEST SCORE:  0.7411918691401452\n",
      "TRAINING TOOK:  544  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.617918886244297 hm:0.5946999037871874\n",
      " ==> New best value..loss:0.6133042040925759 hm:0.6015071294068901\n",
      " ==> New best value..loss:0.6076001152396202 hm:0.6296682488224015\n",
      " ==> New best value..loss:0.6032643862641774 hm:0.6569944241173128\n",
      " ==> New best value..loss:0.5990518944767805 hm:0.6677913704028164\n",
      " ==> New best value..loss:0.5895683599206117 hm:0.675534676611017\n",
      " ==> New best value..loss:0.5890367082678355 hm:0.6765100887127357\n",
      " ==> New best value..loss:0.581466175042666 hm:0.6827026958959521\n",
      " ==> New best value..loss:0.5755145331987968 hm:0.6862134484594535\n",
      " ==> New best value..loss:0.5669228463218763 hm:0.6908338372160092\n",
      " ==> New best value..loss:0.5657387203895129 hm:0.6923204490725017\n",
      " ==> New best value..loss:0.5612315959655322 hm:0.693964953406852\n",
      " ==> New best value..loss:0.5583530016816579 hm:0.6980015861665673\n",
      " ==> New best value..loss:0.5577776122551698 hm:0.7032585600661516\n",
      " ==> New best value..loss:0.5555870710657194 hm:0.7079194236995546\n",
      " ==> New best value..loss:0.5525756919613252 hm:0.7096173608126051\n",
      " ==> New best value..loss:0.5502689016553072 hm:0.7101368418267974\n",
      " ==> New best value..loss:0.5476764085201117 hm:0.7126181382476215\n",
      " ==> New best value..loss:0.5437530668882223 hm:0.714307591859513\n",
      " ==> New best value..loss:0.5418328362015578 hm:0.7155932897931988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5375837253836485 hm:0.7190166329448551\n",
      " ==> New best value..loss:0.536826932659516 hm:0.7214185680276752\n",
      " ==> New best value..loss:0.5341767886510262 hm:0.721862488494713\n",
      " ==> New best value..loss:0.5333187161729886 hm:0.7219428448982784\n",
      " ==> New best value..loss:0.5284135685517237 hm:0.7259034642677824\n",
      " ==> New best value..loss:0.5273823142051697 hm:0.7262171214686987\n",
      " ==> New best value..loss:0.5268515528967748 hm:0.7265244947614443\n",
      " ==> New best value..loss:0.5246145020310695 hm:0.7276755040966844\n",
      " ==> New best value..loss:0.5238546883830657 hm:0.7286185501633328\n",
      " ==> New best value..loss:0.5200646138535097 hm:0.7299409347415913\n",
      " ==> New best value..loss:0.5198436714708805 hm:0.7303436181071417\n",
      " ==> New best value..loss:0.5180088482224025 hm:0.7327990323745917\n",
      " ==> New best value..loss:0.5160361872269557 hm:0.7359619728656522\n",
      " ==> New best value..loss:0.5109162680231608 hm:0.7368764189853687\n",
      " ==> New best value..loss:0.5093016893817828 hm:0.7413979756443981\n",
      " ==> New best value..loss:0.5092165040282103 hm:0.7431704450207011\n",
      "BEST SCORE:  0.7431704450207011\n",
      "TRAINING TOOK:  540  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6013952268629658 hm:0.6076530943932504\n",
      " ==> New best value..loss:0.5876162429245151 hm:0.6739736733967174\n",
      " ==> New best value..loss:0.5831357733327516 hm:0.6771540704724166\n",
      " ==> New best value..loss:0.5591939085600327 hm:0.6923937043665813\n",
      " ==> New best value..loss:0.5519069354144894 hm:0.7055454939672985\n",
      " ==> New best value..loss:0.544130452433411 hm:0.7128653641624954\n",
      " ==> New best value..loss:0.543767158474241 hm:0.7183266821413982\n",
      " ==> New best value..loss:0.5393881031445095 hm:0.7226026135735852\n",
      " ==> New best value..loss:0.537805226384377 hm:0.7264167070193465\n",
      " ==> New best value..loss:0.5260724930130706 hm:0.730880980898975\n",
      " ==> New best value..loss:0.5238943245946145 hm:0.7379610414524214\n",
      " ==> New best value..loss:0.5156023660484625 hm:0.738837935505645\n",
      " ==> New best value..loss:0.5092830937735888 hm:0.738942526610603\n",
      " ==> New best value..loss:0.5056540193606396 hm:0.7436707092981855\n",
      " ==> New best value..loss:0.5018704743409643 hm:0.7463799314933276\n",
      " ==> New best value..loss:0.5006897425164982 hm:0.7499629556108872\n",
      " ==> New best value..loss:0.49690029754930615 hm:0.7504984693221106\n",
      " ==> New best value..loss:0.4934380413318167 hm:0.7541630921153393\n",
      " ==> New best value..loss:0.4899811261162466 hm:0.7552242437640796\n",
      " ==> New best value..loss:0.48901566315670403 hm:0.7568167270728707\n",
      " ==> New best value..loss:0.4883893241687697 hm:0.7592155374352373\n",
      "BEST SCORE:  0.7592155374352373\n",
      "TRAINING TOOK:  529  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6032769300189673 hm:0.5923939837587228\n",
      " ==> New best value..loss:0.6025123251419441 hm:0.6354429211668451\n",
      " ==> New best value..loss:0.5908936010856255 hm:0.669965055987121\n",
      " ==> New best value..loss:0.580652255637973 hm:0.67721172674092\n",
      " ==> New best value..loss:0.5757813366020427 hm:0.6794388090558107\n",
      " ==> New best value..loss:0.5729183420246723 hm:0.6933402657564094\n",
      " ==> New best value..loss:0.5664576204384074 hm:0.6958566065814128\n",
      " ==> New best value..loss:0.5576159369711783 hm:0.6997232794104343\n",
      " ==> New best value..loss:0.5503912702494976 hm:0.7047019597788193\n",
      " ==> New best value..loss:0.5500174842628778 hm:0.7100196352619208\n",
      " ==> New best value..loss:0.5449036862335953 hm:0.7128900944282501\n",
      " ==> New best value..loss:0.542093414886325 hm:0.7155161304851082\n",
      " ==> New best value..loss:0.539524573321436 hm:0.7183566826006716\n",
      " ==> New best value..loss:0.5392342729895723 hm:0.719076275304817\n",
      " ==> New best value..loss:0.5379955897144243 hm:0.7233832683946743\n",
      " ==> New best value..loss:0.5334233664998821 hm:0.7240808699221483\n",
      " ==> New best value..loss:0.5322208667502684 hm:0.7251955809964266\n",
      " ==> New best value..loss:0.530951094977996 hm:0.7274351082512035\n",
      " ==> New best value..loss:0.530274254434249 hm:0.7302816431117857\n",
      " ==> New best value..loss:0.5260976108850217 hm:0.7324650007221979\n",
      " ==> New best value..loss:0.5256862938404083 hm:0.7325099024691125\n",
      " ==> New best value..loss:0.5212009625107634 hm:0.7357724679475727\n",
      " ==> New best value..loss:0.51879048464345 hm:0.7388825621333035\n",
      " ==> New best value..loss:0.5165098175114277 hm:0.7403858960986325\n",
      " ==> New best value..loss:0.5145025037082971 hm:0.7414896609965469\n",
      " ==> New best value..loss:0.5124746146155339 hm:0.7432164934210637\n",
      " ==> New best value..loss:0.5101193610359641 hm:0.7451635125014386\n",
      " ==> New best value..loss:0.5083810313075197 hm:0.745326894761876\n",
      " ==> New best value..loss:0.5080212179352256 hm:0.7466110181761956\n",
      " ==> New best value..loss:0.5051361065284878 hm:0.7509923410414338\n",
      " ==> New best value..loss:0.5034177285783431 hm:0.751068723424705\n",
      " ==> New best value..loss:0.5026331719230203 hm:0.752733660287672\n",
      " ==> New best value..loss:0.4955448823816636 hm:0.7564589314615998\n",
      " ==> New best value..loss:0.4928495141805387 hm:0.7584527928339229\n",
      " ==> New best value..loss:0.4923378877780017 hm:0.7599571508224715\n",
      " ==> New best value..loss:0.4905005170434129 hm:0.7639621706070673\n",
      " ==> New best value..loss:0.4879268799342361 hm:0.7640203929699739\n",
      " ==> New best value..loss:0.4877486059478685 hm:0.7644050635647782\n",
      " ==> New best value..loss:0.487220391923306 hm:0.7658519201973087\n",
      " ==> New best value..loss:0.4851711591084798 hm:0.7659930036964014\n",
      " ==> New best value..loss:0.48354925244462255 hm:0.7685399828102235\n",
      "BEST SCORE:  0.7685399828102235\n",
      "TRAINING TOOK:  548  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5991226510674346 hm:0.5737108749264055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5911907577047161 hm:0.6304442926820454\n",
      " ==> New best value..loss:0.58684340820593 hm:0.6686098873396304\n",
      " ==> New best value..loss:0.5801714138657439 hm:0.6749808298897476\n",
      " ==> New best value..loss:0.5787744703246098 hm:0.6802785691097817\n",
      " ==> New best value..loss:0.5696338122966242 hm:0.6828592182861964\n",
      " ==> New best value..loss:0.56845082079663 hm:0.6884579387284943\n",
      " ==> New best value..loss:0.5630422205317254 hm:0.6966055994305942\n",
      " ==> New best value..loss:0.5554468783677793 hm:0.7021340268243257\n",
      " ==> New best value..loss:0.5527137664018893 hm:0.705216095903801\n",
      " ==> New best value..loss:0.5525000294049581 hm:0.7062887259799541\n",
      " ==> New best value..loss:0.5507882745826945 hm:0.7069786596146325\n",
      " ==> New best value..loss:0.5501721624065848 hm:0.7140779225267266\n",
      " ==> New best value..loss:0.5435029557522606 hm:0.7164532494143955\n",
      " ==> New best value..loss:0.541797127793817 hm:0.7205949870454352\n",
      " ==> New best value..loss:0.5378181688925799 hm:0.7220468911161922\n",
      " ==> New best value..loss:0.5361358634397095 hm:0.7225667626399043\n",
      " ==> New best value..loss:0.531945101186341 hm:0.7244469860167104\n",
      " ==> New best value..loss:0.5292516046879339 hm:0.7283349165744993\n",
      " ==> New best value..loss:0.5273287775469762 hm:0.7320731562192715\n",
      " ==> New best value..loss:0.5262782924315509 hm:0.7329349186414149\n",
      " ==> New best value..loss:0.5261492951243532 hm:0.733780074537413\n",
      " ==> New best value..loss:0.5188509295968449 hm:0.7350599885152898\n",
      " ==> New best value..loss:0.5179316161894331 hm:0.7351963431460505\n",
      " ==> New best value..loss:0.51626236298505 hm:0.7370375671222913\n",
      " ==> New best value..loss:0.5121518279991898 hm:0.7384726643263719\n",
      " ==> New best value..loss:0.5108847413577285 hm:0.7436130042111292\n",
      " ==> New best value..loss:0.5056119771564708 hm:0.7466186010169431\n",
      " ==> New best value..loss:0.5002797748528275 hm:0.7468671852431166\n",
      " ==> New best value..loss:0.49931179892783073 hm:0.7521855015003954\n",
      " ==> New best value..loss:0.49859903606713984 hm:0.7525332785581876\n",
      " ==> New best value..loss:0.495736091744666 hm:0.7551696754902845\n",
      " ==> New best value..loss:0.49461842810406403 hm:0.7563209088493597\n",
      " ==> New best value..loss:0.4881911873817444 hm:0.756646869134129\n",
      "BEST SCORE:  0.756646869134129\n",
      "TRAINING TOOK:  558  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5980082908097435 hm:0.5901442823838502\n",
      " ==> New best value..loss:0.592912011871151 hm:0.6320758406388538\n",
      " ==> New best value..loss:0.5801484824395647 hm:0.6720716602075717\n",
      " ==> New best value..loss:0.5658725757224887 hm:0.675945083374388\n",
      " ==> New best value..loss:0.562586880197712 hm:0.6828851650576848\n",
      " ==> New best value..loss:0.5584840581697577 hm:0.6915507711884159\n",
      " ==> New best value..loss:0.5550863690236035 hm:0.6924316803610917\n",
      " ==> New best value..loss:0.5537978393190047 hm:0.7007535593836034\n",
      " ==> New best value..loss:0.547666012656455 hm:0.7025758355812621\n",
      " ==> New best value..loss:0.546830767509984 hm:0.7035945974133331\n",
      " ==> New best value..loss:0.545046888145746 hm:0.7040764251802403\n",
      " ==> New best value..loss:0.5434905857432122 hm:0.7101541657464637\n",
      " ==> New best value..loss:0.5398005469172609 hm:0.7130480441816193\n",
      " ==> New best value..loss:0.5378623230784547 hm:0.7145991185513357\n",
      " ==> New best value..loss:0.5343890248560438 hm:0.7197402552961233\n",
      " ==> New best value..loss:0.5341667065433428 hm:0.7200175558994639\n",
      " ==> New best value..loss:0.5306095358203439 hm:0.7231476216481291\n",
      " ==> New best value..loss:0.5254250051928502 hm:0.7283237704809824\n",
      " ==> New best value..loss:0.5244698612128987 hm:0.7299820655062107\n",
      " ==> New best value..loss:0.5206431115374845 hm:0.7315690711001744\n",
      " ==> New best value..loss:0.5190515407160217 hm:0.7341381813348551\n",
      " ==> New best value..loss:0.5157265166441599 hm:0.7374620249716736\n",
      " ==> New best value..loss:0.5114366803683487 hm:0.7419859831639614\n",
      " ==> New best value..loss:0.5107800948853586 hm:0.7451020230024944\n",
      " ==> New best value..loss:0.506541113058726 hm:0.7487344226272462\n",
      " ==> New best value..loss:0.5063057927524343 hm:0.7499139245005805\n",
      " ==> New best value..loss:0.49900176361495374 hm:0.7524798933777345\n",
      " ==> New best value..loss:0.4973057233819775 hm:0.7559207979713254\n",
      "BEST SCORE:  0.7559207979713254\n",
      "TRAINING TOOK:  561  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6149847066402435 hm:0.5966093011637112\n",
      " ==> New best value..loss:0.6146173530817032 hm:0.5989551262914685\n",
      " ==> New best value..loss:0.6138148307800293 hm:0.6081629236258471\n",
      " ==> New best value..loss:0.6111902475357056 hm:0.6369863170093526\n",
      " ==> New best value..loss:0.60738410115242 hm:0.6586422761170265\n",
      " ==> New best value..loss:0.5920534843206405 hm:0.6769194934525121\n",
      " ==> New best value..loss:0.5746153455972671 hm:0.6864356984158441\n",
      " ==> New best value..loss:0.5739580637216568 hm:0.6872986650336662\n",
      " ==> New best value..loss:0.5652732682228089 hm:0.6934709479999377\n",
      " ==> New best value..loss:0.559670392870903 hm:0.7022325174360041\n",
      " ==> New best value..loss:0.5564792281389237 hm:0.7088810651442337\n",
      " ==> New best value..loss:0.5554915910959244 hm:0.7127429116077226\n",
      " ==> New best value..loss:0.5521154111623764 hm:0.7147499809847887\n",
      " ==> New best value..loss:0.5498577761650085 hm:0.7157018671459143\n",
      " ==> New best value..loss:0.5487125509977341 hm:0.7158522917878031\n",
      " ==> New best value..loss:0.5477592462301254 hm:0.7176569370336291\n",
      " ==> New best value..loss:0.5456629741191864 hm:0.7201668633828631\n",
      " ==> New best value..loss:0.5434230464696884 hm:0.7215293678725785\n",
      " ==> New best value..loss:0.5419697719812393 hm:0.7234192382278762\n",
      " ==> New best value..loss:0.5406495147943496 hm:0.7242765847590465\n",
      " ==> New best value..loss:0.5394949597120285 hm:0.7243888644905041\n",
      " ==> New best value..loss:0.5385161066055297 hm:0.7265289122069841\n",
      " ==> New best value..loss:0.5339408028125763 hm:0.7319782957395754\n",
      " ==> New best value..loss:0.5318499684333802 hm:0.7324380603571433\n",
      " ==> New best value..loss:0.5286042439937592 hm:0.7360066873413846\n",
      " ==> New best value..loss:0.5252817034721374 hm:0.7380529195851688\n",
      " ==> New best value..loss:0.5246627324819565 hm:0.7407682632021614\n",
      " ==> New best value..loss:0.5196183723211288 hm:0.7411580545635964\n",
      " ==> New best value..loss:0.5179827159643173 hm:0.7421705329403422\n",
      " ==> New best value..loss:0.5155478847026825 hm:0.7448372624175978\n",
      " ==> New best value..loss:0.5147412490844726 hm:0.7449314556594646\n",
      " ==> New best value..loss:0.5127405470609665 hm:0.7449532665799387\n",
      " ==> New best value..loss:0.5112647849321366 hm:0.7495890385929306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.505802455842495 hm:0.7516053377629965\n",
      " ==> New best value..loss:0.5052155131101608 hm:0.7570744962403495\n",
      " ==> New best value..loss:0.5049281787872314 hm:0.7574267735721522\n",
      " ==> New best value..loss:0.5037231487035752 hm:0.7585834114601144\n",
      " ==> New best value..loss:0.5035664474964142 hm:0.7590138500387359\n",
      "BEST SCORE:  0.7590138500387359\n",
      "TRAINING TOOK:  543  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6130154121596858 hm:0.5995107452128892\n",
      " ==> New best value..loss:0.6117162344590673 hm:0.6001776838989135\n",
      " ==> New best value..loss:0.6115469072224959 hm:0.6114503930294151\n",
      " ==> New best value..loss:0.610080139816932 hm:0.6173419118822524\n",
      " ==> New best value..loss:0.6069143740635998 hm:0.6535823063518778\n",
      " ==> New best value..loss:0.5998290720975624 hm:0.6566107064944617\n",
      " ==> New best value..loss:0.586565836982907 hm:0.6706129542749639\n",
      " ==> New best value..loss:0.5839104449973916 hm:0.6734318777562132\n",
      " ==> New best value..loss:0.5796098281752389 hm:0.6871181181468858\n",
      " ==> New best value..loss:0.5775592456448753 hm:0.6886315535130774\n",
      " ==> New best value..loss:0.573759803794465 hm:0.6915092997717547\n",
      " ==> New best value..loss:0.5717066762582311 hm:0.693131234174541\n",
      " ==> New best value..loss:0.5670466434280828 hm:0.6962623384595056\n",
      " ==> New best value..loss:0.5660285527976054 hm:0.6965310001303598\n",
      " ==> New best value..loss:0.5651116989693552 hm:0.700884573673188\n",
      " ==> New best value..loss:0.5645667027752355 hm:0.7039988127483232\n",
      " ==> New best value..loss:0.5643990208517831 hm:0.707305309886368\n",
      " ==> New best value..loss:0.5614538412049132 hm:0.7093760928766583\n",
      " ==> New best value..loss:0.5578561768216906 hm:0.7113030838500158\n",
      " ==> New best value..loss:0.5566777806237059 hm:0.7145691907408741\n",
      " ==> New best value..loss:0.5543132531193068 hm:0.7154039011192598\n",
      " ==> New best value..loss:0.5490529660908681 hm:0.716865955678962\n",
      " ==> New best value..loss:0.5483247294740857 hm:0.7189842881940357\n",
      " ==> New best value..loss:0.5483178085875962 hm:0.7198536289695519\n",
      " ==> New best value..loss:0.5446581531245753 hm:0.7256904931019477\n",
      " ==> New best value..loss:0.5427225597624509 hm:0.7259797657171173\n",
      " ==> New best value..loss:0.5406586314147374 hm:0.7261468339692241\n",
      " ==> New best value..loss:0.5392980598053843 hm:0.7266528328041566\n",
      " ==> New best value..loss:0.5363718102563102 hm:0.7313790450590569\n",
      " ==> New best value..loss:0.5346885860528586 hm:0.7319422819004755\n",
      " ==> New best value..loss:0.5333678885450903 hm:0.733867742329491\n",
      " ==> New best value..loss:0.5316084662698349 hm:0.7356949231278582\n",
      " ==> New best value..loss:0.5300839723281141 hm:0.7358042008308755\n",
      " ==> New best value..loss:0.529968039607102 hm:0.7358398648383018\n",
      " ==> New best value..loss:0.5273216512967955 hm:0.7366907591121147\n",
      " ==> New best value..loss:0.5226836502552032 hm:0.7435945439227758\n",
      " ==> New best value..loss:0.5183297159536829 hm:0.7451397939243065\n",
      " ==> New best value..loss:0.516423448076788 hm:0.7459434602029609\n",
      " ==> New best value..loss:0.5145570191572297 hm:0.7475348546397019\n",
      "BEST SCORE:  0.7475348546397019\n",
      "TRAINING TOOK:  549  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6135160648822784 hm:0.5714042120206829\n",
      " ==> New best value..loss:0.6134800845384598 hm:0.584009502563172\n",
      " ==> New best value..loss:0.6130200105905533 hm:0.594180723958095\n",
      " ==> New best value..loss:0.612186576128006 hm:0.6189641766662766\n",
      " ==> New best value..loss:0.611330344080925 hm:0.6196861008161583\n",
      " ==> New best value..loss:0.601707963347435 hm:0.6702961893511356\n",
      " ==> New best value..loss:0.594258902668953 hm:0.6826615338508647\n",
      " ==> New best value..loss:0.5773655730485916 hm:0.6854569109738915\n",
      " ==> New best value..loss:0.573314236998558 hm:0.688997234974905\n",
      " ==> New best value..loss:0.5708708548545838 hm:0.6913739404814597\n",
      " ==> New best value..loss:0.5622157794237137 hm:0.6962053852067639\n",
      " ==> New best value..loss:0.5606078225374221 hm:0.6977236529477041\n",
      " ==> New best value..loss:0.5593404823541641 hm:0.7021149818738087\n",
      " ==> New best value..loss:0.5571779817342758 hm:0.7022937043535405\n",
      " ==> New best value..loss:0.5567425429821015 hm:0.7060384913717495\n",
      " ==> New best value..loss:0.5540200531482696 hm:0.7117989957555964\n",
      " ==> New best value..loss:0.5533413189649582 hm:0.7127999428869967\n",
      " ==> New best value..loss:0.5514096677303314 hm:0.7139863062264735\n",
      " ==> New best value..loss:0.55102430164814 hm:0.7170956954786727\n",
      " ==> New best value..loss:0.550737538933754 hm:0.7176223789563312\n",
      " ==> New best value..loss:0.5489788520336151 hm:0.7182840798336886\n",
      " ==> New best value..loss:0.5467969566583634 hm:0.7201917044086552\n",
      " ==> New best value..loss:0.5456628787517548 hm:0.7204936136541876\n",
      " ==> New best value..loss:0.5431730151176453 hm:0.7213522853317826\n",
      " ==> New best value..loss:0.5416146177053451 hm:0.7219557868053749\n",
      " ==> New best value..loss:0.5411976855993271 hm:0.7248034194686371\n",
      " ==> New best value..loss:0.541157842874527 hm:0.7255390826024609\n",
      " ==> New best value..loss:0.5372000586986542 hm:0.7278447310987632\n",
      " ==> New best value..loss:0.5353967779874802 hm:0.7281611719047996\n",
      " ==> New best value..loss:0.5322539073228836 hm:0.730276534712866\n",
      " ==> New best value..loss:0.531817477941513 hm:0.7318793666022464\n",
      "BEST SCORE:  0.7318793666022464\n",
      "TRAINING TOOK:  534  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6202971321694991 hm:0.5741903901234993\n",
      " ==> New best value..loss:0.619557366067288 hm:0.583701998304802\n",
      " ==> New best value..loss:0.6189319970561009 hm:0.591170904224372\n",
      " ==> New best value..loss:0.6186661550811693 hm:0.6164781719507741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.6173283194794374 hm:0.6319110501454002\n",
      " ==> New best value..loss:0.6161053916987251 hm:0.6346504385884927\n",
      " ==> New best value..loss:0.611694839070825 hm:0.6365247556132794\n",
      " ==> New best value..loss:0.6070449784690258 hm:0.6482174543943255\n",
      " ==> New best value..loss:0.5978666649145239 hm:0.6618523233351885\n",
      " ==> New best value..loss:0.5945307308552312 hm:0.6688939618356432\n",
      " ==> New best value..loss:0.5879619711754369 hm:0.671498769928214\n",
      " ==> New best value..loss:0.5808253755756453 hm:0.6831038552512255\n",
      " ==> New best value..loss:0.5735766700669831 hm:0.6839257609195633\n",
      " ==> New best value..loss:0.5706337491671244 hm:0.6877229954399505\n",
      " ==> New best value..loss:0.5698679784933726 hm:0.6890546838321376\n",
      " ==> New best value..loss:0.568306656444774 hm:0.6924146968240382\n",
      " ==> New best value..loss:0.5674521630885554 hm:0.6966853023715699\n",
      " ==> New best value..loss:0.5646897186251247 hm:0.69985043512728\n",
      " ==> New best value..loss:0.5626907050609589 hm:0.7003260829984173\n",
      " ==> New best value..loss:0.5619955273235545 hm:0.7035830899737882\n",
      " ==> New best value..loss:0.5609418124544854 hm:0.7041391876449394\n",
      " ==> New best value..loss:0.5600150771000806 hm:0.7047455899277768\n",
      " ==> New best value..loss:0.5588976869396135 hm:0.7059937296414897\n",
      " ==> New best value..loss:0.558054573395673 hm:0.707268165702307\n",
      " ==> New best value..loss:0.5577138890238369 hm:0.7077458356671765\n",
      " ==> New best value..loss:0.553486602563484 hm:0.7125020641044021\n",
      " ==> New best value..loss:0.5523311191914129 hm:0.7136644333794258\n",
      " ==> New best value..loss:0.5517512641701043 hm:0.7180537617250926\n",
      " ==> New best value..loss:0.548723525276371 hm:0.7192237298351387\n",
      " ==> New best value..loss:0.5481029035998326 hm:0.7192638414245386\n",
      " ==> New best value..loss:0.54758859557264 hm:0.7197753107139627\n",
      " ==> New best value..loss:0.5473931256462546 hm:0.7217006890159066\n",
      " ==> New best value..loss:0.5431599996837915 hm:0.7236320125751178\n",
      " ==> New best value..loss:0.5405583282311758 hm:0.7246878490314074\n",
      " ==> New best value..loss:0.5387700877937616 hm:0.7286248341841863\n",
      " ==> New best value..loss:0.5383510396761053 hm:0.728704867091945\n",
      " ==> New best value..loss:0.5373926145188949 hm:0.732943651592679\n",
      " ==> New best value..loss:0.5353980835746316 hm:0.734494184377921\n",
      " ==> New best value..loss:0.5344739462815079 hm:0.7365836287363761\n",
      " ==> New best value..loss:0.5332241391434389 hm:0.7371486686897211\n",
      " ==> New best value..loss:0.5310054561671089 hm:0.7376356486326104\n",
      " ==> New best value..loss:0.5306059718132019 hm:0.7381131517786419\n",
      " ==> New best value..loss:0.52816875074424 hm:0.7402339937324678\n",
      " ==> New best value..loss:0.5255050226753833 hm:0.7429156539960913\n",
      "BEST SCORE:  0.7429156539960913\n",
      "TRAINING TOOK:  533  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5898218069757734 hm:0.5880866747794923\n",
      " ==> New best value..loss:0.5895930224535416 hm:0.5972205320666112\n",
      " ==> New best value..loss:0.5895889948825447 hm:0.5995407216639486\n",
      " ==> New best value..loss:0.5860659321960138 hm:0.6600888659847678\n",
      " ==> New best value..loss:0.5834241217496444 hm:0.6667245613962876\n",
      " ==> New best value..loss:0.5772582760878971 hm:0.6678573602651773\n",
      " ==> New best value..loss:0.5762507739115734 hm:0.6710678652871334\n",
      " ==> New best value..loss:0.5717600486716445 hm:0.677696389394782\n",
      " ==> New best value..loss:0.5645017350206569 hm:0.6789275835138728\n",
      " ==> New best value..loss:0.5603602577228936 hm:0.6823040797290021\n",
      " ==> New best value..loss:0.5598782075911152 hm:0.6827721265813604\n",
      " ==> New best value..loss:0.554149471375407 hm:0.6840388158154008\n",
      " ==> New best value..loss:0.5538789538704619 hm:0.688708761725081\n",
      " ==> New best value..loss:0.5538345307719951 hm:0.6927443962411359\n",
      " ==> New best value..loss:0.5520184265107525 hm:0.6970512006128354\n",
      " ==> New best value..loss:0.547301148273507 hm:0.6972000290073387\n",
      " ==> New best value..loss:0.5455638370951827 hm:0.7040683292663878\n",
      " ==> New best value..loss:0.5429964065551758 hm:0.7046949277137508\n",
      " ==> New best value..loss:0.5418062909525267 hm:0.7071538004543427\n",
      " ==> New best value..loss:0.5413235219157472 hm:0.7110599075921594\n",
      " ==> New best value..loss:0.5399327977579467 hm:0.7110905964413972\n",
      " ==> New best value..loss:0.5398442617484501 hm:0.7122566161125162\n",
      " ==> New best value..loss:0.5381699253101738 hm:0.7162176239092934\n",
      " ==> New best value..loss:0.5368117756989538 hm:0.7188770142127565\n",
      " ==> New best value..loss:0.5362204191636066 hm:0.7203780252499903\n",
      " ==> New best value..loss:0.5352326065910106 hm:0.7232331096428976\n",
      " ==> New best value..loss:0.5342630141851853 hm:0.7258322709454694\n",
      " ==> New best value..loss:0.531409387077604 hm:0.7264168698450244\n",
      " ==> New best value..loss:0.5257060412241488 hm:0.7278587242121458\n",
      " ==> New best value..loss:0.5246694489401214 hm:0.7303437871611599\n",
      " ==> New best value..loss:0.5231361316174877 hm:0.7305139204476899\n",
      " ==> New best value..loss:0.5220266756962757 hm:0.733972675837485\n",
      " ==> New best value..loss:0.5212044916590866 hm:0.7356104783305337\n",
      "BEST SCORE:  0.7356104783305337\n",
      "TRAINING TOOK:  531  s\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'de_attention'\n",
    "\n",
    "nn_deattention = []\n",
    "scores_deattention = []\n",
    "\n",
    "alpha_de_lst = [1, 0.5, 0.05]\n",
    "beta_de_lst = [1, 0.5, 0.05]\n",
    "lr_lst = [1e-4, 7e-5]\n",
    "\n",
    "params_dict['batch_size'] = 30\n",
    "\n",
    "for lr in lr_lst: \n",
    "    params_dict['lr'] = lr    \n",
    "    \n",
    "    for alpha_de in alpha_de_lst:\n",
    "        params_dict['alpha_de'] = alpha_de\n",
    "\n",
    "        for beta_de in beta_de_lst:\n",
    "            params_dict['beta_de'] = beta_de \n",
    "\n",
    "            print('='*80)\n",
    "            d_start = datetime.now() \n",
    "            best_score, classifier = do_training( df_in1, params_dict, criterion)\n",
    "            nn_deattention.append(classifier)\n",
    "            scores_deattention.append(best_score)\n",
    "\n",
    "            print('BEST SCORE: ', best_score)\n",
    "            print('TRAINING TOOK: ', ( datetime.now() - d_start ).seconds, ' s'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 0.5\n",
    "\n",
    "# alpha = 0.5\n",
    "# beta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(scores_softmax)[::-1][:3]\n",
    "np.argsort(scores_tanh)[::-1][:3]\n",
    "np.argsort(scores_deattention)[::-1][ : 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict['lr'] = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Softmax attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5412338563040191 hm:0.730445521381458\n",
      " ==> New best value..loss:0.5218880918680453 hm:0.7528477105833071\n",
      " ==> New best value..loss:0.5055333042846006 hm:0.7657710690944849\n",
      " ==> New best value..loss:0.5038266146884245 hm:0.7659613803091914\n",
      " ==> New best value..loss:0.5000223868033465 hm:0.7697282419349677\n",
      " ==> New best value..loss:0.49788349224071876 hm:0.7725601389717935\n",
      " ==> New best value..loss:0.49392979986527386 hm:0.7732124469504126\n",
      " ==> New best value..loss:0.49284276892157164 hm:0.7770352216704832\n",
      " ==> New best value..loss:0.4907572871329738 hm:0.7777377722184333\n",
      " ==> New best value..loss:0.49015331443618326 hm:0.7822663674526094\n",
      " ==> New best value..loss:0.48863863711263616 hm:0.7838340493462058\n",
      " ==> New best value..loss:0.4857511876844892 hm:0.7855730724892341\n",
      " ==> New best value..loss:0.4834512600711748 hm:0.7882475437660583\n",
      " ==> New best value..loss:0.4794478918991837 hm:0.7931925536540411\n",
      " ==> New best value..loss:0.4794403694423975 hm:0.7945600157866731\n",
      " ==> New best value..loss:0.4719764169524698 hm:0.8002678462016278\n",
      " ==> New best value..loss:0.46916210534525854 hm:0.805024773682019\n",
      " ==> New best value..loss:0.464695859189127 hm:0.807171389813636\n",
      " ==> New best value..loss:0.46452776590983075 hm:0.8109459224642093\n",
      " ==> New best value..loss:0.45919936544754925 hm:0.8118891793946877\n",
      " ==> New best value..loss:0.4531147702067506 hm:0.8134744662074483\n",
      " ==> New best value..loss:0.4492243697830275 hm:0.8146635606179806\n",
      " ==> New best value..loss:0.44720469502841725 hm:0.8188476841253449\n",
      " ==> New best value..loss:0.44412941558688296 hm:0.8225151331346721\n",
      " ==> New best value..loss:0.4381243615758185 hm:0.8280499941632897\n",
      " ==> New best value..loss:0.43618950802905887 hm:0.8287290104154171\n",
      " ==> New best value..loss:0.43445640159588234 hm:0.8298597352620883\n",
      " ==> New best value..loss:0.43436621217166677 hm:0.8302213663018889\n",
      " ==> New best value..loss:0.4260183642892277 hm:0.8355083257907349\n",
      " ==> New best value..loss:0.4229080118969375 hm:0.8355641650116112\n",
      " ==> New best value..loss:0.4201214988442028 hm:0.8358892694788266\n",
      " ==> New best value..loss:0.41794343672546685 hm:0.8391599601624704\n",
      " ==> New best value..loss:0.4145678752193264 hm:0.8400520363058108\n",
      " ==> New best value..loss:0.41118067298449723 hm:0.8427764455304712\n",
      " ==> New best value..loss:0.41008466832778034 hm:0.8429427500931189\n",
      " ==> New best value..loss:0.40731990980167015 hm:0.8453242664122465\n",
      " ==> New best value..loss:0.40431783479802746 hm:0.849591799642094\n",
      " ==> New best value..loss:0.3954284083025128 hm:0.8560503843784255\n",
      " ==> New best value..loss:0.39017657438913983 hm:0.856400623781444\n",
      " ==> New best value..loss:0.38601864319221646 hm:0.8590509452983324\n",
      " ==> New best value..loss:0.38527944128887326 hm:0.8591947971979457\n",
      " ==> New best value..loss:0.3841487405931248 hm:0.8603237817569256\n",
      " ==> New best value..loss:0.3818007342371286 hm:0.8646928955078013\n",
      " ==> New best value..loss:0.38008856744158503 hm:0.8649781526602633\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'softmax'\n",
    "best_score, nn_soft = do_training( df_in1, params_dict, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_soft.to('cpu')\n",
    "classifer.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(classifer, df_test, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tanh Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CoDA (Quasi- Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test module 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifer = nn_deattention[10]\n",
    "# classifer.to('cpu')\n",
    "# classifer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n"
     ]
    }
   ],
   "source": [
    "ind = random.randint(0, len(df_test))\n",
    "print(ind)\n",
    "df_test['sent_org'][ind] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['봄이랑 어울리는 색이에요', '당근과 단감의 중간색 착색 핑크가 아니라 주황색입니다', '추천 해요']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 442\n",
    "# ['봄이랑 어울리는 색이에요', '당근과 단감의 중간색 착색 핑크가 아니라 주황색입니다', '추천 해요']\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 1, \n",
      "Predicted: 0.493\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Attention Visualization</h2><p><span style=\"margin:1px; padding:2px; background-color: #f7fbff\"><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp봄&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp이랑&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp어울리는&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #edf4fc\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp이에요&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #f7fbff\"><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp당근&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp과&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp단감&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp의&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp중간&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f5f9fe\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f4f9fe\">&nbsp착색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f5fafe\">&nbsp핑크&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp가&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f2f8fd\">&nbsp아니라&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f1f7fd\">&nbsp주황색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f1f7fd\">&nbsp입니다&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #f7fbff\"><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp추천&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f3f8fe\">&nbsp해&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp요&nbsp</span></span><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifer = nn_softmax[1]\n",
    "classifer.to('cpu')\n",
    "classifer.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(classifer, df_test, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_doc, x_s, g_t = get_test_sample(df_test, ind)\n",
    "sig_out, a_it, a_i = classifer(x_s)\n",
    "\n",
    "#    docs, doc_lengths, sent_lengths = x_s\n",
    "\n",
    "# get attention values with the trained model\n",
    "#  v, a_it, a_i = han_encoder(docs, doc_lengths, sent_lengths)\n",
    "\n",
    "# get raw data\n",
    "raw_sent = df_test.iloc[ind, :]['sent_org']\n",
    "raw_sent_tok = [ okt.pos(elem) for elem in raw_sent ]\n",
    "processed_raw = [ list(zip(*raw_sent_tok[i]))[0] for i in range(len(raw_sent_tok))]\n",
    "processed_raw = [ list(i) for i in processed_raw] \n",
    "x = len(processed_raw)\n",
    "y = max( [len(i) for i in processed_raw] )\n",
    "update_att = np.zeros((x, y)).tolist()\n",
    "\n",
    "# fill in word attentions\n",
    "wd_atts = a_it.data.tolist()[0]\n",
    "diff = y - len(wd_atts[0])\n",
    "wd_atts = [ i + np.zeros(diff).tolist() for i in wd_atts ]\n",
    "\n",
    "# update attention\n",
    "for s, z in enumerate(zip(orig_doc, processed_raw)):\n",
    "    cnt = 0\n",
    "    for wd, val in enumerate(z[1]): \n",
    "        if val in z[0]:\n",
    "            update_att[s][wd] = wd_atts[s][cnt]  \n",
    "            cnt += 1\n",
    "\n",
    "# Vosia;oze\n",
    "words = processed_raw\n",
    "sent_score = a_i.tolist()[0]\n",
    "word_score = update_att# update_att.tolist()[0]\n",
    "result = \"<h2>Attention Visualization</h2>\"\n",
    "for sent, word_att, sent_att in zip(words, word_score, sent_score):\n",
    "    result += map_sentence_to_color( sent, word_att, sent_att)\n",
    "\n",
    "\n",
    "display(HTML(result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sentence_to_color( sent, word_att, sent_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencemap = matplotlib.cm.get_cmap('Blues')\n",
    "wordmap = matplotlib.cm.get_cmap('Blues')\n",
    "\n",
    "words, scores, sent_score = sent, word_att, sent_att \n",
    "\n",
    "result = '<p><span style=\"margin:1px; padding:2px; background-color: {}\">'\\\n",
    "   .format(matplotlib.colors.rgb2hex(sentencemap(sent_score)[:3]))\n",
    "template = '<span class = \"barcode\"; style =\"color: black; background-color: {}\">{}</span>'\n",
    "for word, score in zip(words, scores):\n",
    "    color = matplotlib.colors.rgb2hex(wordmap(score)[:3])\n",
    "    result += template.format(color, '&nbsp' + word + '&nbsp')\n",
    "result += '</span><p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_att(classifier, df_test, ind, random_st = 21 ):\n",
    "    orig_doc, x_s, g_t = get_test_sample(df_test, ind)\n",
    "    sig_out, a_it, a_i = classifier(x_s)\n",
    "    \n",
    "#    docs, doc_lengths, sent_lengths = x_s\n",
    "    \n",
    "    # get attention values with the trained model\n",
    "  #  v, a_it, a_i = han_encoder(docs, doc_lengths, sent_lengths)\n",
    "    \n",
    "    # get raw data\n",
    "    raw_sent = df_test.iloc[ind, :]['sent_org']\n",
    "    raw_sent_tok = [ okt.pos(elem) for elem in raw_sent ]\n",
    "    processed_raw = [ list(zip(*raw_sent_tok[i]))[0] for i in range(len(raw_sent_tok))]\n",
    "    processed_raw = [ list(i) for i in processed_raw] \n",
    "    x = len(processed_raw)\n",
    "    y = max( [len(i) for i in processed_raw] )\n",
    "    update_att = np.zeros((x, y)).tolist()\n",
    "    \n",
    "    # fill in word attentions\n",
    "    wd_atts = a_it.data.tolist()[0]\n",
    "    diff = y - len(wd_atts[0])\n",
    "    wd_atts = [ i + np.zeros(diff).tolist() for i in wd_atts ]\n",
    "    \n",
    "    # update attention\n",
    "    for s, z in enumerate(zip(orig_doc, processed_raw)):\n",
    "        cnt = 0\n",
    "        for wd, val in enumerate(z[1]): \n",
    "            if val in z[0]:\n",
    "                update_att[s][wd] = wd_atts[s][cnt]  \n",
    "                cnt += 1\n",
    "    \n",
    "    # Vosia;oze\n",
    "    words = processed_raw\n",
    "    sent_score = a_i.tolist()[0]\n",
    "    word_score = update_att# update_att.tolist()[0]\n",
    "    result = \"<h2>Attention Visualization</h2>\"\n",
    "    for sent, word_att, sent_att in zip(words, word_score, sent_score):\n",
    "        result += map_sentence_to_color( sent, word_att, sent_att)\n",
    "\n",
    "    display(HTML(result))\n",
    "\n",
    "    with open(f'test_ind{ind}.html', 'w') as f:\n",
    "        f.write(result)\n",
    "    return result, a_it, a_i, g_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "params_dict['batch_size'] = 4\n",
    "#df_train, df_test = train_test_split(df_in)\n",
    "dl1 = HanDataLoader(HAN_dataset(df_train), params_dict)\n",
    "#han_dat = HAN_dataset(df_in)\n",
    "sample_x_s = iter(dl1).__next__()\n",
    "#x_s = get_x_s(sample_x_s)\n",
    "#docs, doc_lengths, sent_lengths = x_s\n",
    "docs, doc_lengths, sent_lengths = sample_x_s[0], sample_x_s[2], sample_x_s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "word_gru_h_dim = 100\n",
    "word_gru_n_layers = 2\n",
    "sent_gru_h_dim = 100\n",
    "sent_gru_n_layers = 2\n",
    "word_att_dim = 200\n",
    "sent_att_dim = 200\n",
    "dropval = 0.2\n",
    "dropgru_s = 0.2\n",
    "dropgru_w = 0.2\n",
    "\n",
    "sent_gru = nn.GRU( 2 * word_gru_h_dim, sent_gru_h_dim, \n",
    "                                num_layers = sent_gru_n_layers, batch_first = True,\n",
    "                                bidirectional = True, dropout = dropgru_s)\n",
    "sent_layer_norm = nn.LayerNorm( 2 * sent_gru_h_dim, elementwise_affine= True)\n",
    "sent_attention = nn.Linear(2 * sent_gru_h_dim, sent_att_dim)\n",
    "sentence_context_vector = nn.Linear(sent_att_dim, 1, bias = False)\n",
    "\n",
    "        # word\n",
    "word_gru = nn.GRU(embed_dim, word_gru_h_dim, num_layers = word_gru_n_layers, \n",
    "                              batch_first = True, bidirectional = True, dropout = dropgru_w)\n",
    "word_layer_norm = nn.LayerNorm( 2*word_gru_h_dim, elementwise_affine=True)\n",
    "word_attention = nn.Linear( 2 * word_gru_h_dim, word_att_dim)\n",
    "word_context_vector = nn.Linear(word_att_dim, 1, bias = False)\n",
    "#word_context_vector = nn.Linear(word_att_dim, word_att_dim, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_x_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_s = get_x_s(sample_x_s)\n",
    "#docs, doc_lengths, sent_lengths = x_s\n",
    "docs, doc_lengths, sent_lengths = sample_x_s[0], sample_x_s[2], sample_x_s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Packing\n",
    "## 1-1 reorder\n",
    "doc_lengths, doc_perm_idx = doc_lengths.sort(dim = 0, descending = True)\n",
    "docs = docs[doc_perm_idx]\n",
    "sent_lengths = sent_lengths[doc_perm_idx]\n",
    "\n",
    "## 1-2 packing\n",
    "packed_sents = pack_padded_sequence(docs, lengths=doc_lengths.tolist(), batch_first = True)\n",
    "packed_sent_lengths = pack_padded_sequence( sent_lengths, lengths= doc_lengths.tolist(), \n",
    "                                          batch_first=True)\n",
    "valid_bsz_sent = packed_sents.batch_sizes\n",
    "\n",
    "# 2. Word Attention\n",
    "## 2-1. packing input data\n",
    "sents, sent_lengths = packed_sents.data, packed_sent_lengths.data\n",
    "# reorder\n",
    "sent_lengths, sent_perm_idx = sent_lengths.sort(dim = 0, descending = True)\n",
    "sents = sents[sent_perm_idx]\n",
    "\n",
    "# embedding done already, do dropout\n",
    "#sents = self.Dropout(sents)\n",
    "packed_words = pack_padded_sequence( sents, lengths = sent_lengths.tolist(), batch_first=True)\n",
    "valid_bsz_word = packed_words.batch_sizes\n",
    "\n",
    "##2-2 NN\n",
    "# hidden layer\n",
    "h_it, _ = word_gru( packed_words )\n",
    "h_it_normed = word_layer_norm(h_it.data)\n",
    "h_it_pad, _ = pad_packed_sequence ( h_it, batch_first = True )\n",
    "# attention module\n",
    "u_it = torch.tanh( word_attention( h_it_normed.data ))\n",
    "u_it_cv = word_context_vector( u_it ).squeeze(1)\n",
    "\n",
    "## ATTENTION\n",
    "key = u_it\n",
    "query = u_it_cv \n",
    "cv_weight = word_context_vector.weight\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "N_vec = -beta * abs(cv_weight - u_it)\n",
    "N_vec = N_vec.sum(dim = 1, keepdim = True)\n",
    "\n",
    "N_vec_pad, _ = pad_packed_sequence( PackedSequence(N_vec, valid_bsz_word), batch_first = True)\n",
    "value_mask = (1 * (N_vec_pad != 0))\n",
    "N_mean = torch.sum(N_vec_pad, 1) / sent_lengths.unsqueeze(1)\n",
    "\n",
    "N_meaned = N_vec_pad - value_mask*N_mean.unsqueeze(2)\n",
    "\n",
    "E_vec = alpha * torch.matmul( key, cv_weight.T )\n",
    "E_vec_pad, _ = pad_packed_sequence( PackedSequence(E_vec, valid_bsz_word), batch_first = True)\n",
    "E_mean = torch.sum(E_vec_pad, 1) / sent_lengths.unsqueeze(1)\n",
    "\n",
    "E_meaned = E_vec_pad - value_mask*E_mean.unsqueeze(2)\n",
    "A_it = torch.tanh( E_meaned ) * torch.sigmoid( N_meaned)\n",
    "A_it = A_it.squeeze(2)\n",
    "\n",
    "###########\n",
    "\n",
    "s_i = ( h_it_pad * A_it.unsqueeze(2)).sum(dim = 1)\n",
    "\n",
    "_, sent_unperm_idx = sent_perm_idx.sort(dim = 0, descending = False)\n",
    "s_i = s_i[sent_unperm_idx] \n",
    "a_it = A_it[sent_unperm_idx] \n",
    "\n",
    "sents, word_att_weights = s_i, a_it\n",
    "#sents = self.Dropout(sents)\n",
    "\n",
    "# 3-1 NN\n",
    "# hidden layer\n",
    "h_i, _ = sent_gru(PackedSequence(sents, valid_bsz_sent))\n",
    "h_i_normed = sent_layer_norm( h_i.data )\n",
    "h_i_pad, _ = pad_packed_sequence( h_i, batch_first = True )\n",
    "\n",
    "# context mapping\n",
    "u_i = torch.tanh( sent_attention( h_i_normed.data ))\n",
    "\n",
    "# calculate similarity\n",
    "u_i_cv = sentence_context_vector(u_i).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_i_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = u_i\n",
    "query = sentence_context_vector.weight\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "N_vec = -beta * abs(query - key)\n",
    "N_vec = N_vec.sum(dim = 1, keepdim = True)\n",
    "\n",
    "N_vec_pad, _ = pad_packed_sequence( PackedSequence(N_vec, valid_bsz_sent), batch_first = True)\n",
    "value_mask = (1 * (N_vec_pad != 0))\n",
    "N_mean = torch.sum(N_vec_pad, 1) / doc_lengths.unsqueeze(1)\n",
    "\n",
    "N_meaned = N_vec_pad - value_mask*N_mean.unsqueeze(2)\n",
    "\n",
    "E_vec = alpha * torch.matmul( key, query.T )\n",
    "E_vec_pad, _ = pad_packed_sequence( PackedSequence(E_vec, valid_bsz_sent), batch_first = True)\n",
    "E_mean = torch.sum(E_vec_pad, 1) / doc_lengths.unsqueeze(1)\n",
    "\n",
    "E_meaned = E_vec_pad - value_mask*E_mean.unsqueeze(2)\n",
    "A_i = torch.tanh( E_meaned ) * torch.sigmoid( N_meaned)\n",
    "A_i = A_i.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ( h_i_pad * A_i.unsqueeze(2)).sum(dim = 1)\n",
    "\n",
    "# 3-2 reorder\n",
    "word_att_weights, _ = pad_packed_sequence( PackedSequence( word_att_weights, valid_bsz_sent), \n",
    "                                         batch_first = True)\n",
    "_, doc_unperm_idx = doc_perm_idx.sort(dim = 0, descending = False)\n",
    "\n",
    "# 4. Final Output\n",
    "v = v[doc_unperm_idx] \n",
    "a_it = A_it[ doc_unperm_idx ] \n",
    "a_i = A_i[ doc_unperm_idx ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict['attention'] = 'de_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "han = ReviewHAN(params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl1 = HanDataLoader(HAN_dataset(df_train), params_dict)\n",
    "sample_x_s = iter(dl1).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, doc_lengths, sent_lengths = sample_x_s[0], sample_x_s[2], sample_x_s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, a_it, a_i = han(docs, doc_lengths, sent_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
