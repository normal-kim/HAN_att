{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_han import *\n",
    "from data_loader_han import * \n",
    "from data_process_han import *\n",
    "from test_module_han import *\n",
    "from train_han import * \n",
    "from utils_han import *\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:\n",
      " 1    2700\n",
      "0    2700\n",
      "Name: polarity, dtype: int64\n",
      "test_size:\n",
      " 1    300\n",
      "0    300\n",
      "Name: polarity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "with open('df_in.pkl', 'rb') as file:\n",
    "    df_in1 = pickle.load(file)\n",
    "\n",
    "df_train, df_test = train_test_split(df_in1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "\n",
    "params_dict['embed_dim'] = 100\n",
    "params_dict['word_gru_h_dim'] = 100\n",
    "params_dict['sent_gru_h_dim'] = 100\n",
    "params_dict['word_gru_n_layers'] = 2\n",
    "params_dict['sent_gru_n_layers'] = 2\n",
    "params_dict['word_att_dim'] = 200\n",
    "params_dict['sent_att_dim'] = 200\n",
    "params_dict['dropgru_s'] = 0.2 \n",
    "params_dict['dropgru_w'] = 0.2\n",
    "params_dict['dropval'] = 0.2\n",
    "\n",
    "params_dict['tan_a'] = 0.5\n",
    "params_dict['alpha_de'] = 0.5\n",
    "params_dict['beta_de'] = 1\n",
    "\n",
    "params_dict['batch_size'] = 30\n",
    "\n",
    "params_dict['fc1'] = 100\n",
    "params_dict['fc2'] = 20\n",
    "params_dict['drop_fc'] = 0.3\n",
    "params_dict['fc'] = create_fc(params_dict['fc1'],\n",
    "                              params_dict['fc2'], params_dict['drop_fc'])\n",
    "params_dict['epochs'] = 20 \n",
    "params_dict['output_size'] = 1 \n",
    "params_dict['lr'] = 7e-5\n",
    "params_dict['print_every'] = 39\n",
    "params_dict['clip_val'] = 1.5\n",
    "params_dict['attention'] = 'de_attention'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### experiment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_lst = [100, 160, 200] \n",
    "fc2_lst = [15, 30] \n",
    "dropval_lst = [0.1, 0.4] \n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. test softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 15, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6530902328399512 hm:0.6227720714204404\n",
      " ==> New best value..loss:0.6020962584477204 hm:0.6443930417603478\n",
      " ==> New best value..loss:0.5817971670856843 hm:0.686620683120366\n",
      " ==> New best value..loss:0.5616801340992634 hm:0.7238453454825321\n",
      " ==> New best value..loss:0.527322432742669 hm:0.7410731513415807\n",
      " ==> New best value..loss:0.5136758776811453 hm:0.7493519427678029\n",
      " ==> New best value..loss:0.5115373449829909 hm:0.7503448309772163\n",
      " ==> New best value..loss:0.5090382832747239 hm:0.7581169743620831\n",
      " ==> New best value..loss:0.5048960854227726 hm:0.758835774603993\n",
      " ==> New best value..loss:0.5006178892575778 hm:0.7623508917853247\n",
      " ==> New best value..loss:0.497215021115083 hm:0.7699001636393895\n",
      " ==> New best value..loss:0.49542754143476486 hm:0.7757505071431694\n",
      " ==> New best value..loss:0.4917902969397031 hm:0.7763141104459602\n",
      " ==> New best value..loss:0.48585974597013915 hm:0.7839721283757819\n",
      " ==> New best value..loss:0.47764853216134584 hm:0.7889305666081012\n",
      " ==> New best value..loss:0.47516478311557037 hm:0.7917907413198971\n",
      " ==> New best value..loss:0.47307599163972414 hm:0.7944827876262222\n",
      " ==> New best value..loss:0.4679173050591579 hm:0.7950983312678159\n",
      " ==> New best value..loss:0.46464550351867306 hm:0.7975177567023827\n",
      " ==> New best value..loss:0.46253771134294 hm:0.7980328663590207\n",
      " ==> New best value..loss:0.46215555473015857 hm:0.8045534032382515\n",
      " ==> New best value..loss:0.45388537588027805 hm:0.8045751750285037\n",
      " ==> New best value..loss:0.4531269703920071 hm:0.8078736822101084\n",
      " ==> New best value..loss:0.45302952711398786 hm:0.8109967050151697\n",
      " ==> New best value..loss:0.44860841906987703 hm:0.8118951337857206\n",
      " ==> New best value..loss:0.44403217560969865 hm:0.8130535807694608\n",
      " ==> New best value..loss:0.4423110310274821 hm:0.8153888633268502\n",
      " ==> New best value..loss:0.43958097982865113 hm:0.8169441128813055\n",
      " ==> New best value..loss:0.43819293924249136 hm:0.8187987532963173\n",
      " ==> New best value..loss:0.433171942543525 hm:0.8230104266218479\n",
      " ==> New best value..loss:0.4278889178083493 hm:0.8249835489117693\n",
      " ==> New best value..loss:0.4241836088208052 hm:0.8261576982318446\n",
      " ==> New best value..loss:0.42154354172257275 hm:0.8265883787006003\n",
      " ==> New best value..loss:0.42008915772804845 hm:0.8274956341217786\n",
      " ==> New best value..loss:0.41325929818245083 hm:0.8334361971413019\n",
      "BEST SCORE:  0.8334361971413019\n",
      "TRAINING TOOK:  247  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 15, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6711747312545776 hm:0.607538881641584\n",
      " ==> New best value..loss:0.60448237657547 hm:0.622534120184119\n",
      " ==> New best value..loss:0.5950011587142945 hm:0.6617041582068329\n",
      " ==> New best value..loss:0.5696035933494568 hm:0.7051230909585381\n",
      " ==> New best value..loss:0.5405776625871659 hm:0.7338633546184716\n",
      " ==> New best value..loss:0.5140693747997284 hm:0.7535947423597759\n",
      " ==> New best value..loss:0.5047105276584625 hm:0.7606469859769408\n",
      " ==> New best value..loss:0.5029634493589401 hm:0.7638446014519412\n",
      " ==> New best value..loss:0.5015419697761536 hm:0.7639598289505435\n",
      " ==> New best value..loss:0.5010914307832718 hm:0.766444945045118\n",
      " ==> New best value..loss:0.49760957300662995 hm:0.7678380316454375\n",
      " ==> New best value..loss:0.4920413565635681 hm:0.7709763070558628\n",
      " ==> New best value..loss:0.4896338367462158 hm:0.7752454037214104\n",
      " ==> New best value..loss:0.4842421120405197 hm:0.7767248936048297\n",
      " ==> New best value..loss:0.48199560821056364 hm:0.7798415660901226\n",
      " ==> New best value..loss:0.4804618537425995 hm:0.7814082215325308\n",
      " ==> New best value..loss:0.4773321640491486 hm:0.7830372678459816\n",
      " ==> New best value..loss:0.4762910455465317 hm:0.7894287819970875\n",
      " ==> New best value..loss:0.4711977380514145 hm:0.7929869685010041\n",
      " ==> New best value..loss:0.4630597084760666 hm:0.7956944798973494\n",
      " ==> New best value..loss:0.4567536735534668 hm:0.7975701194409087\n",
      " ==> New best value..loss:0.453687464594841 hm:0.8028781066851084\n",
      " ==> New best value..loss:0.4517297506332397 hm:0.8033736844908371\n",
      " ==> New best value..loss:0.4505982321500778 hm:0.8040434077053644\n",
      " ==> New best value..loss:0.4487926205992699 hm:0.8084560621687611\n",
      " ==> New best value..loss:0.447177195250988 hm:0.8105525991717925\n",
      " ==> New best value..loss:0.44583495080471036 hm:0.8117069472728892\n",
      " ==> New best value..loss:0.44330700397491457 hm:0.8128583353260287\n",
      " ==> New best value..loss:0.4361823868751526 hm:0.816571152594739\n",
      " ==> New best value..loss:0.4291958612203598 hm:0.8170399234631726\n",
      " ==> New best value..loss:0.42485842525959017 hm:0.8192800274842758\n",
      " ==> New best value..loss:0.4208002233505249 hm:0.821618650944227\n",
      " ==> New best value..loss:0.4200391983985901 hm:0.8241938486476866\n",
      " ==> New best value..loss:0.4167052894830704 hm:0.8284827971497928\n",
      " ==> New best value..loss:0.4114947259426117 hm:0.8340889801277585\n",
      " ==> New best value..loss:0.40790814489126204 hm:0.8355338365617694\n",
      " ==> New best value..loss:0.40627396702766416 hm:0.8362031437512721\n",
      " ==> New best value..loss:0.40100536406040194 hm:0.8387763255944699\n",
      " ==> New best value..loss:0.3940056198835373 hm:0.842203308800474\n",
      " ==> New best value..loss:0.3931815859675407 hm:0.8445976296301475\n",
      " ==> New best value..loss:0.3930922544002533 hm:0.8484333383512555\n",
      " ==> New best value..loss:0.3904800871014595 hm:0.8491151284964374\n",
      " ==> New best value..loss:0.3887613296508789 hm:0.851319606919436\n",
      " ==> New best value..loss:0.37967191487550733 hm:0.8518946857339256\n",
      "BEST SCORE:  0.8518946857339256\n",
      "TRAINING TOOK:  238  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 30, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6872625022518392 hm:0.5443411948730205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5984147051159217 hm:0.6286383719033645\n",
      " ==> New best value..loss:0.5819223985380056 hm:0.6662856242285715\n",
      " ==> New best value..loss:0.5636214924101927 hm:0.7041059744715393\n",
      " ==> New best value..loss:0.5372360804859473 hm:0.7357826286828542\n",
      " ==> New best value..loss:0.5159118631664588 hm:0.743821276105155\n",
      " ==> New best value..loss:0.5117243114782839 hm:0.7454186972592636\n",
      " ==> New best value..loss:0.5113284052634726 hm:0.7505504423986272\n",
      " ==> New best value..loss:0.5048616668399499 hm:0.7523027551535798\n",
      " ==> New best value..loss:0.5021822470791486 hm:0.7552095358356561\n",
      " ==> New best value..loss:0.49838875811927175 hm:0.7589289318197187\n",
      " ==> New best value..loss:0.49616597136672663 hm:0.7607873947526075\n",
      " ==> New best value..loss:0.49054928580108953 hm:0.7663750397641844\n",
      " ==> New best value..loss:0.48933585140169883 hm:0.767085689084916\n",
      " ==> New best value..loss:0.48612719166035556 hm:0.7693666537579242\n",
      " ==> New best value..loss:0.48270112701824736 hm:0.7756652492148308\n",
      " ==> New best value..loss:0.4817809091538799 hm:0.7825221630362186\n",
      " ==> New best value..loss:0.47717353640770427 hm:0.7842019767232253\n",
      " ==> New best value..loss:0.4767644180327046 hm:0.7879291935994981\n",
      " ==> New best value..loss:0.47286352880147037 hm:0.7884405837172145\n",
      " ==> New best value..loss:0.47088832879553033 hm:0.7901285157410876\n",
      " ==> New best value..loss:0.4688846627060248 hm:0.7911812465157854\n",
      " ==> New best value..loss:0.466193752325311 hm:0.7950697404680993\n",
      " ==> New best value..loss:0.46126276619580325 hm:0.8014501273039727\n",
      " ==> New best value..loss:0.4560542514129561 hm:0.8022227772251516\n",
      " ==> New best value..loss:0.45526260320021184 hm:0.8028129995880182\n",
      " ==> New best value..loss:0.4526676493031638 hm:0.8046809701276463\n",
      " ==> New best value..loss:0.4498227445446715 hm:0.807259985204937\n",
      " ==> New best value..loss:0.44732904495025166 hm:0.8075454752327225\n",
      " ==> New best value..loss:0.4440697261265346 hm:0.808298843234024\n",
      " ==> New best value..loss:0.4434948767326316 hm:0.8093210242892365\n",
      " ==> New best value..loss:0.4415575940998233 hm:0.8110350142042181\n",
      " ==> New best value..loss:0.44099242103343106 hm:0.8130520177580605\n",
      " ==> New best value..loss:0.43398125135168736 hm:0.8164251682395511\n",
      " ==> New best value..loss:0.431091843210921 hm:0.8182384212393422\n",
      " ==> New best value..loss:0.4282988008795952 hm:0.824202187910015\n",
      " ==> New best value..loss:0.4239511669290309 hm:0.8261210099513216\n",
      " ==> New best value..loss:0.4206165452392734 hm:0.8275100982571306\n",
      " ==> New best value..loss:0.4197337524015076 hm:0.8306717714876048\n",
      " ==> New best value..loss:0.41514841695221105 hm:0.8320101681214241\n",
      " ==> New best value..loss:0.41322605129407375 hm:0.8322127605202203\n",
      " ==> New best value..loss:0.4129694651584236 hm:0.8349955503389969\n",
      " ==> New best value..loss:0.41036516154298974 hm:0.8374606884206167\n",
      " ==> New best value..loss:0.40514727697080494 hm:0.838779054312253\n",
      "BEST SCORE:  0.838779054312253\n",
      "TRAINING TOOK:  238  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 100, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=100, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6536764001846314 hm:0.6226940044001273\n",
      " ==> New best value..loss:0.610439623594284 hm:0.6519635783185921\n",
      " ==> New best value..loss:0.5885831129550934 hm:0.6908270776405128\n",
      " ==> New best value..loss:0.5701806843280792 hm:0.7143746243362734\n",
      " ==> New best value..loss:0.541705162525177 hm:0.734641178403218\n",
      " ==> New best value..loss:0.5302845954895019 hm:0.7460691394366402\n",
      " ==> New best value..loss:0.52595141351223 hm:0.7533084354195579\n",
      " ==> New best value..loss:0.518120943903923 hm:0.7570223890992585\n",
      " ==> New best value..loss:0.5179432243108749 hm:0.7594093338722552\n",
      " ==> New best value..loss:0.5145047849416733 hm:0.7624307254900274\n",
      " ==> New best value..loss:0.51064348757267 hm:0.7660951085769732\n",
      " ==> New best value..loss:0.50932059943676 hm:0.7713861662798243\n",
      " ==> New best value..loss:0.5011953485012054 hm:0.773346200847649\n",
      " ==> New best value..loss:0.4980292326211929 hm:0.7770405270512082\n",
      " ==> New best value..loss:0.49623075664043426 hm:0.7791374932971938\n",
      " ==> New best value..loss:0.4904199653863907 hm:0.7804911945676551\n",
      " ==> New best value..loss:0.48653790950775144 hm:0.7841855158245921\n",
      " ==> New best value..loss:0.482848202586174 hm:0.7902342418027746\n",
      " ==> New best value..loss:0.48271948754787447 hm:0.7954006110902508\n",
      " ==> New best value..loss:0.4729129135608673 hm:0.8007513050222637\n",
      " ==> New best value..loss:0.47148468136787414 hm:0.8008233280816346\n",
      " ==> New best value..loss:0.46943255007267 hm:0.8034124963644209\n",
      " ==> New best value..loss:0.46589938044548035 hm:0.8064411543864608\n",
      " ==> New best value..loss:0.46232068419456485 hm:0.8093998698010453\n",
      " ==> New best value..loss:0.4565715992450714 hm:0.810405918714526\n",
      " ==> New best value..loss:0.4542849859595299 hm:0.8112567312712796\n",
      " ==> New best value..loss:0.44929572343826296 hm:0.8141102158135708\n",
      " ==> New best value..loss:0.4470836618542671 hm:0.8152425478607166\n",
      " ==> New best value..loss:0.44526762545108794 hm:0.8183297271462735\n",
      " ==> New best value..loss:0.4426878452301025 hm:0.8190301438860751\n",
      " ==> New best value..loss:0.4365627981722355 hm:0.8201247161098472\n",
      " ==> New best value..loss:0.4350918561220169 hm:0.8242274814901277\n",
      " ==> New best value..loss:0.43084401190280913 hm:0.8258682900191295\n",
      " ==> New best value..loss:0.4307168421149254 hm:0.8261186759271899\n",
      " ==> New best value..loss:0.42955916047096254 hm:0.8292695021151001\n",
      " ==> New best value..loss:0.42815147250890734 hm:0.8300899742338395\n",
      " ==> New best value..loss:0.4248669824004173 hm:0.8314622478060295\n",
      " ==> New best value..loss:0.4216514030098915 hm:0.8333015889638489\n",
      " ==> New best value..loss:0.41784871637821197 hm:0.8405029020017147\n",
      " ==> New best value..loss:0.41401483714580534 hm:0.8465873569816784\n",
      " ==> New best value..loss:0.40332880437374113 hm:0.8475809406020819\n",
      "BEST SCORE:  0.8475809406020819\n",
      "TRAINING TOOK:  242  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 15, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6550415579010459 hm:0.6111825630824302\n",
      " ==> New best value..loss:0.6083035580083436 hm:0.6360441622936477\n",
      " ==> New best value..loss:0.5872871776421865 hm:0.6884988456994006\n",
      " ==> New best value..loss:0.5595342061098885 hm:0.7229196659699275\n",
      " ==> New best value..loss:0.5200911719425052 hm:0.756779721708488\n",
      " ==> New best value..loss:0.512239374366461 hm:0.7610124341190955\n",
      " ==> New best value..loss:0.5067964096864065 hm:0.7640649755799652\n",
      " ==> New best value..loss:0.4998207063067193 hm:0.7668238361891911\n",
      " ==> New best value..loss:0.4956738551457723 hm:0.7732913118221271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.48568378944022983 hm:0.7765300640809573\n",
      " ==> New best value..loss:0.48552821488941417 hm:0.7813593242924094\n",
      " ==> New best value..loss:0.48326856014775293 hm:0.7827215670859899\n",
      " ==> New best value..loss:0.4798414309819539 hm:0.7892028900970851\n",
      " ==> New best value..loss:0.4769187809205523 hm:0.7896886103916986\n",
      " ==> New best value..loss:0.4686136730745727 hm:0.791618641223685\n",
      " ==> New best value..loss:0.4642084316880095 hm:0.7946813102026751\n",
      " ==> New best value..loss:0.4621594594974144 hm:0.8016286601762537\n",
      " ==> New best value..loss:0.45866869652972503 hm:0.8025085009145473\n",
      " ==> New best value..loss:0.4561673075545068 hm:0.805725276919759\n",
      " ==> New best value..loss:0.44582407147276637 hm:0.8086549088553687\n",
      " ==> New best value..loss:0.4454115766520594 hm:0.8086644415980321\n",
      " ==> New best value..loss:0.44106509288152057 hm:0.8116431096957152\n",
      " ==> New best value..loss:0.4405072050936082 hm:0.8150890234094936\n",
      " ==> New best value..loss:0.4306328921925788 hm:0.8198466201643856\n",
      " ==> New best value..loss:0.4292560476882785 hm:0.8242851789155733\n",
      " ==> New best value..loss:0.42323944264767216 hm:0.8259985819165381\n",
      " ==> New best value..loss:0.41469747120258854 hm:0.8279562658005373\n",
      " ==> New best value..loss:0.40991517667676886 hm:0.8311256629248623\n",
      " ==> New best value..loss:0.40860577599675046 hm:0.8363005614397458\n",
      " ==> New best value..loss:0.4038521562721215 hm:0.8366094289428077\n",
      " ==> New best value..loss:0.3983372014527227 hm:0.8378957538835093\n",
      " ==> New best value..loss:0.3969145601286608 hm:0.8406299421475987\n",
      " ==> New best value..loss:0.3962608412200329 hm:0.841669010107562\n",
      " ==> New best value..loss:0.3934095685972887 hm:0.8437522154717118\n",
      " ==> New best value..loss:0.3871753589779723 hm:0.8438556881092697\n",
      "BEST SCORE:  0.8438556881092697\n",
      "TRAINING TOOK:  237  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 15, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6480992114543915 hm:0.622371237028165\n",
      " ==> New best value..loss:0.612699259519577 hm:0.6511013895732083\n",
      " ==> New best value..loss:0.5863311111927032 hm:0.6960078162131695\n",
      " ==> New best value..loss:0.5574065572023392 hm:0.7247028390735432\n",
      " ==> New best value..loss:0.5351092237234115 hm:0.7462675177974964\n",
      " ==> New best value..loss:0.5335481894016266 hm:0.7485950198645326\n",
      " ==> New best value..loss:0.5217798632383347 hm:0.7590172185240536\n",
      " ==> New best value..loss:0.5198928582668304 hm:0.7627249178058896\n",
      " ==> New best value..loss:0.5156230163574219 hm:0.7656774048945928\n",
      " ==> New best value..loss:0.5053130251169204 hm:0.7678107675948377\n",
      " ==> New best value..loss:0.501202175617218 hm:0.7766671528781608\n",
      " ==> New best value..loss:0.49357733249664304 hm:0.782377133225368\n",
      " ==> New best value..loss:0.49195988416671754 hm:0.7842487855898399\n",
      " ==> New best value..loss:0.48636712789535524 hm:0.7885535983201979\n",
      " ==> New best value..loss:0.47845384657382967 hm:0.794986318999523\n",
      " ==> New best value..loss:0.46765393316745757 hm:0.7997358923600463\n",
      " ==> New best value..loss:0.46089833170175554 hm:0.8007316719116819\n",
      " ==> New best value..loss:0.4606237933039665 hm:0.8052020699243749\n",
      " ==> New best value..loss:0.4579494398832321 hm:0.807248950486703\n",
      " ==> New best value..loss:0.45216918230056763 hm:0.8112520741868507\n",
      " ==> New best value..loss:0.4518143022060394 hm:0.8157455902752134\n",
      " ==> New best value..loss:0.4462032741308212 hm:0.8175013400182782\n",
      " ==> New best value..loss:0.44487117558717726 hm:0.8189706977720249\n",
      " ==> New best value..loss:0.44063944011926653 hm:0.8196338367910079\n",
      " ==> New best value..loss:0.4332344219088554 hm:0.8239640586576009\n",
      " ==> New best value..loss:0.4315842390060425 hm:0.8289763300465973\n",
      " ==> New best value..loss:0.42832172334194185 hm:0.8300025946531828\n",
      " ==> New best value..loss:0.42659672141075133 hm:0.8339833358795534\n",
      " ==> New best value..loss:0.41796708047389985 hm:0.8349447326012988\n",
      " ==> New best value..loss:0.4149830138683319 hm:0.836631524734102\n",
      " ==> New best value..loss:0.41354025691747665 hm:0.8388853883381796\n",
      " ==> New best value..loss:0.4124399098753929 hm:0.8414221386944574\n",
      " ==> New best value..loss:0.40698223292827607 hm:0.8444583852909704\n",
      " ==> New best value..loss:0.40602168560028074 hm:0.8452329483713158\n",
      " ==> New best value..loss:0.40527040988206864 hm:0.8488119684769146\n",
      " ==> New best value..loss:0.39825514137744905 hm:0.8496619779479718\n",
      " ==> New best value..loss:0.3967507517337799 hm:0.8545251811622872\n",
      "BEST SCORE:  0.8545251811622872\n",
      "TRAINING TOOK:  237  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 30, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6603206092236089 hm:0.6087513951411104\n",
      " ==> New best value..loss:0.6151684084359337 hm:0.6311227949615515\n",
      " ==> New best value..loss:0.5998022439433079 hm:0.6722957769236092\n",
      " ==> New best value..loss:0.5763021444573122 hm:0.6980318971604309\n",
      " ==> New best value..loss:0.5538810964892892 hm:0.7214899581938687\n",
      " ==> New best value..loss:0.5526354832976472 hm:0.7266285050808374\n",
      " ==> New best value..loss:0.5495951362684661 hm:0.728471235661604\n",
      " ==> New best value..loss:0.5439560769819746 hm:0.7347538209854264\n",
      " ==> New best value..loss:0.54229869445165 hm:0.7409839718354916\n",
      " ==> New best value..loss:0.5415646702635522 hm:0.7411015160287577\n",
      " ==> New best value..loss:0.5285768719280467 hm:0.748744189934506\n",
      " ==> New best value..loss:0.5266980353523704 hm:0.7510051189770203\n",
      " ==> New best value..loss:0.5243400832017263 hm:0.7522713653119351\n",
      " ==> New best value..loss:0.5224326942481247 hm:0.7577958530619958\n",
      " ==> New best value..loss:0.5181054718354169 hm:0.7605189155139637\n",
      " ==> New best value..loss:0.5148772994677225 hm:0.7637531656970765\n",
      " ==> New best value..loss:0.5138527236732782 hm:0.765919332812626\n",
      " ==> New best value..loss:0.5126445310957292 hm:0.7703018069176298\n",
      " ==> New best value..loss:0.5080004223421508 hm:0.7724813338881207\n",
      " ==> New best value..loss:0.5062199234962463 hm:0.7750545198431632\n",
      " ==> New best value..loss:0.5026213003724229 hm:0.7779110369558345\n",
      " ==> New best value..loss:0.49730083287930954 hm:0.7795237377794367\n",
      " ==> New best value..loss:0.4931963121189791 hm:0.7828281804530124\n",
      " ==> New best value..loss:0.4898650874109829 hm:0.7851040599774071\n",
      " ==> New best value..loss:0.48570086208044316 hm:0.7872183320242706\n",
      " ==> New best value..loss:0.47976895903839784 hm:0.7898554525113921\n",
      " ==> New best value..loss:0.47483253654311686 hm:0.7948246780960845\n",
      " ==> New best value..loss:0.47361835895800125 hm:0.7950565926810071\n",
      " ==> New best value..loss:0.4715159389318204 hm:0.7986279263308051\n",
      " ==> New best value..loss:0.46531618576423794 hm:0.8022307998208282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.4642558962691064 hm:0.8022794327648388\n",
      " ==> New best value..loss:0.4635326722088982 hm:0.8036705687402622\n",
      " ==> New best value..loss:0.4602990460162069 hm:0.8039899530860304\n",
      " ==> New best value..loss:0.4573768400678448 hm:0.8098461974705686\n",
      " ==> New best value..loss:0.4560995242174934 hm:0.8115788162745384\n",
      " ==> New best value..loss:0.45049624086595047 hm:0.8119576913224581\n",
      " ==> New best value..loss:0.44793426347713844 hm:0.8128241250796763\n",
      " ==> New best value..loss:0.446470847901176 hm:0.8130612128408634\n",
      " ==> New best value..loss:0.4459822429161446 hm:0.816442979303614\n",
      " ==> New best value..loss:0.4423145420995413 hm:0.8178335505525335\n",
      " ==> New best value..loss:0.4358934713344948 hm:0.8216294141857113\n",
      " ==> New best value..loss:0.4349305156399222 hm:0.8247132280117633\n",
      " ==> New best value..loss:0.43150214646376817 hm:0.8247811011881236\n",
      " ==> New best value..loss:0.4308576242012136 hm:0.8264072660188192\n",
      " ==> New best value..loss:0.42995215046639534 hm:0.8269387316382735\n",
      " ==> New best value..loss:0.42840079232758166 hm:0.8290978534972315\n",
      " ==> New best value..loss:0.4203281154235204 hm:0.8317925713136392\n",
      "BEST SCORE:  0.8317925713136392\n",
      "TRAINING TOOK:  234  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 160, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=160, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=160, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6694060909748077 hm:0.614384017843937\n",
      " ==> New best value..loss:0.6107885992527008 hm:0.6305571577481903\n",
      " ==> New best value..loss:0.5936910825967788 hm:0.6788938556384555\n",
      " ==> New best value..loss:0.5656278139352798 hm:0.7108128702399078\n",
      " ==> New best value..loss:0.536857932806015 hm:0.744820682299345\n",
      " ==> New best value..loss:0.5334532153606415 hm:0.7478186045124469\n",
      " ==> New best value..loss:0.5249460256099701 hm:0.7519435285009519\n",
      " ==> New best value..loss:0.5231372195482255 hm:0.7552177566352167\n",
      " ==> New best value..loss:0.5192506992816925 hm:0.7618139254851422\n",
      " ==> New best value..loss:0.5154095959663391 hm:0.7633537842958286\n",
      " ==> New best value..loss:0.5133607810735703 hm:0.7648934131969307\n",
      " ==> New best value..loss:0.5118557250499726 hm:0.7688026733517727\n",
      " ==> New best value..loss:0.5105209887027741 hm:0.7715476436152026\n",
      " ==> New best value..loss:0.5050565665960312 hm:0.7758100661517641\n",
      " ==> New best value..loss:0.5006428396701813 hm:0.778577730790356\n",
      " ==> New best value..loss:0.4993640917539597 hm:0.7828183443050103\n",
      " ==> New best value..loss:0.49489302217960357 hm:0.7839021026680355\n",
      " ==> New best value..loss:0.4905474925041199 hm:0.7877763214475739\n",
      " ==> New best value..loss:0.48940700948238375 hm:0.791332848576298\n",
      " ==> New best value..loss:0.4838472682237625 hm:0.7922023690387793\n",
      " ==> New best value..loss:0.4834016621112823 hm:0.7957571386851764\n",
      " ==> New best value..loss:0.47885959208011625 hm:0.7987096187941943\n",
      " ==> New best value..loss:0.4752071177959442 hm:0.7998499306852457\n",
      " ==> New best value..loss:0.4703592509031296 hm:0.800052552011609\n",
      " ==> New best value..loss:0.468289635181427 hm:0.8002063310209909\n",
      " ==> New best value..loss:0.46810452818870546 hm:0.8018276658095005\n",
      " ==> New best value..loss:0.46358774840831757 hm:0.8049436576969187\n",
      " ==> New best value..loss:0.4590634536743164 hm:0.8086663033687848\n",
      " ==> New best value..loss:0.456954750418663 hm:0.8105180755592697\n",
      " ==> New best value..loss:0.4530485528707504 hm:0.8113949552895723\n",
      " ==> New best value..loss:0.44793997406959535 hm:0.811779364923941\n",
      " ==> New best value..loss:0.4476386672258377 hm:0.8150988043434038\n",
      " ==> New best value..loss:0.4453649967908859 hm:0.8172688685407008\n",
      " ==> New best value..loss:0.4436512812972069 hm:0.8176765734394643\n",
      " ==> New best value..loss:0.4386860990524292 hm:0.822585832244288\n",
      " ==> New best value..loss:0.4365514436364174 hm:0.8244232432869817\n",
      " ==> New best value..loss:0.43119542896747587 hm:0.8260210920376883\n",
      " ==> New best value..loss:0.4269804334640503 hm:0.8271541718558889\n",
      " ==> New best value..loss:0.42427766740322115 hm:0.8272894093138634\n",
      " ==> New best value..loss:0.42340145975351334 hm:0.829224107029007\n",
      " ==> New best value..loss:0.4216813749074936 hm:0.8338524648827376\n",
      " ==> New best value..loss:0.4167197570204735 hm:0.8352191063184259\n",
      "BEST SCORE:  0.8352191063184259\n",
      "TRAINING TOOK:  233  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 15, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6479352864564634 hm:0.6380797072729423\n",
      " ==> New best value..loss:0.6030128311877158 hm:0.6656155791587507\n",
      " ==> New best value..loss:0.5809135115614125 hm:0.7079647031463453\n",
      " ==> New best value..loss:0.5510951461745244 hm:0.7356368267351276\n",
      " ==> New best value..loss:0.5145048621822806 hm:0.7547503538298401\n",
      " ==> New best value..loss:0.5080027849066491 hm:0.7586571034333269\n",
      " ==> New best value..loss:0.505221110348608 hm:0.764434107503924\n",
      " ==> New best value..loss:0.4989301311034782 hm:0.7674338538804186\n",
      " ==> New best value..loss:0.4956909833001156 hm:0.770580358257237\n",
      " ==> New best value..loss:0.49506936704411225 hm:0.7713517330162271\n",
      " ==> New best value..loss:0.48791686518519534 hm:0.7774975112671285\n",
      " ==> New best value..loss:0.48452476485102786 hm:0.7814541091873892\n",
      " ==> New best value..loss:0.48204320143250856 hm:0.7837794574446771\n",
      " ==> New best value..loss:0.4725717820373236 hm:0.7886951440370858\n",
      " ==> New best value..loss:0.4687137188864689 hm:0.793539549509879\n",
      " ==> New best value..loss:0.4629886775624518 hm:0.7975016306394412\n",
      " ==> New best value..loss:0.45775455061127157 hm:0.8007721893512888\n",
      " ==> New best value..loss:0.4560038803839216 hm:0.8072991064703506\n",
      " ==> New best value..loss:0.4469411507541058 hm:0.8129722442873774\n",
      " ==> New best value..loss:0.43710436306747735 hm:0.8138216907088192\n",
      " ==> New best value..loss:0.43221427763209624 hm:0.818203735726978\n",
      " ==> New best value..loss:0.4264303930834228 hm:0.8218284177333198\n",
      " ==> New best value..loss:0.4233551183167626 hm:0.8232360125454861\n",
      " ==> New best value..loss:0.4199640791790158 hm:0.8293323421655757\n",
      " ==> New best value..loss:0.4179042361530603 hm:0.831814833473988\n",
      " ==> New best value..loss:0.415446389539569 hm:0.8323873682530754\n",
      " ==> New best value..loss:0.4124097292329751 hm:0.833331355471742\n",
      " ==> New best value..loss:0.4088403874752568 hm:0.834662304390978\n",
      " ==> New best value..loss:0.40650266671881957 hm:0.8353204612219978\n",
      " ==> New best value..loss:0.4026438176047568 hm:0.8358519823534741\n",
      " ==> New best value..loss:0.40113018540775075 hm:0.8397041210185906\n",
      " ==> New best value..loss:0.3995099535175398 hm:0.8399760344253814\n",
      " ==> New best value..loss:0.3930376259719624 hm:0.8410523690302907\n",
      "BEST SCORE:  0.8410523690302907\n",
      "TRAINING TOOK:  246  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 15, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=15, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.6653191074728966 hm:0.6331857666679885\n",
      " ==> New best value..loss:0.5979626203576723 hm:0.6502835762885122\n",
      " ==> New best value..loss:0.5816616769880056 hm:0.6919041882968414\n",
      " ==> New best value..loss:0.5551579693953196 hm:0.7194168625461655\n",
      " ==> New best value..loss:0.5265154764056206 hm:0.746998098854891\n",
      " ==> New best value..loss:0.5205829069018364 hm:0.7498542558653251\n",
      " ==> New best value..loss:0.520446772997578 hm:0.7529414181173378\n",
      " ==> New best value..loss:0.5148810346921285 hm:0.7586474166380037\n",
      " ==> New best value..loss:0.5070524973173937 hm:0.7686409919366916\n",
      " ==> New best value..loss:0.5033651012927294 hm:0.7688564733885238\n",
      " ==> New best value..loss:0.49973851318160695 hm:0.7710348894543323\n",
      " ==> New best value..loss:0.49730021009842557 hm:0.7744536736874784\n",
      " ==> New best value..loss:0.49062127713114023 hm:0.7773388876722247\n",
      " ==> New best value..loss:0.49027921073138714 hm:0.7791913739148519\n",
      " ==> New best value..loss:0.48987832355002564 hm:0.7802282829725516\n",
      " ==> New best value..loss:0.48211179363230866 hm:0.7853713740084612\n",
      " ==> New best value..loss:0.4815564335634311 hm:0.7859397234420972\n",
      " ==> New best value..loss:0.4773839817692836 hm:0.7930868624770728\n",
      " ==> New best value..loss:0.47518622192243737 hm:0.7930951272907211\n",
      " ==> New best value..loss:0.46977332793176174 hm:0.7958326187660174\n",
      " ==> New best value..loss:0.46640726923942566 hm:0.8001927238130117\n",
      " ==> New best value..loss:0.46374954655766487 hm:0.8017661722257305\n",
      " ==> New best value..loss:0.4596860601256291 hm:0.8018924126249635\n",
      " ==> New best value..loss:0.4590273567785819 hm:0.8037396258358114\n",
      " ==> New best value..loss:0.4530679701517026 hm:0.8091568054812234\n",
      " ==> New best value..loss:0.45293219356487197 hm:0.8112477000151743\n",
      " ==> New best value..loss:0.45120026357471943 hm:0.8134137056843698\n",
      " ==> New best value..loss:0.4502080638582508 hm:0.8136127818859689\n",
      " ==> New best value..loss:0.445050610229373 hm:0.8138943635807202\n",
      " ==> New best value..loss:0.442835308611393 hm:0.8147025549421235\n",
      " ==> New best value..loss:0.44018045626580715 hm:0.818347338924598\n",
      " ==> New best value..loss:0.43759271036833525 hm:0.8208384741782702\n",
      " ==> New best value..loss:0.4330700517942508 hm:0.8219085118646208\n",
      " ==> New best value..loss:0.4272666967784365 hm:0.8262443352425317\n",
      " ==> New best value..loss:0.42551785117636126 hm:0.8262730644117056\n",
      " ==> New best value..loss:0.4219560641795397 hm:0.8282493236965597\n",
      " ==> New best value..loss:0.4199871827537815 hm:0.829942894198714\n",
      " ==> New best value..loss:0.4194849006210764 hm:0.835010301047468\n",
      " ==> New best value..loss:0.4162514600902796 hm:0.8359079987001591\n",
      " ==> New best value..loss:0.41519855087002117 hm:0.8361090091502771\n",
      " ==> New best value..loss:0.4122801451012492 hm:0.8362323853137743\n",
      " ==> New best value..loss:0.4077433692291379 hm:0.8433562966013228\n",
      " ==> New best value..loss:0.40393687536319095 hm:0.8467650616361009\n",
      " ==> New best value..loss:0.3971572431425254 hm:0.8495039057435292\n",
      " ==> New best value..loss:0.3957460783421993 hm:0.8505626553510389\n",
      " ==> New best value..loss:0.39478133898228407 hm:0.8513019046256456\n",
      " ==> New best value..loss:0.38673877622932196 hm:0.8517273913930795\n",
      "BEST SCORE:  0.8517273913930795\n",
      "TRAINING TOOK:  237  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.1, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.1, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6519576370716095 hm:0.6148286418272109\n",
      " ==> New best value..loss:0.6022430866956711 hm:0.6414788027891885\n",
      " ==> New best value..loss:0.5838501727581025 hm:0.6854070897831034\n",
      " ==> New best value..loss:0.56159019947052 hm:0.7154690838486674\n",
      " ==> New best value..loss:0.5265266156196594 hm:0.7456613830538638\n",
      " ==> New best value..loss:0.5178415924310684 hm:0.7525203206867781\n",
      " ==> New best value..loss:0.5123444849252701 hm:0.7604835325538235\n",
      " ==> New best value..loss:0.5097519159317017 hm:0.7617258764795328\n",
      " ==> New best value..loss:0.5061511898040771 hm:0.7644022573673216\n",
      " ==> New best value..loss:0.5022624337673187 hm:0.7676638863099347\n",
      " ==> New best value..loss:0.5008952069282532 hm:0.7720329385121646\n",
      " ==> New best value..loss:0.4978009402751923 hm:0.7780096828656512\n",
      " ==> New best value..loss:0.49047301411628724 hm:0.7813320916714181\n",
      " ==> New best value..loss:0.4882111144065857 hm:0.7819569791152762\n",
      " ==> New best value..loss:0.4869398540258408 hm:0.7835412078906826\n",
      " ==> New best value..loss:0.4843272787332535 hm:0.7853462707991763\n",
      " ==> New best value..loss:0.4840764886140823 hm:0.7878455896208502\n",
      " ==> New best value..loss:0.48138897597789765 hm:0.7893940819739851\n",
      " ==> New best value..loss:0.4786223363876343 hm:0.7898988098937869\n",
      " ==> New best value..loss:0.47813898682594297 hm:0.7914222769682215\n",
      " ==> New best value..loss:0.4772568887472153 hm:0.7921025035602185\n",
      " ==> New best value..loss:0.47467020094394685 hm:0.794201667987784\n",
      " ==> New best value..loss:0.47401824057102204 hm:0.7981451191751324\n",
      " ==> New best value..loss:0.471475727558136 hm:0.7990259330041556\n",
      " ==> New best value..loss:0.46902630567550657 hm:0.801732820285712\n",
      " ==> New best value..loss:0.4654617464542389 hm:0.8024331120425037\n",
      " ==> New best value..loss:0.464789000749588 hm:0.8035722936142368\n",
      " ==> New best value..loss:0.4627667552232742 hm:0.8057623813542875\n",
      " ==> New best value..loss:0.45913102447986603 hm:0.807184778829528\n",
      " ==> New best value..loss:0.4560586988925934 hm:0.8122675507249131\n",
      " ==> New best value..loss:0.45192701160907744 hm:0.8143958406445673\n",
      " ==> New best value..loss:0.44932428896427157 hm:0.8169428662999643\n",
      " ==> New best value..loss:0.44615563333034514 hm:0.8183347013543943\n",
      " ==> New best value..loss:0.44508690118789673 hm:0.8199489923562467\n",
      " ==> New best value..loss:0.4444992834329605 hm:0.8202095198438414\n",
      " ==> New best value..loss:0.4431678760051727 hm:0.8224861416062159\n",
      " ==> New best value..loss:0.4379981908202171 hm:0.8241695456846213\n",
      " ==> New best value..loss:0.4346790510416031 hm:0.8257819248166872\n",
      " ==> New best value..loss:0.4340301150083542 hm:0.8278938438468371\n",
      " ==> New best value..loss:0.42564783096313474 hm:0.8303698852020126\n",
      " ==> New best value..loss:0.41999311149120333 hm:0.8316824003199321\n",
      " ==> New best value..loss:0.41837832778692247 hm:0.8337799333249132\n",
      " ==> New best value..loss:0.41728302001953127 hm:0.8357972699523879\n",
      " ==> New best value..loss:0.41378101021051406 hm:0.8362491492696319\n",
      " ==> New best value..loss:0.4082679370045662 hm:0.8375133858860396\n",
      " ==> New best value..loss:0.4080575558543205 hm:0.8384463238306433\n",
      " ==> New best value..loss:0.40567570596933367 hm:0.83925007899654\n",
      " ==> New best value..loss:0.40509928673505785 hm:0.8409808658604385\n",
      " ==> New best value..loss:0.4038496485352516 hm:0.8435156315910145\n",
      " ==> New best value..loss:0.40240806877613067 hm:0.8443908532874336\n",
      " ==> New best value..loss:0.4012194228172302 hm:0.8453007097557874\n",
      " ==> New best value..loss:0.39784235298633575 hm:0.8454124242217795\n",
      "BEST SCORE:  0.8454124242217795\n",
      "TRAINING TOOK:  238  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 20, 'output_size': 1, 'lr': 7e-05, 'print_every': 39, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.663026967048645 hm:0.6385019009360973\n",
      " ==> New best value..loss:0.5864562112092971 hm:0.6574620294875555\n",
      " ==> New best value..loss:0.5690643799304962 hm:0.7015497758860607\n",
      " ==> New best value..loss:0.5417865389585494 hm:0.7303227023696208\n",
      " ==> New best value..loss:0.5120329761505127 hm:0.7546193694865798\n",
      " ==> New best value..loss:0.5009598562121391 hm:0.7621923293798628\n",
      " ==> New best value..loss:0.49209857404232027 hm:0.768773780588451\n",
      " ==> New best value..loss:0.49144320011138914 hm:0.772790319336704\n",
      " ==> New best value..loss:0.4873995852470398 hm:0.7758647373755305\n",
      " ==> New best value..loss:0.4858922475576401 hm:0.7761697543903279\n",
      " ==> New best value..loss:0.48338143408298495 hm:0.777695752105049\n",
      " ==> New best value..loss:0.4833384996652603 hm:0.7786603211715579\n",
      " ==> New best value..loss:0.4802502989768982 hm:0.781349501615187\n",
      " ==> New best value..loss:0.47723802506923674 hm:0.7840469831508775\n",
      " ==> New best value..loss:0.47343736946582793 hm:0.7874696964798237\n",
      " ==> New best value..loss:0.47159528017044067 hm:0.7938345123128421\n",
      " ==> New best value..loss:0.46506294548511506 hm:0.7958826635959544\n",
      " ==> New best value..loss:0.46088017642498014 hm:0.7965846682576082\n",
      " ==> New best value..loss:0.456905454993248 hm:0.8025204444347412\n",
      " ==> New best value..loss:0.45124183148145675 hm:0.8034839740566202\n",
      " ==> New best value..loss:0.44805253118276595 hm:0.8046696652644812\n",
      " ==> New best value..loss:0.4425737768411636 hm:0.8081962404242551\n",
      " ==> New best value..loss:0.4406217038631439 hm:0.8116668280355654\n",
      " ==> New best value..loss:0.4380559664964676 hm:0.8119964053313892\n",
      " ==> New best value..loss:0.43311887472867966 hm:0.8140403624707069\n",
      " ==> New best value..loss:0.43074687391519545 hm:0.8194322363274325\n",
      " ==> New best value..loss:0.4261113503575325 hm:0.8229156181028271\n",
      " ==> New best value..loss:0.42162743270397185 hm:0.8252159522506785\n",
      " ==> New best value..loss:0.41897934168577194 hm:0.8308168839265675\n",
      " ==> New best value..loss:0.4138704016804695 hm:0.8313830896028952\n",
      " ==> New best value..loss:0.411891034245491 hm:0.8324353542407433\n",
      " ==> New best value..loss:0.41067891955375674 hm:0.8330862986715597\n",
      " ==> New best value..loss:0.40872097939252855 hm:0.8338955663731783\n",
      " ==> New best value..loss:0.40536001563072205 hm:0.836852234105984\n",
      " ==> New best value..loss:0.40228470623493195 hm:0.8389850484861748\n",
      " ==> New best value..loss:0.40173170655965806 hm:0.841084574003937\n",
      " ==> New best value..loss:0.39797478944063186 hm:0.8439443474117635\n",
      " ==> New best value..loss:0.39705566883087157 hm:0.8467707040854437\n",
      "BEST SCORE:  0.8467707040854437\n",
      "TRAINING TOOK:  235  s\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'softmax'\n",
    "\n",
    "nn_softmax = []\n",
    "scores_softmax = []\n",
    "\n",
    "for fc1 in fc1_lst:\n",
    "    params_dict['fc1'] = fc1\n",
    "    \n",
    "    for fc2 in fc2_lst:\n",
    "        params_dict['fc2'] = fc2\n",
    "        \n",
    "        for dropval in dropval_lst:\n",
    "            params_dict['drop_fc'] = dropval\n",
    "            params_dict['fc'] = create_fc( params_dict['fc1'],\n",
    "                                params_dict['fc2'],params_dict['drop_fc'])\n",
    "            \n",
    "            print('='*80)\n",
    "            d_start = datetime.now() \n",
    "            best_score, classifier = do_training( df_in1, params_dict, criterion)\n",
    "            nn_softmax.append(classifier)\n",
    "            scores_softmax.append(best_score)\n",
    "            print('BEST SCORE: ', best_score)\n",
    "            print('TRAINING TOOK: ', ( datetime.now() - d_start ).seconds, ' s'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax( scores_softmax )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embed_dim': 100,\n",
       " 'word_gru_h_dim': 100,\n",
       " 'sent_gru_h_dim': 100,\n",
       " 'word_gru_n_layers': 2,\n",
       " 'sent_gru_n_layers': 2,\n",
       " 'word_att_dim': 200,\n",
       " 'sent_att_dim': 200,\n",
       " 'dropgru_s': 0.2,\n",
       " 'dropgru_w': 0.2,\n",
       " 'dropval': 0.2,\n",
       " 'tan_a': 0.5,\n",
       " 'alpha_de': 0.5,\n",
       " 'beta_de': 1,\n",
       " 'batch_size': 30,\n",
       " 'fc1': 200,\n",
       " 'fc2': 30,\n",
       " 'drop_fc': 0.4,\n",
       " 'fc': Sequential(\n",
       "   (0): Dropout(p=0.4, inplace=False)\n",
       "   (1): Linear(in_features=200, out_features=200, bias=True)\n",
       "   (2): Dropout(p=0.2, inplace=False)\n",
       "   (3): Linear(in_features=200, out_features=30, bias=True)\n",
       "   (4): Dropout(p=0.2, inplace=False)\n",
       "   (5): Linear(in_features=30, out_features=1, bias=True)\n",
       "   (6): Sigmoid()\n",
       " ),\n",
       " 'epochs': 20,\n",
       " 'output_size': 1,\n",
       " 'lr': 7e-05,\n",
       " 'print_every': 39,\n",
       " 'clip_val': 1.5,\n",
       " 'attention': 'softmax'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_softmax[5].encoder.params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = 200, fc2 = 30, drop_fc = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. test tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6664791834354401 hm:0.5878378834779499\n",
      " ==> New best value..loss:0.6296174311637879 hm:0.5965293112486563\n",
      " ==> New best value..loss:0.6165251219272614 hm:0.6182575276426481\n",
      " ==> New best value..loss:0.6014027237892151 hm:0.6513705232433251\n",
      " ==> New best value..loss:0.5904790610074997 hm:0.6642190373033595\n",
      " ==> New best value..loss:0.5585851705074311 hm:0.7069198657675154\n",
      " ==> New best value..loss:0.5545915549993515 hm:0.7134826566368886\n",
      " ==> New best value..loss:0.544029415845871 hm:0.7326002075180679\n",
      " ==> New best value..loss:0.5407909959554672 hm:0.7397654157852409\n",
      " ==> New best value..loss:0.5324717307090759 hm:0.7406084765544214\n",
      " ==> New best value..loss:0.5266994464397431 hm:0.7453466187374462\n",
      " ==> New best value..loss:0.5254883432388305 hm:0.7516612048095083\n",
      " ==> New best value..loss:0.5223809540271759 hm:0.7538066949414792\n",
      " ==> New best value..loss:0.5121807760000229 hm:0.755125162722011\n",
      " ==> New best value..loss:0.5096887564659118 hm:0.7602238474877734\n",
      " ==> New best value..loss:0.508708878159523 hm:0.7604443409624504\n",
      " ==> New best value..loss:0.5071539515256882 hm:0.7613581888531916\n",
      " ==> New best value..loss:0.502832202911377 hm:0.7690190747462944\n",
      " ==> New best value..loss:0.5011054944992065 hm:0.7698350985919646\n",
      " ==> New best value..loss:0.49325754404067995 hm:0.7715284012926915\n",
      " ==> New best value..loss:0.486736536026001 hm:0.7795456479168539\n",
      " ==> New best value..loss:0.48258889496326446 hm:0.7812242556787626\n",
      " ==> New best value..loss:0.47768153369426725 hm:0.7834902064257163\n",
      " ==> New best value..loss:0.476991211771965 hm:0.7861903355581773\n",
      " ==> New best value..loss:0.47254512429237366 hm:0.78714387404978\n",
      " ==> New best value..loss:0.4720674830675125 hm:0.7890105470542547\n",
      " ==> New best value..loss:0.4686919414997101 hm:0.7907534030436503\n",
      " ==> New best value..loss:0.46346032083034516 hm:0.7919234498586346\n",
      " ==> New best value..loss:0.4621620547771454 hm:0.7936729296450448\n",
      " ==> New best value..loss:0.45791759610176086 hm:0.7964442759888454\n",
      " ==> New best value..loss:0.457869656085968 hm:0.7967386933816865\n",
      " ==> New best value..loss:0.4563790440559387 hm:0.7976113876538717\n",
      " ==> New best value..loss:0.45222581684589386 hm:0.7979485968466737\n",
      " ==> New best value..loss:0.4486157900094986 hm:0.7994450591865119\n",
      " ==> New best value..loss:0.44544620752334596 hm:0.800511666304515\n",
      " ==> New best value..loss:0.44396506309509276 hm:0.8063700641358593\n",
      " ==> New best value..loss:0.44340735077857973 hm:0.8103667260173071\n",
      " ==> New best value..loss:0.4430533856153488 hm:0.810429834005513\n",
      " ==> New best value..loss:0.44166062474250795 hm:0.8104810267023235\n",
      " ==> New best value..loss:0.4383360922336578 hm:0.8107998245804948\n",
      " ==> New best value..loss:0.43782277971506117 hm:0.8114210765322692\n",
      " ==> New best value..loss:0.4369100937247276 hm:0.8139088433865559\n",
      " ==> New best value..loss:0.43139119386672975 hm:0.8144093415488538\n",
      " ==> New best value..loss:0.42994044333696363 hm:0.815266889233517\n",
      " ==> New best value..loss:0.4297210437059402 hm:0.817408768777313\n",
      " ==> New best value..loss:0.4296920019388199 hm:0.8208610436663819\n",
      " ==> New best value..loss:0.42845204621553423 hm:0.8209521274288757\n",
      " ==> New best value..loss:0.4261484265327454 hm:0.8212972858561659\n",
      " ==> New best value..loss:0.4242794677615166 hm:0.8230678402157265\n",
      " ==> New best value..loss:0.4228668862581253 hm:0.8258198497107694\n",
      "BEST SCORE:  0.8258198497107694\n",
      "TRAINING TOOK:  466  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6342595658212338 hm:0.5988859619692324\n",
      " ==> New best value..loss:0.617776132417175 hm:0.6106028160378348\n",
      " ==> New best value..loss:0.6004412269817209 hm:0.6371078043676504\n",
      " ==> New best value..loss:0.5945928271086711 hm:0.67979657101065\n",
      " ==> New best value..loss:0.5740800752954663 hm:0.6895945308387361\n",
      " ==> New best value..loss:0.5739973013131123 hm:0.6951422440376236\n",
      " ==> New best value..loss:0.5635377950263474 hm:0.6996863686335976\n",
      " ==> New best value..loss:0.5532553077868696 hm:0.703041533596948\n",
      " ==> New best value..loss:0.5510448667238343 hm:0.7104145686428701\n",
      " ==> New best value..loss:0.5487360588784488 hm:0.7114512381185609\n",
      " ==> New best value..loss:0.5433606078039925 hm:0.7164497116103078\n",
      " ==> New best value..loss:0.5410666027159061 hm:0.7312686812853854\n",
      " ==> New best value..loss:0.5404320297376165 hm:0.732594118465107\n",
      " ==> New best value..loss:0.5348076904719731 hm:0.7354655774331644\n",
      " ==> New best value..loss:0.5270346813606765 hm:0.7359592470534131\n",
      " ==> New best value..loss:0.5256703119232969 hm:0.7428774189360904\n",
      " ==> New best value..loss:0.5178727012760235 hm:0.7482953064425396\n",
      " ==> New best value..loss:0.5122149603546791 hm:0.7496880440317303\n",
      " ==> New best value..loss:0.5095329745760504 hm:0.7525281342004578\n",
      " ==> New best value..loss:0.5079289775974346 hm:0.7541195445332262\n",
      " ==> New best value..loss:0.5078071007188761 hm:0.7552993668968484\n",
      " ==> New best value..loss:0.5031627753995499 hm:0.7557063406079642\n",
      " ==> New best value..loss:0.5031329084117457 hm:0.7636837693870739\n",
      " ==> New best value..loss:0.49324459568509516 hm:0.7687707960312284\n",
      " ==> New best value..loss:0.4893990991250524 hm:0.7732288188017412\n",
      " ==> New best value..loss:0.48921134786785775 hm:0.7791881625546292\n",
      " ==> New best value..loss:0.48745764426465304 hm:0.7804087138192384\n",
      " ==> New best value..loss:0.48079336645468224 hm:0.7827086056142318\n",
      " ==> New best value..loss:0.47038265444197747 hm:0.7827182052241997\n",
      " ==> New best value..loss:0.47013208101380544 hm:0.7850578502562169\n",
      " ==> New best value..loss:0.4686517619861747 hm:0.7870409085827035\n",
      " ==> New best value..loss:0.46180949458536114 hm:0.7878738384724677\n",
      " ==> New best value..loss:0.4587064587844993 hm:0.794084689148355\n",
      " ==> New best value..loss:0.4565327319334138 hm:0.796001145265923\n",
      " ==> New best value..loss:0.4547834236104533 hm:0.7970241556657826\n",
      " ==> New best value..loss:0.4536370078347764 hm:0.7993606580495228\n",
      " ==> New best value..loss:0.45259136692532953 hm:0.8008663726200649\n",
      " ==> New best value..loss:0.4494724672920299 hm:0.8026090113151048\n",
      " ==> New best value..loss:0.44911440194777724 hm:0.8078608520004362\n",
      " ==> New best value..loss:0.44487830996513367 hm:0.809483287851249\n",
      " ==> New best value..loss:0.44458195173515463 hm:0.8128866156691782\n",
      "BEST SCORE:  0.8128866156691782\n",
      "TRAINING TOOK:  474  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.7232798057443955 hm:0.3824529900708221\n",
      " ==> New best value..loss:0.6822634865255917 hm:0.525807043001758\n",
      " ==> New best value..loss:0.6422199969198189 hm:0.5882623832435938\n",
      " ==> New best value..loss:0.6339348858478022 hm:0.5981170302027651\n",
      " ==> New best value..loss:0.6276407656716365 hm:0.6094348814278819\n",
      " ==> New best value..loss:0.6188785556484672 hm:0.6225741125405987\n",
      " ==> New best value..loss:0.6101183938045128 hm:0.6382592116410082\n",
      " ==> New best value..loss:0.6030491724902508 hm:0.6517144503595111\n",
      " ==> New best value..loss:0.5978973805904388 hm:0.659599934222208\n",
      " ==> New best value..loss:0.593979559692682 hm:0.6660916419465391\n",
      " ==> New best value..loss:0.5930772347777498 hm:0.6705608953438214\n",
      " ==> New best value..loss:0.5908186932404836 hm:0.6792917365801264\n",
      " ==> New best value..loss:0.5867615283704272 hm:0.6833873030320333\n",
      " ==> New best value..loss:0.5775840212317074 hm:0.6959273482906183\n",
      " ==> New best value..loss:0.5746367123781466 hm:0.701022998250027\n",
      " ==> New best value..loss:0.5716691811879476 hm:0.7071178073242402\n",
      " ==> New best value..loss:0.5713878887541154 hm:0.7129795642530239\n",
      " ==> New best value..loss:0.5646863608968025 hm:0.7212763735929983\n",
      " ==> New best value..loss:0.563904207126767 hm:0.7243284015434089\n",
      " ==> New best value..loss:0.5537136793136597 hm:0.7261791513110357\n",
      " ==> New best value..loss:0.5528575772163915 hm:0.7292206756243448\n",
      " ==> New best value..loss:0.5436530241779253 hm:0.7303280382971543\n",
      " ==> New best value..loss:0.5391450448363435 hm:0.7439198796210207\n",
      " ==> New best value..loss:0.5241080487475676 hm:0.7452426457244179\n",
      " ==> New best value..loss:0.5226801329968023 hm:0.7461161670028013\n",
      " ==> New best value..loss:0.5208918510698805 hm:0.7493984402424494\n",
      " ==> New best value..loss:0.5184923387041279 hm:0.7543116453803292\n",
      " ==> New best value..loss:0.5145343273293739 hm:0.7549337601023719\n",
      " ==> New best value..loss:0.5118474247408848 hm:0.7585598475283415\n",
      " ==> New best value..loss:0.5068186842927745 hm:0.7594050741756273\n",
      " ==> New best value..loss:0.5041933235000161 hm:0.7638935264162128\n",
      " ==> New best value..loss:0.501161061665591 hm:0.7680331337662388\n",
      " ==> New best value..loss:0.4971763555910073 hm:0.7709257035761613\n",
      " ==> New best value..loss:0.4969475251786849 hm:0.771378740668113\n",
      " ==> New best value..loss:0.49654555963534935 hm:0.7735759887495248\n",
      " ==> New best value..loss:0.4918596954906688 hm:0.77545424993043\n",
      " ==> New best value..loss:0.48935844442423654 hm:0.7785072265636886\n",
      " ==> New best value..loss:0.4869726124931784 hm:0.7798560046025935\n",
      " ==> New best value..loss:0.48493470572957803 hm:0.7803662520686745\n",
      " ==> New best value..loss:0.4828033540763107 hm:0.7824082126598434\n",
      " ==> New best value..loss:0.4802711278784509 hm:0.7845777882159584\n",
      " ==> New best value..loss:0.4792818497208988 hm:0.7869082920404779\n",
      " ==> New best value..loss:0.4752650301830441 hm:0.7872920495536971\n",
      " ==> New best value..loss:0.47396255240720864 hm:0.7922157227690871\n",
      " ==> New best value..loss:0.47316113640280333 hm:0.792946314889275\n",
      " ==> New best value..loss:0.47283683980212493 hm:0.7933670171198409\n",
      " ==> New best value..loss:0.46747518024023843 hm:0.7942049258774013\n",
      " ==> New best value..loss:0.46716169633117377 hm:0.7949999904233234\n",
      " ==> New best value..loss:0.46325357638153375 hm:0.7978517321157959\n",
      " ==> New best value..loss:0.46247730973888845 hm:0.8000317040630696\n",
      " ==> New best value..loss:0.4609304952855204 hm:0.8038299526780616\n",
      " ==> New best value..loss:0.45459747022273495 hm:0.8067074422167527\n",
      " ==> New best value..loss:0.4542808030165878 hm:0.8089423652172381\n",
      " ==> New best value..loss:0.45126522756090354 hm:0.8096289148157821\n",
      " ==> New best value..loss:0.45011401936119677 hm:0.8105893071559616\n",
      " ==> New best value..loss:0.4492597667609944 hm:0.8110369686942814\n",
      " ==> New best value..loss:0.44701045284084245 hm:0.8137841941992957\n",
      " ==> New best value..loss:0.4456922400231455 hm:0.8152752233581825\n",
      " ==> New best value..loss:0.44423742563116786 hm:0.8177660501444772\n",
      " ==> New best value..loss:0.44269927956309973 hm:0.8183418452821228\n",
      " ==> New best value..loss:0.44074223847950206 hm:0.8185761086268174\n",
      " ==> New best value..loss:0.43974121411641437 hm:0.82066804606914\n",
      " ==> New best value..loss:0.43771417117586325 hm:0.8212819412577352\n",
      " ==> New best value..loss:0.43659035832274196 hm:0.8215629380664751\n",
      " ==> New best value..loss:0.4352053596692927 hm:0.8237550267174981\n",
      " ==> New best value..loss:0.43476027600905476 hm:0.8255543129443582\n",
      "BEST SCORE:  0.8255543129443582\n",
      "TRAINING TOOK:  501  s\n",
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6054440995057424 hm:0.635647173631272\n",
      " ==> New best value..loss:0.577740952372551 hm:0.6820345938979745\n",
      " ==> New best value..loss:0.5621006349722545 hm:0.7067622489263115\n",
      " ==> New best value..loss:0.5565478126207988 hm:0.716726749410952\n",
      " ==> New best value..loss:0.5366880853970846 hm:0.7410181519405682\n",
      " ==> New best value..loss:0.5263075808684031 hm:0.7438700190267158\n",
      " ==> New best value..loss:0.5199094345172246 hm:0.7461627535970113\n",
      " ==> New best value..loss:0.5169825603564581 hm:0.7519863432183903\n",
      " ==> New best value..loss:0.5159215937058131 hm:0.7563948978513698\n",
      " ==> New best value..loss:0.5140996327002844 hm:0.7612118274206149\n",
      " ==> New best value..loss:0.5045557071765264 hm:0.7647540815923191\n",
      " ==> New best value..loss:0.49501008888085685 hm:0.7670343681304717\n",
      " ==> New best value..loss:0.4924602856238683 hm:0.7680933264612151\n",
      " ==> New best value..loss:0.4867687384287516 hm:0.7691133330189387\n",
      " ==> New best value..loss:0.48423062860965727 hm:0.7741616554170903\n",
      " ==> New best value..loss:0.47776000102361044 hm:0.7812230667836452\n",
      " ==> New best value..loss:0.47744102279345196 hm:0.783503297541728\n",
      " ==> New best value..loss:0.47652551233768464 hm:0.7879564378009317\n",
      " ==> New best value..loss:0.47250117858250934 hm:0.7911418576346664\n",
      " ==> New best value..loss:0.4644849826892217 hm:0.7924506294847641\n",
      " ==> New best value..loss:0.46414132515589396 hm:0.7955776403461088\n",
      " ==> New best value..loss:0.4579424132903417 hm:0.7958760844494783\n",
      " ==> New best value..loss:0.45653496285279593 hm:0.7969913105407727\n",
      " ==> New best value..loss:0.45512310167153675 hm:0.798387723883032\n",
      " ==> New best value..loss:0.4526553819576899 hm:0.7993119262203285\n",
      " ==> New best value..loss:0.45107504924138386 hm:0.8017371189273841\n",
      " ==> New best value..loss:0.44813508093357085 hm:0.8021571406164125\n",
      " ==> New best value..loss:0.446881032983462 hm:0.8047788051155287\n",
      " ==> New best value..loss:0.4441217571496964 hm:0.8068398292660505\n",
      " ==> New best value..loss:0.44177671869595847 hm:0.8069111589042992\n",
      " ==> New best value..loss:0.44138497710227964 hm:0.8071422699652407\n",
      " ==> New best value..loss:0.4411663144826889 hm:0.8073564312085811\n",
      " ==> New best value..loss:0.4399312218030294 hm:0.8082702969961242\n",
      " ==> New best value..loss:0.4392409394184748 hm:0.8094087873206228\n",
      " ==> New best value..loss:0.43672079145908355 hm:0.8106621178725859\n",
      " ==> New best value..loss:0.4345136513312658 hm:0.8107800693827393\n",
      " ==> New best value..loss:0.43116908172766366 hm:0.8108217315279644\n",
      "BEST SCORE:  0.8108217315279644\n",
      "TRAINING TOOK:  292  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.648840396568693 hm:0.5876122786908373\n",
      " ==> New best value..loss:0.615687697098173 hm:0.6363070200644877\n",
      " ==> New best value..loss:0.5893647321339311 hm:0.6769949661458073\n",
      " ==> New best value..loss:0.5766269914035139 hm:0.6967923833600822\n",
      " ==> New best value..loss:0.5692527304435598 hm:0.7244783557615856\n",
      " ==> New best value..loss:0.5510093055922409 hm:0.7397859555383538\n",
      " ==> New best value..loss:0.5385761548732889 hm:0.7438699967606153\n",
      " ==> New best value..loss:0.5339270706834465 hm:0.7484599877110042\n",
      " ==> New best value..loss:0.528983814962979 hm:0.7545473195421284\n",
      " ==> New best value..loss:0.5252290018673601 hm:0.7549408497262333\n",
      " ==> New best value..loss:0.5200431603809883 hm:0.7579741941422851\n",
      " ==> New best value..loss:0.5143281241943096 hm:0.7590002718514739\n",
      " ==> New best value..loss:0.5132111968665287 hm:0.7633510682527794\n",
      " ==> New best value..loss:0.5062797275082819 hm:0.7660727896290908\n",
      " ==> New best value..loss:0.505086717934444 hm:0.7705972103802519\n",
      " ==> New best value..loss:0.5037613839938723 hm:0.7723821778137024\n",
      " ==> New best value..loss:0.5026811597676113 hm:0.774915992715613\n",
      " ==> New best value..loss:0.4903585160600728 hm:0.776670662246247\n",
      " ==> New best value..loss:0.48792238893180057 hm:0.7797748285506826\n",
      " ==> New best value..loss:0.4847282140419401 hm:0.7820080573034682\n",
      " ==> New best value..loss:0.4811597055402295 hm:0.7825929657991479\n",
      " ==> New best value..loss:0.48105604484163483 hm:0.7860267285956289\n",
      " ==> New best value..loss:0.4772281985858391 hm:0.7875958573842197\n",
      " ==> New best value..loss:0.47295455172144135 hm:0.7919700587603066\n",
      " ==> New best value..loss:0.4725434656800895 hm:0.7954813876823817\n",
      " ==> New best value..loss:0.4645052881076418 hm:0.7981954105705517\n",
      " ==> New best value..loss:0.4561535510523566 hm:0.7989169757534524\n",
      " ==> New best value..loss:0.4560772632730418 hm:0.8006731178967107\n",
      " ==> New best value..loss:0.45527650261747427 hm:0.8016200647529829\n",
      " ==> New best value..loss:0.45061286461764366 hm:0.8023825769917096\n",
      " ==> New best value..loss:0.44778123292429695 hm:0.8054322440679929\n",
      " ==> New best value..loss:0.4473662366127146 hm:0.8056234053905297\n",
      " ==> New best value..loss:0.44577463536426937 hm:0.807621867094064\n",
      " ==> New best value..loss:0.44492549937346887 hm:0.809620245404381\n",
      " ==> New best value..loss:0.4431374586861709 hm:0.8120404171385293\n",
      " ==> New best value..loss:0.438249245799821 hm:0.8134001258890513\n",
      " ==> New best value..loss:0.4340177558619401 hm:0.8158091487583882\n",
      " ==> New best value..loss:0.43099960890309563 hm:0.8170397628628235\n",
      " ==> New best value..loss:0.4293370534633768 hm:0.8175436345332755\n",
      " ==> New best value..loss:0.42360938520267094 hm:0.8190251299994448\n",
      " ==> New best value..loss:0.4211011405648856 hm:0.8215549086114448\n",
      " ==> New best value..loss:0.419637438552133 hm:0.8242232530318184\n",
      "BEST SCORE:  0.8242232530318184\n",
      "TRAINING TOOK:  282  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6357984792801642 hm:0.5915121383398609\n",
      " ==> New best value..loss:0.6185555784933029 hm:0.5926808087516479\n",
      " ==> New best value..loss:0.6146717283033556 hm:0.6124946031685323\n",
      " ==> New best value..loss:0.6124196504392931 hm:0.6308300785140722\n",
      " ==> New best value..loss:0.5858872532844543 hm:0.6525203837841762\n",
      " ==> New best value..loss:0.5829899830202903 hm:0.6743774016641465\n",
      " ==> New best value..loss:0.5738066107996048 hm:0.692934541446219\n",
      " ==> New best value..loss:0.5727693640416668 hm:0.7046884007233033\n",
      " ==> New best value..loss:0.5565627409565833 hm:0.7096181696635516\n",
      " ==> New best value..loss:0.5483198175507207 hm:0.7096303276477296\n",
      " ==> New best value..loss:0.5363116966139886 hm:0.7148905013846173\n",
      " ==> New best value..loss:0.530518772140626 hm:0.7153771700162048\n",
      " ==> New best value..loss:0.5188945022321516 hm:0.7282457186626642\n",
      " ==> New best value..loss:0.5144160111104289 hm:0.7402871359954896\n",
      " ==> New best value..loss:0.5129711695255772 hm:0.7492143374984331\n",
      " ==> New best value..loss:0.5128701973345972 hm:0.7527941725129854\n",
      " ==> New best value..loss:0.5095474508500868 hm:0.7556516356923266\n",
      " ==> New best value..loss:0.49942907594865366 hm:0.763918251586335\n",
      " ==> New best value..loss:0.4939505736674032 hm:0.7692507148583977\n",
      " ==> New best value..loss:0.4892663124107545 hm:0.7740425482427232\n",
      " ==> New best value..loss:0.48662644913119657 hm:0.7771787444032644\n",
      " ==> New best value..loss:0.4855743415894047 hm:0.781832344022188\n",
      " ==> New best value..loss:0.4851609035845726 hm:0.7819155250185039\n",
      " ==> New best value..loss:0.47857070930542484 hm:0.7825355178294013\n",
      " ==> New best value..loss:0.47605047975817033 hm:0.7873996188241303\n",
      " ==> New best value..loss:0.47443333652711683 hm:0.7876713600309837\n",
      " ==> New best value..loss:0.47348532753606 hm:0.7894193289066573\n",
      " ==> New best value..loss:0.4624084219817192 hm:0.7911737943357654\n",
      " ==> New best value..loss:0.4553688658821967 hm:0.7962547377641682\n",
      " ==> New best value..loss:0.4512678596281236 hm:0.7993800942302477\n",
      " ==> New best value..loss:0.4470434208070078 hm:0.8060274884797932\n",
      " ==> New best value..loss:0.44656986671109355 hm:0.807086480310704\n",
      " ==> New best value..loss:0.43587561143982795 hm:0.8082569821517438\n",
      " ==> New best value..loss:0.4323227794901017 hm:0.8116327041291924\n",
      " ==> New best value..loss:0.42751258034859935 hm:0.8210144513323135\n",
      " ==> New best value..loss:0.42579566615243114 hm:0.8212995568301291\n",
      "BEST SCORE:  0.8212995568301291\n",
      "TRAINING TOOK:  279  s\n",
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6280569922924042 hm:0.5682427644811207\n",
      " ==> New best value..loss:0.6264836037158966 hm:0.5856051869136685\n",
      " ==> New best value..loss:0.6261751186847687 hm:0.5968643268372916\n",
      " ==> New best value..loss:0.6202579581737518 hm:0.5999794296045143\n",
      " ==> New best value..loss:0.6179302859306336 hm:0.6060398266126725\n",
      " ==> New best value..loss:0.6150525087118148 hm:0.6104949484070689\n",
      " ==> New best value..loss:0.61025252699852 hm:0.6174803043282937\n",
      " ==> New best value..loss:0.6099736207723617 hm:0.6291646271105453\n",
      " ==> New best value..loss:0.6059710615873337 hm:0.6337545824536335\n",
      " ==> New best value..loss:0.6016857600212098 hm:0.650332903575587\n",
      " ==> New best value..loss:0.5963795918226242 hm:0.6667207422497731\n",
      " ==> New best value..loss:0.5826153600215912 hm:0.6966553008539649\n",
      " ==> New best value..loss:0.5792285722494125 hm:0.7059267284943614\n",
      " ==> New best value..loss:0.5614854884147644 hm:0.7094700648864516\n",
      " ==> New best value..loss:0.559729529619217 hm:0.7122684988461715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5547122019529342 hm:0.7170247793737565\n",
      " ==> New best value..loss:0.5482956725358963 hm:0.7240858482981474\n",
      " ==> New best value..loss:0.5451044523715973 hm:0.7261402184184552\n",
      " ==> New best value..loss:0.5441886895895004 hm:0.7283016889065016\n",
      " ==> New best value..loss:0.5380273574590683 hm:0.7352364163346325\n",
      " ==> New best value..loss:0.5363202369213105 hm:0.7381879539205298\n",
      " ==> New best value..loss:0.533107727766037 hm:0.7411174599220953\n",
      " ==> New best value..loss:0.530920895934105 hm:0.7444233563312551\n",
      " ==> New best value..loss:0.5298384273052216 hm:0.7460405728493206\n",
      " ==> New best value..loss:0.5298167389631271 hm:0.7463652558971852\n",
      " ==> New best value..loss:0.5276361286640168 hm:0.7474631005293891\n",
      " ==> New best value..loss:0.5269643360376358 hm:0.7488410850982793\n",
      " ==> New best value..loss:0.523317312002182 hm:0.7501878508536345\n",
      " ==> New best value..loss:0.5228390502929687 hm:0.7506850283369486\n",
      " ==> New best value..loss:0.5216810929775239 hm:0.7513277167177637\n",
      " ==> New best value..loss:0.5215960657596588 hm:0.7529774983289088\n",
      " ==> New best value..loss:0.5197929525375367 hm:0.7567960463467744\n",
      " ==> New best value..loss:0.5179256993532181 hm:0.7576586148623594\n",
      " ==> New best value..loss:0.5151496666669846 hm:0.759103778923002\n",
      " ==> New best value..loss:0.5150193387269973 hm:0.7599174463154251\n",
      " ==> New best value..loss:0.5123762774467469 hm:0.7604871428506712\n",
      " ==> New best value..loss:0.5093069505691529 hm:0.761745284438152\n",
      " ==> New best value..loss:0.5070246712863445 hm:0.7630294531430027\n",
      " ==> New best value..loss:0.5058072704076767 hm:0.7639454636953654\n",
      " ==> New best value..loss:0.5052425813674927 hm:0.76609683652754\n",
      " ==> New best value..loss:0.5043907177448272 hm:0.7673382298024916\n",
      " ==> New best value..loss:0.5036218869686127 hm:0.7695638283946297\n",
      " ==> New best value..loss:0.5027790534496307 hm:0.7704179200532869\n",
      " ==> New best value..loss:0.5017543578147888 hm:0.7740862606914192\n",
      " ==> New best value..loss:0.4982738995552063 hm:0.7743720781948904\n",
      " ==> New best value..loss:0.49808039247989655 hm:0.775338476331189\n",
      " ==> New best value..loss:0.49746854960918424 hm:0.7780500451349871\n",
      " ==> New best value..loss:0.49482855677604676 hm:0.7788707423346063\n",
      " ==> New best value..loss:0.4926391887664795 hm:0.7794652962616527\n",
      " ==> New best value..loss:0.48943192601203916 hm:0.780755505161316\n",
      " ==> New best value..loss:0.48562848299741745 hm:0.782149610363564\n",
      " ==> New best value..loss:0.48210294663906095 hm:0.7831438994517824\n",
      " ==> New best value..loss:0.4815928828716278 hm:0.7837123521476729\n",
      " ==> New best value..loss:0.47942553102970126 hm:0.7870463436344012\n",
      " ==> New best value..loss:0.47846255004405974 hm:0.7874161265676353\n",
      " ==> New best value..loss:0.4771611189842224 hm:0.789075816754958\n",
      " ==> New best value..loss:0.4758513063192368 hm:0.7904084553263098\n",
      " ==> New best value..loss:0.47523790717124936 hm:0.790742001835422\n",
      " ==> New best value..loss:0.470893959403038 hm:0.7911674710715721\n",
      "BEST SCORE:  0.7911674710715721\n",
      "TRAINING TOOK:  482  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6320694595575332 hm:0.5750714586337867\n",
      " ==> New best value..loss:0.6310499387979508 hm:0.577794086584093\n",
      " ==> New best value..loss:0.6292457711696625 hm:0.5797088945982534\n",
      " ==> New best value..loss:0.6200827467441559 hm:0.5838061525150192\n",
      " ==> New best value..loss:0.6169397383928299 hm:0.6015898344289842\n",
      " ==> New best value..loss:0.6150885373353958 hm:0.6211942785805415\n",
      " ==> New best value..loss:0.6117982459068299 hm:0.6319369271044848\n",
      " ==> New best value..loss:0.6081708127260208 hm:0.6441980286601808\n",
      " ==> New best value..loss:0.6075848281383515 hm:0.6574224745034888\n",
      " ==> New best value..loss:0.5989570981264114 hm:0.6674883777490486\n",
      " ==> New best value..loss:0.594266881942749 hm:0.6767675653885726\n",
      " ==> New best value..loss:0.5877467089891434 hm:0.6943974352645247\n",
      " ==> New best value..loss:0.5780623644590378 hm:0.7003866641417293\n",
      " ==> New best value..loss:0.5678075245022773 hm:0.708272327118054\n",
      " ==> New best value..loss:0.5657708537578583 hm:0.7115385475737599\n",
      " ==> New best value..loss:0.5576704919338227 hm:0.713240722575445\n",
      " ==> New best value..loss:0.5566825157403946 hm:0.7182639681158313\n",
      " ==> New best value..loss:0.5558904987573624 hm:0.7224299094132021\n",
      " ==> New best value..loss:0.5509613305330276 hm:0.7247039905887979\n",
      " ==> New best value..loss:0.5505407345294953 hm:0.7283109922519878\n",
      " ==> New best value..loss:0.5492832815647125 hm:0.7302615915562173\n",
      " ==> New best value..loss:0.5478673765063286 hm:0.7323301138168489\n",
      " ==> New best value..loss:0.5458313864469528 hm:0.7352299317924833\n",
      " ==> New best value..loss:0.5415931022167206 hm:0.7368404142769345\n",
      " ==> New best value..loss:0.538922112584114 hm:0.7377260685910928\n",
      " ==> New best value..loss:0.534087887108326 hm:0.7396280860448888\n",
      " ==> New best value..loss:0.5302430576086045 hm:0.7467832816903686\n",
      " ==> New best value..loss:0.5283899801969528 hm:0.7506528184778454\n",
      " ==> New best value..loss:0.5253252273797989 hm:0.7511506557794883\n",
      " ==> New best value..loss:0.5235508194565773 hm:0.7543430511473854\n",
      " ==> New best value..loss:0.5203996521234512 hm:0.7567215914660812\n",
      " ==> New best value..loss:0.5179417750239372 hm:0.7605379980182349\n",
      " ==> New best value..loss:0.5154677376151084 hm:0.7609867553917901\n",
      " ==> New best value..loss:0.5153046908974648 hm:0.7629585464680168\n",
      " ==> New best value..loss:0.512359756231308 hm:0.7637815919357241\n",
      " ==> New best value..loss:0.5089524000883102 hm:0.7707615718300043\n",
      " ==> New best value..loss:0.5084052681922913 hm:0.7719493484381771\n",
      " ==> New best value..loss:0.5067189222574234 hm:0.7746124367799787\n",
      " ==> New best value..loss:0.5053526645898819 hm:0.7771622609460186\n",
      " ==> New best value..loss:0.5026037454605102 hm:0.7795814751010404\n",
      " ==> New best value..loss:0.4982254606485367 hm:0.7812794121193521\n",
      " ==> New best value..loss:0.496661217212677 hm:0.7828350015765478\n",
      " ==> New best value..loss:0.4949891927838326 hm:0.7853113932599564\n",
      " ==> New best value..loss:0.4912292391061783 hm:0.7871313051065144\n",
      " ==> New best value..loss:0.4903951680660248 hm:0.7911838079034902\n",
      " ==> New best value..loss:0.48859581887722014 hm:0.7934669570107499\n",
      " ==> New best value..loss:0.4861824572086334 hm:0.7936398793409817\n",
      " ==> New best value..loss:0.4800091689825058 hm:0.7942919420544178\n",
      " ==> New best value..loss:0.47505647748708724 hm:0.7977539906008778\n",
      " ==> New best value..loss:0.4750523778796196 hm:0.7989838802556117\n",
      " ==> New best value..loss:0.4716500985622406 hm:0.8015873554940139\n",
      "BEST SCORE:  0.8015873554940139\n",
      "TRAINING TOOK:  484  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.6276988520914194 hm:0.5567581963608192\n",
      " ==> New best value..loss:0.6267333857867182 hm:0.5673119691339493\n",
      " ==> New best value..loss:0.6260517215242192 hm:0.5760937284822486\n",
      " ==> New best value..loss:0.6211165335713601 hm:0.5796048893907549\n",
      " ==> New best value..loss:0.6201267789821235 hm:0.5841859194394223\n",
      " ==> New best value..loss:0.6190491428180617 hm:0.5892771751446585\n",
      " ==> New best value..loss:0.6177925747268054 hm:0.5937824712796098\n",
      " ==> New best value..loss:0.616709019456591 hm:0.5984397307458954\n",
      " ==> New best value..loss:0.6156938209825632 hm:0.6017015353250754\n",
      " ==> New best value..loss:0.6142612561887625 hm:0.603047727414238\n",
      " ==> New best value..loss:0.6135754360228168 hm:0.6041028767180919\n",
      " ==> New best value..loss:0.6129688590156789 hm:0.6095346089528685\n",
      " ==> New best value..loss:0.6126526338713509 hm:0.6162396319872389\n",
      " ==> New best value..loss:0.6123486708621589 hm:0.6200442581711638\n",
      " ==> New best value..loss:0.6114269750458854 hm:0.6232502559218943\n",
      " ==> New best value..loss:0.6103865479936406 hm:0.6235428081182888\n",
      " ==> New best value..loss:0.6093217450745252 hm:0.6254609768952012\n",
      " ==> New best value..loss:0.6082260918860533 hm:0.6280228294608124\n",
      " ==> New best value..loss:0.6071386166981289 hm:0.630249157040954\n",
      " ==> New best value..loss:0.6060103050300053 hm:0.6333976858221136\n",
      " ==> New best value..loss:0.6048019187791007 hm:0.6379316082602813\n",
      " ==> New best value..loss:0.6034683013448909 hm:0.6409333762589959\n",
      " ==> New best value..loss:0.6017752551302618 hm:0.647126795572751\n",
      " ==> New best value..loss:0.599491938644526 hm:0.6545054547279617\n",
      " ==> New best value..loss:0.596985828511569 hm:0.6616468796944793\n",
      " ==> New best value..loss:0.5950962000963639 hm:0.6657824162220704\n",
      " ==> New best value..loss:0.5925225706733003 hm:0.6699252192768907\n",
      " ==> New best value..loss:0.5898449846676418 hm:0.6769500829235229\n",
      " ==> New best value..loss:0.5870282418873846 hm:0.68566858568035\n",
      " ==> New best value..loss:0.5844394753173906 hm:0.687217222499138\n",
      " ==> New best value..loss:0.5817166347892917 hm:0.6914103033583385\n",
      " ==> New best value..loss:0.5788593474699526 hm:0.6962515651314621\n",
      " ==> New best value..loss:0.5761790202588452 hm:0.6982858354100338\n",
      " ==> New best value..loss:0.5728765586201026 hm:0.7029080763709609\n",
      " ==> New best value..loss:0.5701315798321549 hm:0.7059950509751743\n",
      " ==> New best value..loss:0.5681551159644613 hm:0.7080315865037836\n",
      " ==> New best value..loss:0.5650849062569288 hm:0.709227158150784\n",
      " ==> New best value..loss:0.562430841582162 hm:0.7097448669628602\n",
      " ==> New best value..loss:0.5603370775981825 hm:0.7103763272887468\n",
      " ==> New best value..loss:0.5571698698462272 hm:0.7118208747028659\n",
      " ==> New best value..loss:0.5555209480986303 hm:0.712067424763314\n",
      " ==> New best value..loss:0.5539654456839269 hm:0.7125108779917123\n",
      " ==> New best value..loss:0.5509551970326171 hm:0.713929131876215\n",
      " ==> New best value..loss:0.5503038818738899 hm:0.7144566974805758\n",
      " ==> New best value..loss:0.5478023381865754 hm:0.7163949863733393\n",
      " ==> New best value..loss:0.5468042103611693 hm:0.7183901255579068\n",
      " ==> New best value..loss:0.5466440739680309 hm:0.7190875355056864\n",
      " ==> New best value..loss:0.5451394374273262 hm:0.719838599550231\n",
      " ==> New best value..loss:0.5432022797818087 hm:0.7209092070276192\n",
      " ==> New best value..loss:0.5425687918857652 hm:0.7219612016505915\n",
      " ==> New best value..loss:0.541866557938712 hm:0.7240444431298352\n",
      " ==> New best value..loss:0.5413182542032126 hm:0.7244439040603818\n",
      " ==> New best value..loss:0.5407905402232189 hm:0.7254564857661172\n",
      " ==> New best value..loss:0.5403374901839665 hm:0.7263671871833933\n",
      " ==> New best value..loss:0.539175919732269 hm:0.7270201099323436\n",
      " ==> New best value..loss:0.5383396781220728 hm:0.727595873512723\n",
      " ==> New best value..loss:0.5371685368674142 hm:0.7286029307075697\n",
      " ==> New best value..loss:0.5367598053143949 hm:0.7299526999151725\n",
      " ==> New best value..loss:0.535140545392523 hm:0.7307211379459739\n",
      " ==> New best value..loss:0.5346328968904457 hm:0.7317180974349964\n",
      " ==> New best value..loss:0.5335681833782975 hm:0.7321884435491929\n",
      " ==> New best value..loss:0.5330857476409601 hm:0.7326634123095529\n",
      " ==> New best value..loss:0.5329948335277791 hm:0.7328942633403809\n",
      " ==> New best value..loss:0.5327628254890442 hm:0.7332760110522321\n",
      " ==> New best value..loss:0.5326346560400359 hm:0.734012132861029\n",
      " ==> New best value..loss:0.5324434887389747 hm:0.7341692015856676\n",
      " ==> New best value..loss:0.5319534479355326 hm:0.734407854663114\n",
      " ==> New best value..loss:0.5312123031032329 hm:0.7346677364063707\n",
      " ==> New best value..loss:0.5307103492775742 hm:0.7358069693163312\n",
      " ==> New best value..loss:0.5302013055402406 hm:0.7359757131545379\n",
      " ==> New best value..loss:0.5300384899791406 hm:0.7362712170532499\n",
      " ==> New best value..loss:0.5297013673247123 hm:0.736545586893757\n",
      " ==> New best value..loss:0.5289638139763657 hm:0.736752268412404\n",
      " ==> New best value..loss:0.5282631346157619 hm:0.7380253772789067\n",
      " ==> New best value..loss:0.5278123611090134 hm:0.7381254597643488\n",
      " ==> New best value..loss:0.5274897120436843 hm:0.7384297465280919\n",
      " ==> New best value..loss:0.5273313887265264 hm:0.7393801124535458\n",
      " ==> New best value..loss:0.5261266146387372 hm:0.7397039111491717\n",
      " ==> New best value..loss:0.5258163365782523 hm:0.7406905826194631\n",
      " ==> New best value..loss:0.5238231761114938 hm:0.7414294325548355\n",
      " ==> New best value..loss:0.5224164760842616 hm:0.7417980263615441\n",
      " ==> New best value..loss:0.5220928903745146 hm:0.742933603831564\n",
      " ==> New best value..loss:0.5218357127539965 hm:0.7431953454420077\n",
      " ==> New best value..loss:0.5212574290985964 hm:0.7432184664225504\n",
      " ==> New best value..loss:0.5205700561708334 hm:0.7434727055816127\n",
      " ==> New best value..loss:0.5201251512887527 hm:0.7439804458621592\n",
      " ==> New best value..loss:0.519507364959133 hm:0.7451458124994992\n",
      " ==> New best value..loss:0.5192816403447366 hm:0.7452229754332759\n",
      " ==> New best value..loss:0.518495688633043 hm:0.7456793506669743\n",
      " ==> New best value..loss:0.5183089235607459 hm:0.7466708639670535\n",
      " ==> New best value..loss:0.5177298376754839 hm:0.7472042148934175\n",
      " ==> New best value..loss:0.5174344267163958 hm:0.748254746793739\n",
      " ==> New best value..loss:0.5153180896019449 hm:0.7490545978177579\n",
      " ==> New best value..loss:0.5144148943375568 hm:0.7496162533679636\n",
      " ==> New best value..loss:0.5141143713678632 hm:0.7501921361310342\n",
      " ==> New best value..loss:0.5135491368721943 hm:0.7515088106443351\n",
      " ==> New best value..loss:0.5131633999396343 hm:0.7527758408077923\n",
      " ==> New best value..loss:0.5113867576024971 hm:0.7534494344352051\n",
      " ==> New best value..loss:0.5106472634539312 hm:0.753995898167872\n",
      " ==> New best value..loss:0.5102529045270414 hm:0.7569846465918296\n",
      " ==> New best value..loss:0.509942144763713 hm:0.7576224236451408\n",
      " ==> New best value..loss:0.5095184366313779 hm:0.7576408851971371\n",
      " ==> New best value..loss:0.5087017179751883 hm:0.7587640802759872\n",
      " ==> New best value..loss:0.5083436978106596 hm:0.7597971966017105\n",
      " ==> New best value..loss:0.507374066479352 hm:0.760034196886417\n",
      " ==> New best value..loss:0.5069207774133099 hm:0.7605873993070402\n",
      " ==> New best value..loss:0.5066869252798508 hm:0.7606399386279055\n",
      " ==> New best value..loss:0.5058895884727945 hm:0.7620504598191166\n",
      " ==> New best value..loss:0.5057555935820754 hm:0.7625960157409337\n",
      " ==> New best value..loss:0.5050780937379721 hm:0.7628210663254577\n",
      " ==> New best value..loss:0.5048504374465164 hm:0.7633745040016738\n",
      " ==> New best value..loss:0.5037063335885807 hm:0.7636076424357591\n",
      " ==> New best value..loss:0.5031907327321111 hm:0.7656151750211206\n",
      " ==> New best value..loss:0.5015002276216235 hm:0.7665322097689172\n",
      " ==> New best value..loss:0.5011141324529842 hm:0.7684363362258496\n",
      " ==> New best value..loss:0.5002959692964748 hm:0.7708689410698781\n",
      " ==> New best value..loss:0.49790441320866957 hm:0.7712154262661595\n",
      " ==> New best value..loss:0.49760972419563604 hm:0.7714392894571088\n",
      " ==> New best value..loss:0.49681092342551875 hm:0.7730613039663666\n",
      " ==> New best value..loss:0.49633900608335224 hm:0.7736133177195841\n",
      " ==> New best value..loss:0.4954794116166173 hm:0.7742700005231522\n",
      " ==> New best value..loss:0.49460738471576143 hm:0.7743369176338238\n",
      " ==> New best value..loss:0.4945619696257066 hm:0.7758139676183358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.4932785289628165 hm:0.7772533243229985\n",
      " ==> New best value..loss:0.49306043921684733 hm:0.7779862823411358\n",
      " ==> New best value..loss:0.49216672413203183 hm:0.7785503614843162\n",
      " ==> New best value..loss:0.4904333012444632 hm:0.7787643770350225\n",
      " ==> New best value..loss:0.490157062910041 hm:0.7794391738617678\n",
      " ==> New best value..loss:0.4900599547794887 hm:0.7800227013546385\n",
      " ==> New best value..loss:0.4896466032582886 hm:0.7804510457605328\n",
      " ==> New best value..loss:0.48838090774964316 hm:0.7805043307279097\n",
      " ==> New best value..loss:0.48816825358235105 hm:0.7810541872273534\n",
      " ==> New best value..loss:0.48765527897951555 hm:0.7817013128918775\n",
      " ==> New best value..loss:0.486982737876931 hm:0.7827916264046467\n",
      " ==> New best value..loss:0.48620471358299255 hm:0.7842357087559381\n",
      " ==> New best value..loss:0.4861243592233074 hm:0.7845939564140071\n",
      " ==> New best value..loss:0.48564026002981225 hm:0.784915184907291\n",
      "BEST SCORE:  0.784915184907291\n",
      "TRAINING TOOK:  481  s\n",
      "================================================================================\n",
      "alpha: 1 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 1, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6350804050763448 hm:0.569770155566366\n",
      " ==> New best value..loss:0.6328102846940359 hm:0.6363725043285635\n",
      " ==> New best value..loss:0.6262987156709036 hm:0.6545699470671925\n",
      " ==> New best value..loss:0.6052418529987336 hm:0.6615445154632322\n",
      " ==> New best value..loss:0.6020926813284556 hm:0.6758328724914525\n",
      " ==> New best value..loss:0.5961944212516149 hm:0.6780830796464554\n",
      " ==> New best value..loss:0.592661048968633 hm:0.6822288032426365\n",
      " ==> New best value..loss:0.5888828893502553 hm:0.6844056120868336\n",
      " ==> New best value..loss:0.58761651913325 hm:0.6877103344597766\n",
      " ==> New best value..loss:0.5838796933492024 hm:0.6918944279425222\n",
      " ==> New best value..loss:0.5817851920922598 hm:0.6937696857961735\n",
      " ==> New best value..loss:0.5780261327823003 hm:0.6957358499509738\n",
      " ==> New best value..loss:0.5779529541730881 hm:0.6965240727134748\n",
      " ==> New best value..loss:0.5770750015974044 hm:0.6981695580605978\n",
      " ==> New best value..loss:0.574145519733429 hm:0.7039220196017927\n",
      " ==> New best value..loss:0.5725881854693095 hm:0.7084047329054209\n",
      " ==> New best value..loss:0.5709431837002437 hm:0.7094952355526487\n",
      " ==> New best value..loss:0.5695906708637873 hm:0.7130083933611281\n",
      " ==> New best value..loss:0.5685931911071141 hm:0.7139246598214867\n",
      " ==> New best value..loss:0.5672233939170838 hm:0.7150690193788373\n",
      " ==> New best value..loss:0.5660005847613017 hm:0.7163425934845001\n",
      " ==> New best value..loss:0.5652151674032211 hm:0.7181072579487755\n",
      " ==> New best value..loss:0.5628907740116119 hm:0.719627556016394\n",
      " ==> New best value..loss:0.5608762592077255 hm:0.7196283791325055\n",
      " ==> New best value..loss:0.5589998871088028 hm:0.7202443830222572\n",
      " ==> New best value..loss:0.5576466610034306 hm:0.7247529207237415\n",
      " ==> New best value..loss:0.5562579284111658 hm:0.7261937776140751\n",
      " ==> New best value..loss:0.5554142067829768 hm:0.7285678887599677\n",
      " ==> New best value..loss:0.5542769571145375 hm:0.7289515897375693\n",
      " ==> New best value..loss:0.5537549883127213 hm:0.7302678692465762\n",
      " ==> New best value..loss:0.5530885408322016 hm:0.7306724163814822\n",
      " ==> New best value..loss:0.5530268311500549 hm:0.7328524579138567\n",
      " ==> New best value..loss:0.5524293820063273 hm:0.7335508815548927\n",
      " ==> New best value..loss:0.5517073810100556 hm:0.7348328246185009\n",
      " ==> New best value..loss:0.5510883261760076 hm:0.7364762837876779\n",
      " ==> New best value..loss:0.5485850632190704 hm:0.7367940139245738\n",
      " ==> New best value..loss:0.5475887914498647 hm:0.737887130816879\n",
      " ==> New best value..loss:0.5464688917001088 hm:0.73839389999422\n",
      " ==> New best value..loss:0.5459513862927755 hm:0.7404523312778817\n",
      " ==> New best value..loss:0.5451618323723475 hm:0.7427107790461762\n",
      " ==> New best value..loss:0.5439582020044327 hm:0.7432717695965586\n",
      " ==> New best value..loss:0.5437457491954167 hm:0.7457075015748895\n",
      " ==> New best value..loss:0.5418762077887853 hm:0.7460771484157627\n",
      " ==> New best value..loss:0.5403291215499242 hm:0.7461165600995513\n",
      " ==> New best value..loss:0.5391174455483755 hm:0.7464329373159673\n",
      " ==> New best value..loss:0.5362793693939845 hm:0.7466370608784155\n",
      " ==> New best value..loss:0.534803663690885 hm:0.7466409054133303\n",
      " ==> New best value..loss:0.5347126315037409 hm:0.7499060008826283\n",
      " ==> New best value..loss:0.5326410641272863 hm:0.7511388737058408\n",
      " ==> New best value..loss:0.5319177548090617 hm:0.7517809028960782\n",
      " ==> New best value..loss:0.5303202410538991 hm:0.7518156282508079\n",
      " ==> New best value..loss:0.5298368682463964 hm:0.7530976240497623\n",
      " ==> New best value..loss:0.5282316615184148 hm:0.7543150523680273\n",
      " ==> New best value..loss:0.5270500659942627 hm:0.7548056931281267\n",
      " ==> New best value..loss:0.5266457170248031 hm:0.7578201287737726\n",
      " ==> New best value..loss:0.5261678000291189 hm:0.7589188541766064\n",
      " ==> New best value..loss:0.5248803357283275 hm:0.7593913710321509\n",
      " ==> New best value..loss:0.5233219365278879 hm:0.7600487810249823\n",
      " ==> New best value..loss:0.5207928667465845 hm:0.7637862812453694\n",
      "BEST SCORE:  0.7637862812453694\n",
      "TRAINING TOOK:  274  s\n",
      "================================================================================\n",
      "alpha: 0.5 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6193368992497844 hm:0.5484761670188356\n",
      " ==> New best value..loss:0.6182974519268158 hm:0.6455427529389485\n",
      " ==> New best value..loss:0.6153794430917309 hm:0.6635493999002303\n",
      " ==> New best value..loss:0.6130538275164943 hm:0.6651385586321874\n",
      " ==> New best value..loss:0.5915271534073737 hm:0.6662366810379482\n",
      " ==> New best value..loss:0.5878239158661135 hm:0.6724102078837142\n",
      " ==> New best value..loss:0.5809527347164769 hm:0.6813335595586205\n",
      " ==> New best value..loss:0.5801047019420131 hm:0.6882077487086814\n",
      " ==> New best value..loss:0.5692619239130328 hm:0.7006928057589173\n",
      " ==> New best value..loss:0.560182987682281 hm:0.7090277683106303\n",
      " ==> New best value..loss:0.554530680179596 hm:0.7151336931288462\n",
      " ==> New best value..loss:0.5517924793304936 hm:0.715322025957067\n",
      " ==> New best value..loss:0.5452045894438221 hm:0.7205508461010922\n",
      " ==> New best value..loss:0.5441760372730994 hm:0.7209545757895484\n",
      " ==> New best value..loss:0.54282372613107 hm:0.7228983761500466\n",
      " ==> New best value..loss:0.5411300005451325 hm:0.7236783004307081\n",
      " ==> New best value..loss:0.5408624477924839 hm:0.7248128486049756\n",
      " ==> New best value..loss:0.5369274020195007 hm:0.7255287876477252\n",
      " ==> New best value..loss:0.5362507950875067 hm:0.7272502981989979\n",
      " ==> New best value..loss:0.5307728398230768 hm:0.729998504738465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5292888495229906 hm:0.7307452349147441\n",
      " ==> New best value..loss:0.5274026326594814 hm:0.730975335835922\n",
      " ==> New best value..loss:0.5259808926813064 hm:0.7324666335682937\n",
      " ==> New best value..loss:0.5237509223722643 hm:0.733236165051303\n",
      " ==> New best value..loss:0.5226631020345995 hm:0.7342272165935702\n",
      " ==> New best value..loss:0.5183992933842444 hm:0.7345331504927083\n",
      " ==> New best value..loss:0.5179132434629625 hm:0.7382051635849037\n",
      " ==> New best value..loss:0.5175130367279053 hm:0.7392376939659852\n",
      " ==> New best value..loss:0.515199464175009 hm:0.7401151283792993\n",
      " ==> New best value..loss:0.5140825596547896 hm:0.7410368737997044\n",
      " ==> New best value..loss:0.5131816681354276 hm:0.7438220999904304\n",
      " ==> New best value..loss:0.5127527021592663 hm:0.744052538630957\n",
      " ==> New best value..loss:0.5102287386694262 hm:0.7448801881460936\n",
      " ==> New best value..loss:0.5098763848504713 hm:0.74511892728112\n",
      " ==> New best value..loss:0.5097091351785967 hm:0.7485131590178444\n",
      " ==> New best value..loss:0.5082678362246482 hm:0.7485336540367628\n",
      " ==> New best value..loss:0.507921342888186 hm:0.7486794701049136\n",
      " ==> New best value..loss:0.5069125794595287 hm:0.7491781126710526\n",
      " ==> New best value..loss:0.5044237307963833 hm:0.7492673370626167\n",
      " ==> New best value..loss:0.5030888838152732 hm:0.7521424284949757\n",
      " ==> New best value..loss:0.5026772618293762 hm:0.7522541439744624\n",
      " ==> New best value..loss:0.500003061948284 hm:0.7535473893902856\n",
      " ==> New best value..loss:0.49822524862904705 hm:0.7571679234654564\n",
      " ==> New best value..loss:0.4979286809121409 hm:0.7596789818387243\n",
      " ==> New best value..loss:0.49708595679652307 hm:0.7596912741569546\n",
      " ==> New best value..loss:0.49661960044214803 hm:0.7616944780426068\n",
      " ==> New best value..loss:0.49494696047998243 hm:0.7626791844593003\n",
      " ==> New best value..loss:0.49481557357695793 hm:0.7632130466680753\n",
      " ==> New best value..loss:0.4937622287581044 hm:0.7639053309110333\n",
      " ==> New best value..loss:0.49289539264094445 hm:0.7653169332924763\n",
      " ==> New best value..loss:0.4920785763571339 hm:0.7656055347015693\n",
      " ==> New best value..loss:0.4916731330656236 hm:0.766597133464238\n",
      " ==> New best value..loss:0.49117575633910393 hm:0.7668107722702486\n",
      " ==> New best value..loss:0.4910182770221464 hm:0.7684870816073214\n",
      "BEST SCORE:  0.7684870816073214\n",
      "TRAINING TOOK:  276  s\n",
      "================================================================================\n",
      "alpha: 0.05 bs\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 50, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-06, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6402035295963288 hm:0.5966753844815877\n",
      " ==> New best value..loss:0.6389243245124817 hm:0.5991045955061279\n",
      " ==> New best value..loss:0.616589163740476 hm:0.6015687650477661\n",
      " ==> New best value..loss:0.6155850867430369 hm:0.6053113022353842\n",
      " ==> New best value..loss:0.6147951344648998 hm:0.6077785793444165\n",
      " ==> New best value..loss:0.6134632011254628 hm:0.6121842504786541\n",
      " ==> New best value..loss:0.6118740230798722 hm:0.6168818607429846\n",
      " ==> New best value..loss:0.6111761291821798 hm:0.621647536199661\n",
      " ==> New best value..loss:0.6097910702228546 hm:0.6245560299981895\n",
      " ==> New best value..loss:0.6082600831985474 hm:0.6283972290964657\n",
      " ==> New best value..loss:0.6077539503574372 hm:0.6311629304667753\n",
      " ==> New best value..loss:0.6062464018662771 hm:0.6352454111159113\n",
      " ==> New best value..loss:0.6049850205580394 hm:0.6391355280148028\n",
      " ==> New best value..loss:0.6035536269346873 hm:0.6438128905053276\n",
      " ==> New best value..loss:0.6020892679691314 hm:0.6485505340399088\n",
      " ==> New best value..loss:0.6007323265075684 hm:0.6519987536207851\n",
      " ==> New best value..loss:0.6003907879193624 hm:0.6539623454552851\n",
      " ==> New best value..loss:0.5983859697977701 hm:0.6579841325838928\n",
      " ==> New best value..loss:0.5970768958330155 hm:0.6611003554010056\n",
      " ==> New best value..loss:0.5953912625710169 hm:0.6644420975839457\n",
      " ==> New best value..loss:0.5952670246362686 hm:0.6660225371596944\n",
      " ==> New best value..loss:0.5950545986493428 hm:0.6672019134736459\n",
      " ==> New best value..loss:0.5949931422869364 hm:0.6687849384432126\n",
      " ==> New best value..loss:0.5929852922757467 hm:0.6719357326943699\n",
      " ==> New best value..loss:0.5905111600955327 hm:0.6757158932247043\n",
      " ==> New best value..loss:0.5894164214531581 hm:0.6783578966167448\n",
      " ==> New best value..loss:0.5890719085931778 hm:0.6794113862682299\n",
      " ==> New best value..loss:0.5882236043612162 hm:0.6806192436599484\n",
      " ==> New best value..loss:0.5874984472990036 hm:0.6827270075039955\n",
      " ==> New best value..loss:0.5866576333840688 hm:0.6835838777752218\n",
      " ==> New best value..loss:0.5865374058485031 hm:0.6851133518425703\n",
      " ==> New best value..loss:0.5859086106220881 hm:0.6865108212005246\n",
      " ==> New best value..loss:0.5852881769339243 hm:0.6875594092100021\n",
      " ==> New best value..loss:0.5846699684858322 hm:0.6884290562444042\n",
      " ==> New best value..loss:0.5834473162889481 hm:0.6902376778058751\n",
      " ==> New best value..loss:0.5823864738146464 hm:0.6912021796315415\n",
      " ==> New best value..loss:0.5817886809508006 hm:0.6919773421458877\n",
      " ==> New best value..loss:0.5809464395046234 hm:0.693702549792043\n",
      " ==> New best value..loss:0.5806836108366649 hm:0.6943239143053197\n",
      " ==> New best value..loss:0.580452545483907 hm:0.6947380608692766\n",
      " ==> New best value..loss:0.5788977901140849 hm:0.6956896042860324\n",
      " ==> New best value..loss:0.5785665849844615 hm:0.6969189030537724\n",
      " ==> New best value..loss:0.578114660580953 hm:0.6973102112740406\n",
      " ==> New best value..loss:0.5774752030769984 hm:0.6979095616059944\n",
      " ==> New best value..loss:0.5771882017453511 hm:0.6981982260119404\n",
      " ==> New best value..loss:0.5755680859088897 hm:0.6995760111060846\n",
      " ==> New best value..loss:0.575421804189682 hm:0.7003907690021726\n",
      " ==> New best value..loss:0.5747861564159393 hm:0.7007010114244572\n",
      " ==> New best value..loss:0.5738450249036153 hm:0.7014089363859813\n",
      " ==> New best value..loss:0.5733162532250087 hm:0.7022208845076631\n",
      " ==> New best value..loss:0.5731117079655329 hm:0.7022884598642503\n",
      " ==> New best value..loss:0.5707074761390686 hm:0.7045857230267271\n",
      " ==> New best value..loss:0.5696072399616241 hm:0.7054723165735509\n",
      " ==> New best value..loss:0.5686741709709168 hm:0.7061633314166615\n",
      " ==> New best value..loss:0.5686617960532506 hm:0.7064451090572638\n",
      " ==> New best value..loss:0.5674410283565521 hm:0.7070468339055643\n",
      " ==> New best value..loss:0.5670497685670852 hm:0.7075461972299467\n",
      " ==> New best value..loss:0.5653895109891891 hm:0.7088403191004656\n",
      " ==> New best value..loss:0.5640935639540354 hm:0.7110501085611353\n",
      " ==> New best value..loss:0.5630295604467392 hm:0.7118056253837621\n",
      " ==> New best value..loss:0.5626727958520253 hm:0.7125389368977887\n",
      " ==> New best value..loss:0.5611618598302205 hm:0.713401540865843\n",
      " ==> New best value..loss:0.5599152038494746 hm:0.7139833696063379\n",
      " ==> New best value..loss:0.5582585275173187 hm:0.7155234280499089\n",
      " ==> New best value..loss:0.5576618234316508 hm:0.7164003382849615\n",
      " ==> New best value..loss:0.5535969833532969 hm:0.7198247961236149\n",
      " ==> New best value..loss:0.5527732819318771 hm:0.7198268113434896\n",
      " ==> New best value..loss:0.5507639229297638 hm:0.72127119577014\n",
      " ==> New best value..loss:0.5491629709800084 hm:0.7232359506880216\n",
      " ==> New best value..loss:0.5482209612925847 hm:0.7241082380425077\n",
      " ==> New best value..loss:0.5479137053092321 hm:0.7251921358311177\n",
      " ==> New best value..loss:0.5460023383299509 hm:0.730551666358852\n",
      " ==> New best value..loss:0.5443822145462036 hm:0.7313395108586246\n",
      " ==> New best value..loss:0.5440682778755824 hm:0.7324984007373119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5439172049363454 hm:0.7339652183312204\n",
      " ==> New best value..loss:0.5418542792399724 hm:0.7380138271040745\n",
      " ==> New best value..loss:0.5374140828847885 hm:0.7382444229990928\n",
      " ==> New best value..loss:0.5350431551535925 hm:0.7387800532551344\n",
      " ==> New best value..loss:0.5347143799066544 hm:0.7389524863406146\n",
      " ==> New best value..loss:0.5345651706059774 hm:0.7403051364646972\n",
      " ==> New best value..loss:0.5327365775903066 hm:0.7410033869670408\n",
      " ==> New best value..loss:0.5323325842618942 hm:0.741885936000431\n",
      " ==> New best value..loss:0.5321142146984736 hm:0.7420397775495922\n",
      " ==> New best value..loss:0.5311592052380244 hm:0.7422313629065803\n",
      " ==> New best value..loss:0.530291736125946 hm:0.7424523052687827\n",
      " ==> New best value..loss:0.5297740558783214 hm:0.742494479770574\n",
      " ==> New best value..loss:0.5284297317266464 hm:0.7446234057816955\n",
      " ==> New best value..loss:0.5264718184868494 hm:0.7448124514755204\n",
      " ==> New best value..loss:0.5262720435857773 hm:0.7453111719450679\n",
      " ==> New best value..loss:0.5255629519621531 hm:0.7479898446851134\n",
      " ==> New best value..loss:0.5246637493371964 hm:0.7481105422378582\n",
      " ==> New best value..loss:0.5236953785022099 hm:0.7497578469808889\n",
      " ==> New best value..loss:0.5233632306257884 hm:0.7502131570462564\n",
      " ==> New best value..loss:0.5233594387769699 hm:0.7503646811747207\n",
      " ==> New best value..loss:0.5212510913610459 hm:0.7514475785766744\n",
      " ==> New best value..loss:0.5211122890313467 hm:0.7516792388444089\n",
      " ==> New best value..loss:0.51944540143013 hm:0.7544005011172228\n",
      " ==> New best value..loss:0.5193881114323934 hm:0.7551373417551294\n",
      " ==> New best value..loss:0.5189538151025772 hm:0.756349810931084\n",
      " ==> New best value..loss:0.5175893723964691 hm:0.7569071090309998\n",
      " ==> New best value..loss:0.517186297972997 hm:0.7572427256489476\n",
      " ==> New best value..loss:0.5163067738215129 hm:0.7588369444968986\n",
      " ==> New best value..loss:0.5160777707894643 hm:0.7628209504762761\n",
      " ==> New best value..loss:0.5142716258764267 hm:0.7633095591839805\n",
      " ==> New best value..loss:0.5134340027968088 hm:0.763348378604034\n",
      " ==> New best value..loss:0.5125938067833583 hm:0.764627461404929\n",
      " ==> New best value..loss:0.5125637988249461 hm:0.7666017395561608\n",
      " ==> New best value..loss:0.5111046582460403 hm:0.7666301419768509\n",
      " ==> New best value..loss:0.510113196571668 hm:0.7670228059899382\n",
      " ==> New best value..loss:0.5093364636103312 hm:0.7683406347012873\n",
      " ==> New best value..loss:0.5084691007932027 hm:0.768862662495468\n",
      " ==> New best value..loss:0.5074338525533676 hm:0.7693893552578207\n",
      " ==> New best value..loss:0.5072990616162618 hm:0.7695739455687026\n",
      " ==> New best value..loss:0.5055958678325018 hm:0.7717843022556171\n",
      " ==> New best value..loss:0.5053828100363413 hm:0.7735043919121564\n",
      "BEST SCORE:  0.7735043919121564\n",
      "TRAINING TOOK:  283  s\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'tanh'\n",
    "\n",
    "params_dict['epochs'] = 30 \n",
    "params_dict['print_every'] = 19\n",
    "\n",
    "params_dict['fc1'] = 200\n",
    "params_dict['fc2'] = 30\n",
    "params_dict['drop_fc'] = 0.4\n",
    "params_dict['fc'] = create_fc( params_dict['fc1'],\n",
    "                    params_dict['fc2'],params_dict['drop_fc'])\n",
    "        \n",
    "\n",
    "alpha_lst = [1, 0.5, 0.05]\n",
    "lr_lst = [7e-5, 7e-6]\n",
    "bs_lst = [30, 50]\n",
    "\n",
    "nn_tanh= []\n",
    "scores_tanh = []\n",
    "\n",
    "for lr in lr_lst:\n",
    "    params_dict['lr'] = lr\n",
    "    \n",
    "    for bs in bs_lst:\n",
    "        params_dict['batch_size'] = bs\n",
    "\n",
    "        for alpha in alpha_lst:\n",
    "            params_dict['tan_a'] = alpha\n",
    "\n",
    "            print('='*80)\n",
    "            print('alpha:', alpha, 'bs', )\n",
    "            d_start = datetime.now() \n",
    "            best_score, classifier = do_training( df_in1, params_dict, criterion)\n",
    "            nn_tanh.append(classifier)\n",
    "            scores_tanh.append(best_score)\n",
    "\n",
    "            print('BEST SCORE: ', best_score)\n",
    "            print('TRAINING TOOK: ', ( datetime.now() - d_start ).seconds, ' s'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11,  8,  6,  7,  3,  1,  5,  4,  2,  0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(scores_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. test de-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6187478620178846 hm:0.582793437686237\n",
      " ==> New best value..loss:0.6075767375984971 hm:0.6120527624427844\n",
      " ==> New best value..loss:0.5969545464126431 hm:0.652552547068315\n",
      " ==> New best value..loss:0.5943502345863654 hm:0.6644549155597278\n",
      " ==> New best value..loss:0.5888529061054697 hm:0.6723466264083655\n",
      " ==> New best value..loss:0.579917236250274 hm:0.6801194284307024\n",
      " ==> New best value..loss:0.5753704704800431 hm:0.685400100376497\n",
      " ==> New best value..loss:0.5685809412781073 hm:0.6954779077448645\n",
      " ==> New best value..loss:0.5601949843825126 hm:0.7007892182740623\n",
      " ==> New best value..loss:0.5594322833479667 hm:0.7016362007371897\n",
      " ==> New best value..loss:0.5522294299943107 hm:0.7101138402954598\n",
      " ==> New best value..loss:0.550817000622652 hm:0.7103132612065239\n",
      " ==> New best value..loss:0.5496511222148428 hm:0.7162479070289564\n",
      " ==> New best value..loss:0.5451856170381818 hm:0.729344984903187\n",
      " ==> New best value..loss:0.5411443746819788 hm:0.7318230931642218\n",
      " ==> New best value..loss:0.5270441107603968 hm:0.7324980423283037\n",
      " ==> New best value..loss:0.525659655429879 hm:0.7343933804711323\n",
      " ==> New best value..loss:0.5243529704760532 hm:0.739797757384085\n",
      " ==> New best value..loss:0.5206806860408004 hm:0.7400436153030467\n",
      " ==> New best value..loss:0.5203743681919818 hm:0.741476220075184\n",
      " ==> New best value..loss:0.5142016155379159 hm:0.743344513358202\n",
      " ==> New best value..loss:0.5121891389087755 hm:0.749428026291451\n",
      " ==> New best value..loss:0.5088366580252744 hm:0.7525552442766164\n",
      "BEST SCORE:  0.7525552442766164\n",
      "TRAINING TOOK:  533  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6017604531074057 hm:0.6117247257690227\n",
      " ==> New best value..loss:0.6007047514526211 hm:0.6180544573014747\n",
      " ==> New best value..loss:0.5832266083785466 hm:0.685762167845667\n",
      " ==> New best value..loss:0.5697155357623587 hm:0.6990591317583611\n",
      " ==> New best value..loss:0.5602421079363141 hm:0.7129398976613491\n",
      " ==> New best value..loss:0.5352476847415067 hm:0.7166915196956412\n",
      " ==> New best value..loss:0.529677439252941 hm:0.7214476323961053\n",
      " ==> New best value..loss:0.5245675547998778 hm:0.7310418299067996\n",
      " ==> New best value..loss:0.5207015640881597 hm:0.7379911643534474\n",
      " ==> New best value..loss:0.5155406390525856 hm:0.7408222396758464\n",
      " ==> New best value..loss:0.5139680769370527 hm:0.7408271508120349\n",
      " ==> New best value..loss:0.5075573483291937 hm:0.745779646543022\n",
      " ==> New best value..loss:0.4995781992162977 hm:0.7552352458388145\n",
      " ==> New best value..loss:0.4990990751860093 hm:0.7592585926116886\n",
      " ==> New best value..loss:0.49730874993363205 hm:0.7593250440497153\n",
      " ==> New best value..loss:0.4833920569140084 hm:0.7608981491230565\n",
      " ==> New best value..loss:0.48291052786671385 hm:0.766404818506085\n",
      " ==> New best value..loss:0.4759387281932393 hm:0.7673813336081616\n",
      " ==> New best value..loss:0.4739987227913676 hm:0.7700862116166055\n",
      " ==> New best value..loss:0.46762629078549084 hm:0.7781728250304266\n",
      "BEST SCORE:  0.7781728250304266\n",
      "TRAINING TOOK:  535  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6096282573241107 hm:0.6188960993535562\n",
      " ==> New best value..loss:0.6082971337831246 hm:0.6191291724677483\n",
      " ==> New best value..loss:0.6047762283739054 hm:0.6246316762658657\n",
      " ==> New best value..loss:0.6000907713512205 hm:0.6588127699875734\n",
      " ==> New best value..loss:0.587922770459697 hm:0.6756168290726434\n",
      " ==> New best value..loss:0.5755756441152321 hm:0.6840328453079566\n",
      " ==> New best value..loss:0.5686933043992745 hm:0.6956013070425964\n",
      " ==> New best value..loss:0.5607460461697489 hm:0.6972937000658475\n",
      " ==> New best value..loss:0.5567566954864646 hm:0.7008949415223545\n",
      " ==> New best value..loss:0.554794080414862 hm:0.7026802391395366\n",
      " ==> New best value..loss:0.5538744712775608 hm:0.7099419590319178\n",
      " ==> New best value..loss:0.553216556895454 hm:0.7155631137059008\n",
      " ==> New best value..loss:0.5487847457516868 hm:0.7171750239367888\n",
      " ==> New best value..loss:0.5483177776606578 hm:0.7177306929860536\n",
      " ==> New best value..loss:0.5410042556951631 hm:0.7220009910897025\n",
      " ==> New best value..loss:0.5358970727560655 hm:0.7233456562678854\n",
      " ==> New best value..loss:0.5342421857815869 hm:0.729529440281528\n",
      " ==> New best value..loss:0.5325782552080335 hm:0.730943497203119\n",
      " ==> New best value..loss:0.5298123961349703 hm:0.736498576636589\n",
      " ==> New best value..loss:0.5277831841189906 hm:0.7390263609202148\n",
      " ==> New best value..loss:0.5239846037243897 hm:0.7407119822134173\n",
      " ==> New best value..loss:0.5233494296388806 hm:0.7413632635805414\n",
      " ==> New best value..loss:0.5171324048402175 hm:0.7433198621174277\n",
      " ==> New best value..loss:0.5138780013570245 hm:0.7450501756115833\n",
      " ==> New best value..loss:0.513547273177021 hm:0.747755413922078\n",
      " ==> New best value..loss:0.5117693408480231 hm:0.7508685910081339\n",
      " ==> New best value..loss:0.5055869938629978 hm:0.751507212841736\n",
      " ==> New best value..loss:0.5031029627008258 hm:0.7541630644108732\n",
      " ==> New best value..loss:0.501593383977998 hm:0.7569093179671288\n",
      " ==> New best value..loss:0.49931724847487685 hm:0.758229136538608\n",
      " ==> New best value..loss:0.49296371948044254 hm:0.7602385347976769\n",
      " ==> New best value..loss:0.4929470906280122 hm:0.7610008083045503\n",
      " ==> New best value..loss:0.4926927382091306 hm:0.7626000887674191\n",
      "BEST SCORE:  0.7626000887674191\n",
      "TRAINING TOOK:  546  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.613550102593852 hm:0.6044089609031805\n",
      " ==> New best value..loss:0.6116615884444293 hm:0.6731448505366545\n",
      " ==> New best value..loss:0.6027237971623739 hm:0.6770354899870906\n",
      " ==> New best value..loss:0.5862043686941558 hm:0.6781152260406227\n",
      " ==> New best value..loss:0.578347220140345 hm:0.6863044525468047\n",
      " ==> New best value..loss:0.5736643192814845 hm:0.6888243133367293\n",
      " ==> New best value..loss:0.5694618587400399 hm:0.6918407734053228\n",
      " ==> New best value..loss:0.562798311605173 hm:0.6965861960972253\n",
      " ==> New best value..loss:0.5578353679647633 hm:0.6994636033018661\n",
      " ==> New best value..loss:0.5567359801600961 hm:0.705568190382913\n",
      " ==> New best value..loss:0.5567174325971043 hm:0.7059622149830624\n",
      " ==> New best value..loss:0.5551821571939132 hm:0.7099460182936602\n",
      " ==> New best value..loss:0.54975579123871 hm:0.7130024625277165\n",
      " ==> New best value..loss:0.5481579882257125 hm:0.7132726271038293\n",
      " ==> New best value..loss:0.5463222060717788 hm:0.7151892811908257\n",
      " ==> New best value..loss:0.5443677136711046 hm:0.7224080965016768\n",
      " ==> New best value..loss:0.5408041880411261 hm:0.7227346373077222\n",
      " ==> New best value..loss:0.5393046362727296 hm:0.7241217273127477\n",
      " ==> New best value..loss:0.5369039674599966 hm:0.7242989585015903\n",
      " ==> New best value..loss:0.5315946474963543 hm:0.7282745699951265\n",
      " ==> New best value..loss:0.5315004931945427 hm:0.7344499452120679\n",
      " ==> New best value..loss:0.5251733917816013 hm:0.7385411952578615\n",
      " ==> New best value..loss:0.523173814310747 hm:0.7392894900160927\n",
      " ==> New best value..loss:0.5195227227374619 hm:0.7409220595582142\n",
      " ==> New best value..loss:0.5162152285669365 hm:0.7424071584276241\n",
      " ==> New best value..loss:0.5160511580168032 hm:0.7470995067410303\n",
      " ==> New best value..loss:0.515672919212603 hm:0.7482048007828507\n",
      " ==> New best value..loss:0.5146944183929294 hm:0.748694931671655\n",
      " ==> New best value..loss:0.5123605833334082 hm:0.7498306538619034\n",
      " ==> New best value..loss:0.5113091392844331 hm:0.7499573636340281\n",
      " ==> New best value..loss:0.5080155756543664 hm:0.75177434993952\n",
      " ==> New best value..loss:0.5062398115793864 hm:0.7534848511933819\n",
      " ==> New best value..loss:0.5058625077500063 hm:0.7544409442063472\n",
      " ==> New best value..loss:0.5051910754512338 hm:0.7583492513218333\n",
      " ==> New best value..loss:0.5027041636845645 hm:0.7596582200059973\n",
      " ==> New best value..loss:0.4988207951480267 hm:0.7602839067299564\n",
      " ==> New best value..loss:0.4960266959433462 hm:0.7610259263725652\n",
      "BEST SCORE:  0.7610259263725652\n",
      "TRAINING TOOK:  551  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.609291078413234 hm:0.5858415706887488\n",
      " ==> New best value..loss:0.6087973117828369 hm:0.6004826154998543\n",
      " ==> New best value..loss:0.6087317811507805 hm:0.6202654117638501\n",
      " ==> New best value..loss:0.5920127285461799 hm:0.6670831690666251\n",
      " ==> New best value..loss:0.5846764071314943 hm:0.6743498193006136\n",
      " ==> New best value..loss:0.5781412580434013 hm:0.6853107643961095\n",
      " ==> New best value..loss:0.573919052586836 hm:0.6895168746613859\n",
      " ==> New best value..loss:0.5738269283491022 hm:0.692681787755463\n",
      " ==> New best value..loss:0.5654050894812042 hm:0.7018530633050539\n",
      " ==> New best value..loss:0.5607852778014015 hm:0.7060902396509406\n",
      " ==> New best value..loss:0.5587664211497587 hm:0.7074289121087943\n",
      " ==> New best value..loss:0.5577714998348087 hm:0.7083144945937399\n",
      " ==> New best value..loss:0.5568423610107571 hm:0.7085469529304941\n",
      " ==> New best value..loss:0.555912034184325 hm:0.7110635623395146\n",
      " ==> New best value..loss:0.5523975719423855 hm:0.7180204079406166\n",
      " ==> New best value..loss:0.5521559949014702 hm:0.7189185415332783\n",
      " ==> New best value..loss:0.5447886650468788 hm:0.7221433194566033\n",
      " ==> New best value..loss:0.5379791855812073 hm:0.7276289670286848\n",
      " ==> New best value..loss:0.5349078756921432 hm:0.728400545942171\n",
      " ==> New best value..loss:0.5340657748428046 hm:0.7299529635182945\n",
      " ==> New best value..loss:0.5325239949366626 hm:0.7308204205408299\n",
      " ==> New best value..loss:0.5305273971136879 hm:0.731012375588671\n",
      " ==> New best value..loss:0.5303051372369131 hm:0.7335659810894091\n",
      " ==> New best value..loss:0.526288686429753 hm:0.7363443863578537\n",
      " ==> New best value..loss:0.5249982832693586 hm:0.73942784019265\n",
      " ==> New best value..loss:0.5244218718771841 hm:0.7407189214809928\n",
      "BEST SCORE:  0.7407189214809928\n",
      "TRAINING TOOK:  552  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6029468356416776 hm:0.5747645231647882\n",
      " ==> New best value..loss:0.6028406471014023 hm:0.6416665143217694\n",
      " ==> New best value..loss:0.5902030370556391 hm:0.6477777222024111\n",
      " ==> New best value..loss:0.5899068461014674 hm:0.656509372431127\n",
      " ==> New best value..loss:0.5891034700549566 hm:0.6606030474774952\n",
      " ==> New best value..loss:0.5817783274329625 hm:0.6734317067852589\n",
      " ==> New best value..loss:0.5756483169702383 hm:0.6879234134609122\n",
      " ==> New best value..loss:0.5680663740405669 hm:0.6952386351146554\n",
      " ==> New best value..loss:0.5647840247704432 hm:0.7004940113505682\n",
      " ==> New best value..loss:0.5619637140860925 hm:0.7011437399191632\n",
      " ==> New best value..loss:0.5614980040834501 hm:0.7014345493649353\n",
      " ==> New best value..loss:0.5596185744954989 hm:0.708462391726585\n",
      " ==> New best value..loss:0.5576907281692212 hm:0.7089582456487434\n",
      " ==> New best value..loss:0.5567543088243558 hm:0.7134806233946581\n",
      " ==> New best value..loss:0.5531005412340164 hm:0.7156720242874243\n",
      " ==> New best value..loss:0.5459410296036646 hm:0.7161999710606097\n",
      " ==> New best value..loss:0.5376447221407523 hm:0.724952229681629\n",
      " ==> New best value..loss:0.5340336400728959 hm:0.7275180061973672\n",
      " ==> New best value..loss:0.5309236445105993 hm:0.7323528707833467\n",
      " ==> New best value..loss:0.5262363673402712 hm:0.7330464966762543\n",
      " ==> New best value..loss:0.5254126265645027 hm:0.7376430537808455\n",
      " ==> New best value..loss:0.5201956773033509 hm:0.7395993688555662\n",
      " ==> New best value..loss:0.5192155299278406 hm:0.7448494305325347\n",
      " ==> New best value..loss:0.5104928698677283 hm:0.7481997524878732\n",
      " ==> New best value..loss:0.5073262069087762 hm:0.7496548306972182\n",
      " ==> New best value..loss:0.5048291780627691 hm:0.7521205116118113\n",
      " ==> New best value..loss:0.5045985419016618 hm:0.7551598541394583\n",
      " ==> New best value..loss:0.5045733990577551 hm:0.7555792543919395\n",
      " ==> New best value..loss:0.5010636787001903 hm:0.7619947034186886\n",
      " ==> New best value..loss:0.49925870448350906 hm:0.7634017431605478\n",
      " ==> New best value..loss:0.4919098506753261 hm:0.7638602091826726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.4915426493837283 hm:0.7643927879595057\n",
      " ==> New best value..loss:0.48961145889300567 hm:0.7657019144730779\n",
      " ==> New best value..loss:0.4860831338625688 hm:0.7678971583032422\n",
      " ==> New best value..loss:0.4827446026297716 hm:0.7718059190553199\n",
      " ==> New best value..loss:0.48230829949562365 hm:0.7726253244346873\n",
      "BEST SCORE:  0.7726253244346873\n",
      "TRAINING TOOK:  555  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6093855422735214 hm:0.5761128699562006\n",
      " ==> New best value..loss:0.6089081960916519 hm:0.5824308801167848\n",
      " ==> New best value..loss:0.6046192353963852 hm:0.5959818661121121\n",
      " ==> New best value..loss:0.6022622060775756 hm:0.6558760261412725\n",
      " ==> New best value..loss:0.5901980954408645 hm:0.6771517822205327\n",
      " ==> New best value..loss:0.5787377482652665 hm:0.6827774659138983\n",
      " ==> New best value..loss:0.5655543148517609 hm:0.6837479788915406\n",
      " ==> New best value..loss:0.5653776717185974 hm:0.6849837767552344\n",
      " ==> New best value..loss:0.5652387148141861 hm:0.6922785377004972\n",
      " ==> New best value..loss:0.5649502503871918 hm:0.6967809758388026\n",
      " ==> New best value..loss:0.56076191842556 hm:0.6990930790510888\n",
      " ==> New best value..loss:0.5528947740793229 hm:0.7008282495565216\n",
      " ==> New best value..loss:0.5521609461307526 hm:0.7085814505273875\n",
      " ==> New best value..loss:0.5470606362819672 hm:0.7112022406053672\n",
      " ==> New best value..loss:0.5443501478433609 hm:0.7128403131861563\n",
      " ==> New best value..loss:0.5425484770536423 hm:0.7131457993837482\n",
      " ==> New best value..loss:0.5424461430311203 hm:0.7181942805904622\n",
      " ==> New best value..loss:0.5396381717920303 hm:0.7204492843094269\n",
      " ==> New best value..loss:0.5374905508756638 hm:0.7242016858126896\n",
      " ==> New best value..loss:0.5346057862043381 hm:0.72579560925463\n",
      " ==> New best value..loss:0.5309111052751541 hm:0.7302954950221836\n",
      " ==> New best value..loss:0.5306285279989242 hm:0.7317852436376737\n",
      " ==> New best value..loss:0.530423315167427 hm:0.7344208595545308\n",
      " ==> New best value..loss:0.5256965154409409 hm:0.7357409474148998\n",
      " ==> New best value..loss:0.5216557067632676 hm:0.7359615845393273\n",
      " ==> New best value..loss:0.5182363268733025 hm:0.7390704737676385\n",
      "BEST SCORE:  0.7390704737676385\n",
      "TRAINING TOOK:  545  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5986877305834901 hm:0.5763171438972647\n",
      " ==> New best value..loss:0.5985476631744235 hm:0.5976228934049728\n",
      " ==> New best value..loss:0.5976401818733589 hm:0.6132812762691071\n",
      " ==> New best value..loss:0.594348867149914 hm:0.662874767865372\n",
      " ==> New best value..loss:0.5797601944091273 hm:0.675804513774966\n",
      " ==> New best value..loss:0.5721778670946757 hm:0.6789767379732583\n",
      " ==> New best value..loss:0.5706505588456696 hm:0.6825624749770055\n",
      " ==> New best value..loss:0.5690860123026604 hm:0.6857705195738653\n",
      " ==> New best value..loss:0.5688872202938678 hm:0.6907581831440034\n",
      " ==> New best value..loss:0.5679087007746977 hm:0.6916404288370979\n",
      " ==> New best value..loss:0.566271551099478 hm:0.6967454955203285\n",
      " ==> New best value..loss:0.5653031836537754 hm:0.6977842659230055\n",
      " ==> New best value..loss:0.5630461766439325 hm:0.6980551664320308\n",
      " ==> New best value..loss:0.5622437111302918 hm:0.702200563085954\n",
      " ==> New best value..loss:0.558390703271417 hm:0.7051866252720917\n",
      " ==> New best value..loss:0.5568337551518983 hm:0.7073558899643193\n",
      " ==> New best value..loss:0.5525840596825469 hm:0.7106192813404505\n",
      " ==> New best value..loss:0.5502338064651863 hm:0.713587474847774\n",
      " ==> New best value..loss:0.5488236569890789 hm:0.7163489771175978\n",
      " ==> New best value..loss:0.5479484591998306 hm:0.7211621768580071\n",
      " ==> New best value..loss:0.5456290011312447 hm:0.7236663306422979\n",
      " ==> New best value..loss:0.5451406287211998 hm:0.7246698352416527\n",
      " ==> New best value..loss:0.5450278532271292 hm:0.7303326129761134\n",
      " ==> New best value..loss:0.5343376392242956 hm:0.734168522263884\n",
      " ==> New best value..loss:0.5341025655176125 hm:0.7344387206686168\n",
      " ==> New best value..loss:0.5295914674506468 hm:0.7356083954205672\n",
      " ==> New best value..loss:0.5269947624674031 hm:0.7372630301525805\n",
      " ==> New best value..loss:0.5238684567750669 hm:0.7411918691401452\n",
      "BEST SCORE:  0.7411918691401452\n",
      "TRAINING TOOK:  544  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.617918886244297 hm:0.5946999037871874\n",
      " ==> New best value..loss:0.6133042040925759 hm:0.6015071294068901\n",
      " ==> New best value..loss:0.6076001152396202 hm:0.6296682488224015\n",
      " ==> New best value..loss:0.6032643862641774 hm:0.6569944241173128\n",
      " ==> New best value..loss:0.5990518944767805 hm:0.6677913704028164\n",
      " ==> New best value..loss:0.5895683599206117 hm:0.675534676611017\n",
      " ==> New best value..loss:0.5890367082678355 hm:0.6765100887127357\n",
      " ==> New best value..loss:0.581466175042666 hm:0.6827026958959521\n",
      " ==> New best value..loss:0.5755145331987968 hm:0.6862134484594535\n",
      " ==> New best value..loss:0.5669228463218763 hm:0.6908338372160092\n",
      " ==> New best value..loss:0.5657387203895129 hm:0.6923204490725017\n",
      " ==> New best value..loss:0.5612315959655322 hm:0.693964953406852\n",
      " ==> New best value..loss:0.5583530016816579 hm:0.6980015861665673\n",
      " ==> New best value..loss:0.5577776122551698 hm:0.7032585600661516\n",
      " ==> New best value..loss:0.5555870710657194 hm:0.7079194236995546\n",
      " ==> New best value..loss:0.5525756919613252 hm:0.7096173608126051\n",
      " ==> New best value..loss:0.5502689016553072 hm:0.7101368418267974\n",
      " ==> New best value..loss:0.5476764085201117 hm:0.7126181382476215\n",
      " ==> New best value..loss:0.5437530668882223 hm:0.714307591859513\n",
      " ==> New best value..loss:0.5418328362015578 hm:0.7155932897931988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5375837253836485 hm:0.7190166329448551\n",
      " ==> New best value..loss:0.536826932659516 hm:0.7214185680276752\n",
      " ==> New best value..loss:0.5341767886510262 hm:0.721862488494713\n",
      " ==> New best value..loss:0.5333187161729886 hm:0.7219428448982784\n",
      " ==> New best value..loss:0.5284135685517237 hm:0.7259034642677824\n",
      " ==> New best value..loss:0.5273823142051697 hm:0.7262171214686987\n",
      " ==> New best value..loss:0.5268515528967748 hm:0.7265244947614443\n",
      " ==> New best value..loss:0.5246145020310695 hm:0.7276755040966844\n",
      " ==> New best value..loss:0.5238546883830657 hm:0.7286185501633328\n",
      " ==> New best value..loss:0.5200646138535097 hm:0.7299409347415913\n",
      " ==> New best value..loss:0.5198436714708805 hm:0.7303436181071417\n",
      " ==> New best value..loss:0.5180088482224025 hm:0.7327990323745917\n",
      " ==> New best value..loss:0.5160361872269557 hm:0.7359619728656522\n",
      " ==> New best value..loss:0.5109162680231608 hm:0.7368764189853687\n",
      " ==> New best value..loss:0.5093016893817828 hm:0.7413979756443981\n",
      " ==> New best value..loss:0.5092165040282103 hm:0.7431704450207011\n",
      "BEST SCORE:  0.7431704450207011\n",
      "TRAINING TOOK:  540  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6013952268629658 hm:0.6076530943932504\n",
      " ==> New best value..loss:0.5876162429245151 hm:0.6739736733967174\n",
      " ==> New best value..loss:0.5831357733327516 hm:0.6771540704724166\n",
      " ==> New best value..loss:0.5591939085600327 hm:0.6923937043665813\n",
      " ==> New best value..loss:0.5519069354144894 hm:0.7055454939672985\n",
      " ==> New best value..loss:0.544130452433411 hm:0.7128653641624954\n",
      " ==> New best value..loss:0.543767158474241 hm:0.7183266821413982\n",
      " ==> New best value..loss:0.5393881031445095 hm:0.7226026135735852\n",
      " ==> New best value..loss:0.537805226384377 hm:0.7264167070193465\n",
      " ==> New best value..loss:0.5260724930130706 hm:0.730880980898975\n",
      " ==> New best value..loss:0.5238943245946145 hm:0.7379610414524214\n",
      " ==> New best value..loss:0.5156023660484625 hm:0.738837935505645\n",
      " ==> New best value..loss:0.5092830937735888 hm:0.738942526610603\n",
      " ==> New best value..loss:0.5056540193606396 hm:0.7436707092981855\n",
      " ==> New best value..loss:0.5018704743409643 hm:0.7463799314933276\n",
      " ==> New best value..loss:0.5006897425164982 hm:0.7499629556108872\n",
      " ==> New best value..loss:0.49690029754930615 hm:0.7504984693221106\n",
      " ==> New best value..loss:0.4934380413318167 hm:0.7541630921153393\n",
      " ==> New best value..loss:0.4899811261162466 hm:0.7552242437640796\n",
      " ==> New best value..loss:0.48901566315670403 hm:0.7568167270728707\n",
      " ==> New best value..loss:0.4883893241687697 hm:0.7592155374352373\n",
      "BEST SCORE:  0.7592155374352373\n",
      "TRAINING TOOK:  529  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6032769300189673 hm:0.5923939837587228\n",
      " ==> New best value..loss:0.6025123251419441 hm:0.6354429211668451\n",
      " ==> New best value..loss:0.5908936010856255 hm:0.669965055987121\n",
      " ==> New best value..loss:0.580652255637973 hm:0.67721172674092\n",
      " ==> New best value..loss:0.5757813366020427 hm:0.6794388090558107\n",
      " ==> New best value..loss:0.5729183420246723 hm:0.6933402657564094\n",
      " ==> New best value..loss:0.5664576204384074 hm:0.6958566065814128\n",
      " ==> New best value..loss:0.5576159369711783 hm:0.6997232794104343\n",
      " ==> New best value..loss:0.5503912702494976 hm:0.7047019597788193\n",
      " ==> New best value..loss:0.5500174842628778 hm:0.7100196352619208\n",
      " ==> New best value..loss:0.5449036862335953 hm:0.7128900944282501\n",
      " ==> New best value..loss:0.542093414886325 hm:0.7155161304851082\n",
      " ==> New best value..loss:0.539524573321436 hm:0.7183566826006716\n",
      " ==> New best value..loss:0.5392342729895723 hm:0.719076275304817\n",
      " ==> New best value..loss:0.5379955897144243 hm:0.7233832683946743\n",
      " ==> New best value..loss:0.5334233664998821 hm:0.7240808699221483\n",
      " ==> New best value..loss:0.5322208667502684 hm:0.7251955809964266\n",
      " ==> New best value..loss:0.530951094977996 hm:0.7274351082512035\n",
      " ==> New best value..loss:0.530274254434249 hm:0.7302816431117857\n",
      " ==> New best value..loss:0.5260976108850217 hm:0.7324650007221979\n",
      " ==> New best value..loss:0.5256862938404083 hm:0.7325099024691125\n",
      " ==> New best value..loss:0.5212009625107634 hm:0.7357724679475727\n",
      " ==> New best value..loss:0.51879048464345 hm:0.7388825621333035\n",
      " ==> New best value..loss:0.5165098175114277 hm:0.7403858960986325\n",
      " ==> New best value..loss:0.5145025037082971 hm:0.7414896609965469\n",
      " ==> New best value..loss:0.5124746146155339 hm:0.7432164934210637\n",
      " ==> New best value..loss:0.5101193610359641 hm:0.7451635125014386\n",
      " ==> New best value..loss:0.5083810313075197 hm:0.745326894761876\n",
      " ==> New best value..loss:0.5080212179352256 hm:0.7466110181761956\n",
      " ==> New best value..loss:0.5051361065284878 hm:0.7509923410414338\n",
      " ==> New best value..loss:0.5034177285783431 hm:0.751068723424705\n",
      " ==> New best value..loss:0.5026331719230203 hm:0.752733660287672\n",
      " ==> New best value..loss:0.4955448823816636 hm:0.7564589314615998\n",
      " ==> New best value..loss:0.4928495141805387 hm:0.7584527928339229\n",
      " ==> New best value..loss:0.4923378877780017 hm:0.7599571508224715\n",
      " ==> New best value..loss:0.4905005170434129 hm:0.7639621706070673\n",
      " ==> New best value..loss:0.4879268799342361 hm:0.7640203929699739\n",
      " ==> New best value..loss:0.4877486059478685 hm:0.7644050635647782\n",
      " ==> New best value..loss:0.487220391923306 hm:0.7658519201973087\n",
      " ==> New best value..loss:0.4851711591084798 hm:0.7659930036964014\n",
      " ==> New best value..loss:0.48354925244462255 hm:0.7685399828102235\n",
      "BEST SCORE:  0.7685399828102235\n",
      "TRAINING TOOK:  548  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 1, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5991226510674346 hm:0.5737108749264055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.5911907577047161 hm:0.6304442926820454\n",
      " ==> New best value..loss:0.58684340820593 hm:0.6686098873396304\n",
      " ==> New best value..loss:0.5801714138657439 hm:0.6749808298897476\n",
      " ==> New best value..loss:0.5787744703246098 hm:0.6802785691097817\n",
      " ==> New best value..loss:0.5696338122966242 hm:0.6828592182861964\n",
      " ==> New best value..loss:0.56845082079663 hm:0.6884579387284943\n",
      " ==> New best value..loss:0.5630422205317254 hm:0.6966055994305942\n",
      " ==> New best value..loss:0.5554468783677793 hm:0.7021340268243257\n",
      " ==> New best value..loss:0.5527137664018893 hm:0.705216095903801\n",
      " ==> New best value..loss:0.5525000294049581 hm:0.7062887259799541\n",
      " ==> New best value..loss:0.5507882745826945 hm:0.7069786596146325\n",
      " ==> New best value..loss:0.5501721624065848 hm:0.7140779225267266\n",
      " ==> New best value..loss:0.5435029557522606 hm:0.7164532494143955\n",
      " ==> New best value..loss:0.541797127793817 hm:0.7205949870454352\n",
      " ==> New best value..loss:0.5378181688925799 hm:0.7220468911161922\n",
      " ==> New best value..loss:0.5361358634397095 hm:0.7225667626399043\n",
      " ==> New best value..loss:0.531945101186341 hm:0.7244469860167104\n",
      " ==> New best value..loss:0.5292516046879339 hm:0.7283349165744993\n",
      " ==> New best value..loss:0.5273287775469762 hm:0.7320731562192715\n",
      " ==> New best value..loss:0.5262782924315509 hm:0.7329349186414149\n",
      " ==> New best value..loss:0.5261492951243532 hm:0.733780074537413\n",
      " ==> New best value..loss:0.5188509295968449 hm:0.7350599885152898\n",
      " ==> New best value..loss:0.5179316161894331 hm:0.7351963431460505\n",
      " ==> New best value..loss:0.51626236298505 hm:0.7370375671222913\n",
      " ==> New best value..loss:0.5121518279991898 hm:0.7384726643263719\n",
      " ==> New best value..loss:0.5108847413577285 hm:0.7436130042111292\n",
      " ==> New best value..loss:0.5056119771564708 hm:0.7466186010169431\n",
      " ==> New best value..loss:0.5002797748528275 hm:0.7468671852431166\n",
      " ==> New best value..loss:0.49931179892783073 hm:0.7521855015003954\n",
      " ==> New best value..loss:0.49859903606713984 hm:0.7525332785581876\n",
      " ==> New best value..loss:0.495736091744666 hm:0.7551696754902845\n",
      " ==> New best value..loss:0.49461842810406403 hm:0.7563209088493597\n",
      " ==> New best value..loss:0.4881911873817444 hm:0.756646869134129\n",
      "BEST SCORE:  0.756646869134129\n",
      "TRAINING TOOK:  558  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5980082908097435 hm:0.5901442823838502\n",
      " ==> New best value..loss:0.592912011871151 hm:0.6320758406388538\n",
      " ==> New best value..loss:0.5801484824395647 hm:0.6720716602075717\n",
      " ==> New best value..loss:0.5658725757224887 hm:0.675945083374388\n",
      " ==> New best value..loss:0.562586880197712 hm:0.6828851650576848\n",
      " ==> New best value..loss:0.5584840581697577 hm:0.6915507711884159\n",
      " ==> New best value..loss:0.5550863690236035 hm:0.6924316803610917\n",
      " ==> New best value..loss:0.5537978393190047 hm:0.7007535593836034\n",
      " ==> New best value..loss:0.547666012656455 hm:0.7025758355812621\n",
      " ==> New best value..loss:0.546830767509984 hm:0.7035945974133331\n",
      " ==> New best value..loss:0.545046888145746 hm:0.7040764251802403\n",
      " ==> New best value..loss:0.5434905857432122 hm:0.7101541657464637\n",
      " ==> New best value..loss:0.5398005469172609 hm:0.7130480441816193\n",
      " ==> New best value..loss:0.5378623230784547 hm:0.7145991185513357\n",
      " ==> New best value..loss:0.5343890248560438 hm:0.7197402552961233\n",
      " ==> New best value..loss:0.5341667065433428 hm:0.7200175558994639\n",
      " ==> New best value..loss:0.5306095358203439 hm:0.7231476216481291\n",
      " ==> New best value..loss:0.5254250051928502 hm:0.7283237704809824\n",
      " ==> New best value..loss:0.5244698612128987 hm:0.7299820655062107\n",
      " ==> New best value..loss:0.5206431115374845 hm:0.7315690711001744\n",
      " ==> New best value..loss:0.5190515407160217 hm:0.7341381813348551\n",
      " ==> New best value..loss:0.5157265166441599 hm:0.7374620249716736\n",
      " ==> New best value..loss:0.5114366803683487 hm:0.7419859831639614\n",
      " ==> New best value..loss:0.5107800948853586 hm:0.7451020230024944\n",
      " ==> New best value..loss:0.506541113058726 hm:0.7487344226272462\n",
      " ==> New best value..loss:0.5063057927524343 hm:0.7499139245005805\n",
      " ==> New best value..loss:0.49900176361495374 hm:0.7524798933777345\n",
      " ==> New best value..loss:0.4973057233819775 hm:0.7559207979713254\n",
      "BEST SCORE:  0.7559207979713254\n",
      "TRAINING TOOK:  561  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6149847066402435 hm:0.5966093011637112\n",
      " ==> New best value..loss:0.6146173530817032 hm:0.5989551262914685\n",
      " ==> New best value..loss:0.6138148307800293 hm:0.6081629236258471\n",
      " ==> New best value..loss:0.6111902475357056 hm:0.6369863170093526\n",
      " ==> New best value..loss:0.60738410115242 hm:0.6586422761170265\n",
      " ==> New best value..loss:0.5920534843206405 hm:0.6769194934525121\n",
      " ==> New best value..loss:0.5746153455972671 hm:0.6864356984158441\n",
      " ==> New best value..loss:0.5739580637216568 hm:0.6872986650336662\n",
      " ==> New best value..loss:0.5652732682228089 hm:0.6934709479999377\n",
      " ==> New best value..loss:0.559670392870903 hm:0.7022325174360041\n",
      " ==> New best value..loss:0.5564792281389237 hm:0.7088810651442337\n",
      " ==> New best value..loss:0.5554915910959244 hm:0.7127429116077226\n",
      " ==> New best value..loss:0.5521154111623764 hm:0.7147499809847887\n",
      " ==> New best value..loss:0.5498577761650085 hm:0.7157018671459143\n",
      " ==> New best value..loss:0.5487125509977341 hm:0.7158522917878031\n",
      " ==> New best value..loss:0.5477592462301254 hm:0.7176569370336291\n",
      " ==> New best value..loss:0.5456629741191864 hm:0.7201668633828631\n",
      " ==> New best value..loss:0.5434230464696884 hm:0.7215293678725785\n",
      " ==> New best value..loss:0.5419697719812393 hm:0.7234192382278762\n",
      " ==> New best value..loss:0.5406495147943496 hm:0.7242765847590465\n",
      " ==> New best value..loss:0.5394949597120285 hm:0.7243888644905041\n",
      " ==> New best value..loss:0.5385161066055297 hm:0.7265289122069841\n",
      " ==> New best value..loss:0.5339408028125763 hm:0.7319782957395754\n",
      " ==> New best value..loss:0.5318499684333802 hm:0.7324380603571433\n",
      " ==> New best value..loss:0.5286042439937592 hm:0.7360066873413846\n",
      " ==> New best value..loss:0.5252817034721374 hm:0.7380529195851688\n",
      " ==> New best value..loss:0.5246627324819565 hm:0.7407682632021614\n",
      " ==> New best value..loss:0.5196183723211288 hm:0.7411580545635964\n",
      " ==> New best value..loss:0.5179827159643173 hm:0.7421705329403422\n",
      " ==> New best value..loss:0.5155478847026825 hm:0.7448372624175978\n",
      " ==> New best value..loss:0.5147412490844726 hm:0.7449314556594646\n",
      " ==> New best value..loss:0.5127405470609665 hm:0.7449532665799387\n",
      " ==> New best value..loss:0.5112647849321366 hm:0.7495890385929306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.505802455842495 hm:0.7516053377629965\n",
      " ==> New best value..loss:0.5052155131101608 hm:0.7570744962403495\n",
      " ==> New best value..loss:0.5049281787872314 hm:0.7574267735721522\n",
      " ==> New best value..loss:0.5037231487035752 hm:0.7585834114601144\n",
      " ==> New best value..loss:0.5035664474964142 hm:0.7590138500387359\n",
      "BEST SCORE:  0.7590138500387359\n",
      "TRAINING TOOK:  543  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.5, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6130154121596858 hm:0.5995107452128892\n",
      " ==> New best value..loss:0.6117162344590673 hm:0.6001776838989135\n",
      " ==> New best value..loss:0.6115469072224959 hm:0.6114503930294151\n",
      " ==> New best value..loss:0.610080139816932 hm:0.6173419118822524\n",
      " ==> New best value..loss:0.6069143740635998 hm:0.6535823063518778\n",
      " ==> New best value..loss:0.5998290720975624 hm:0.6566107064944617\n",
      " ==> New best value..loss:0.586565836982907 hm:0.6706129542749639\n",
      " ==> New best value..loss:0.5839104449973916 hm:0.6734318777562132\n",
      " ==> New best value..loss:0.5796098281752389 hm:0.6871181181468858\n",
      " ==> New best value..loss:0.5775592456448753 hm:0.6886315535130774\n",
      " ==> New best value..loss:0.573759803794465 hm:0.6915092997717547\n",
      " ==> New best value..loss:0.5717066762582311 hm:0.693131234174541\n",
      " ==> New best value..loss:0.5670466434280828 hm:0.6962623384595056\n",
      " ==> New best value..loss:0.5660285527976054 hm:0.6965310001303598\n",
      " ==> New best value..loss:0.5651116989693552 hm:0.700884573673188\n",
      " ==> New best value..loss:0.5645667027752355 hm:0.7039988127483232\n",
      " ==> New best value..loss:0.5643990208517831 hm:0.707305309886368\n",
      " ==> New best value..loss:0.5614538412049132 hm:0.7093760928766583\n",
      " ==> New best value..loss:0.5578561768216906 hm:0.7113030838500158\n",
      " ==> New best value..loss:0.5566777806237059 hm:0.7145691907408741\n",
      " ==> New best value..loss:0.5543132531193068 hm:0.7154039011192598\n",
      " ==> New best value..loss:0.5490529660908681 hm:0.716865955678962\n",
      " ==> New best value..loss:0.5483247294740857 hm:0.7189842881940357\n",
      " ==> New best value..loss:0.5483178085875962 hm:0.7198536289695519\n",
      " ==> New best value..loss:0.5446581531245753 hm:0.7256904931019477\n",
      " ==> New best value..loss:0.5427225597624509 hm:0.7259797657171173\n",
      " ==> New best value..loss:0.5406586314147374 hm:0.7261468339692241\n",
      " ==> New best value..loss:0.5392980598053843 hm:0.7266528328041566\n",
      " ==> New best value..loss:0.5363718102563102 hm:0.7313790450590569\n",
      " ==> New best value..loss:0.5346885860528586 hm:0.7319422819004755\n",
      " ==> New best value..loss:0.5333678885450903 hm:0.733867742329491\n",
      " ==> New best value..loss:0.5316084662698349 hm:0.7356949231278582\n",
      " ==> New best value..loss:0.5300839723281141 hm:0.7358042008308755\n",
      " ==> New best value..loss:0.529968039607102 hm:0.7358398648383018\n",
      " ==> New best value..loss:0.5273216512967955 hm:0.7366907591121147\n",
      " ==> New best value..loss:0.5226836502552032 hm:0.7435945439227758\n",
      " ==> New best value..loss:0.5183297159536829 hm:0.7451397939243065\n",
      " ==> New best value..loss:0.516423448076788 hm:0.7459434602029609\n",
      " ==> New best value..loss:0.5145570191572297 hm:0.7475348546397019\n",
      "BEST SCORE:  0.7475348546397019\n",
      "TRAINING TOOK:  549  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 1, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6135160648822784 hm:0.5714042120206829\n",
      " ==> New best value..loss:0.6134800845384598 hm:0.584009502563172\n",
      " ==> New best value..loss:0.6130200105905533 hm:0.594180723958095\n",
      " ==> New best value..loss:0.612186576128006 hm:0.6189641766662766\n",
      " ==> New best value..loss:0.611330344080925 hm:0.6196861008161583\n",
      " ==> New best value..loss:0.601707963347435 hm:0.6702961893511356\n",
      " ==> New best value..loss:0.594258902668953 hm:0.6826615338508647\n",
      " ==> New best value..loss:0.5773655730485916 hm:0.6854569109738915\n",
      " ==> New best value..loss:0.573314236998558 hm:0.688997234974905\n",
      " ==> New best value..loss:0.5708708548545838 hm:0.6913739404814597\n",
      " ==> New best value..loss:0.5622157794237137 hm:0.6962053852067639\n",
      " ==> New best value..loss:0.5606078225374221 hm:0.6977236529477041\n",
      " ==> New best value..loss:0.5593404823541641 hm:0.7021149818738087\n",
      " ==> New best value..loss:0.5571779817342758 hm:0.7022937043535405\n",
      " ==> New best value..loss:0.5567425429821015 hm:0.7060384913717495\n",
      " ==> New best value..loss:0.5540200531482696 hm:0.7117989957555964\n",
      " ==> New best value..loss:0.5533413189649582 hm:0.7127999428869967\n",
      " ==> New best value..loss:0.5514096677303314 hm:0.7139863062264735\n",
      " ==> New best value..loss:0.55102430164814 hm:0.7170956954786727\n",
      " ==> New best value..loss:0.550737538933754 hm:0.7176223789563312\n",
      " ==> New best value..loss:0.5489788520336151 hm:0.7182840798336886\n",
      " ==> New best value..loss:0.5467969566583634 hm:0.7201917044086552\n",
      " ==> New best value..loss:0.5456628787517548 hm:0.7204936136541876\n",
      " ==> New best value..loss:0.5431730151176453 hm:0.7213522853317826\n",
      " ==> New best value..loss:0.5416146177053451 hm:0.7219557868053749\n",
      " ==> New best value..loss:0.5411976855993271 hm:0.7248034194686371\n",
      " ==> New best value..loss:0.541157842874527 hm:0.7255390826024609\n",
      " ==> New best value..loss:0.5372000586986542 hm:0.7278447310987632\n",
      " ==> New best value..loss:0.5353967779874802 hm:0.7281611719047996\n",
      " ==> New best value..loss:0.5322539073228836 hm:0.730276534712866\n",
      " ==> New best value..loss:0.531817477941513 hm:0.7318793666022464\n",
      "BEST SCORE:  0.7318793666022464\n",
      "TRAINING TOOK:  534  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6202971321694991 hm:0.5741903901234993\n",
      " ==> New best value..loss:0.619557366067288 hm:0.583701998304802\n",
      " ==> New best value..loss:0.6189319970561009 hm:0.591170904224372\n",
      " ==> New best value..loss:0.6186661550811693 hm:0.6164781719507741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==> New best value..loss:0.6173283194794374 hm:0.6319110501454002\n",
      " ==> New best value..loss:0.6161053916987251 hm:0.6346504385884927\n",
      " ==> New best value..loss:0.611694839070825 hm:0.6365247556132794\n",
      " ==> New best value..loss:0.6070449784690258 hm:0.6482174543943255\n",
      " ==> New best value..loss:0.5978666649145239 hm:0.6618523233351885\n",
      " ==> New best value..loss:0.5945307308552312 hm:0.6688939618356432\n",
      " ==> New best value..loss:0.5879619711754369 hm:0.671498769928214\n",
      " ==> New best value..loss:0.5808253755756453 hm:0.6831038552512255\n",
      " ==> New best value..loss:0.5735766700669831 hm:0.6839257609195633\n",
      " ==> New best value..loss:0.5706337491671244 hm:0.6877229954399505\n",
      " ==> New best value..loss:0.5698679784933726 hm:0.6890546838321376\n",
      " ==> New best value..loss:0.568306656444774 hm:0.6924146968240382\n",
      " ==> New best value..loss:0.5674521630885554 hm:0.6966853023715699\n",
      " ==> New best value..loss:0.5646897186251247 hm:0.69985043512728\n",
      " ==> New best value..loss:0.5626907050609589 hm:0.7003260829984173\n",
      " ==> New best value..loss:0.5619955273235545 hm:0.7035830899737882\n",
      " ==> New best value..loss:0.5609418124544854 hm:0.7041391876449394\n",
      " ==> New best value..loss:0.5600150771000806 hm:0.7047455899277768\n",
      " ==> New best value..loss:0.5588976869396135 hm:0.7059937296414897\n",
      " ==> New best value..loss:0.558054573395673 hm:0.707268165702307\n",
      " ==> New best value..loss:0.5577138890238369 hm:0.7077458356671765\n",
      " ==> New best value..loss:0.553486602563484 hm:0.7125020641044021\n",
      " ==> New best value..loss:0.5523311191914129 hm:0.7136644333794258\n",
      " ==> New best value..loss:0.5517512641701043 hm:0.7180537617250926\n",
      " ==> New best value..loss:0.548723525276371 hm:0.7192237298351387\n",
      " ==> New best value..loss:0.5481029035998326 hm:0.7192638414245386\n",
      " ==> New best value..loss:0.54758859557264 hm:0.7197753107139627\n",
      " ==> New best value..loss:0.5473931256462546 hm:0.7217006890159066\n",
      " ==> New best value..loss:0.5431599996837915 hm:0.7236320125751178\n",
      " ==> New best value..loss:0.5405583282311758 hm:0.7246878490314074\n",
      " ==> New best value..loss:0.5387700877937616 hm:0.7286248341841863\n",
      " ==> New best value..loss:0.5383510396761053 hm:0.728704867091945\n",
      " ==> New best value..loss:0.5373926145188949 hm:0.732943651592679\n",
      " ==> New best value..loss:0.5353980835746316 hm:0.734494184377921\n",
      " ==> New best value..loss:0.5344739462815079 hm:0.7365836287363761\n",
      " ==> New best value..loss:0.5332241391434389 hm:0.7371486686897211\n",
      " ==> New best value..loss:0.5310054561671089 hm:0.7376356486326104\n",
      " ==> New best value..loss:0.5306059718132019 hm:0.7381131517786419\n",
      " ==> New best value..loss:0.52816875074424 hm:0.7402339937324678\n",
      " ==> New best value..loss:0.5255050226753833 hm:0.7429156539960913\n",
      "BEST SCORE:  0.7429156539960913\n",
      "TRAINING TOOK:  533  s\n",
      "================================================================================\n",
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 7e-05, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5898218069757734 hm:0.5880866747794923\n",
      " ==> New best value..loss:0.5895930224535416 hm:0.5972205320666112\n",
      " ==> New best value..loss:0.5895889948825447 hm:0.5995407216639486\n",
      " ==> New best value..loss:0.5860659321960138 hm:0.6600888659847678\n",
      " ==> New best value..loss:0.5834241217496444 hm:0.6667245613962876\n",
      " ==> New best value..loss:0.5772582760878971 hm:0.6678573602651773\n",
      " ==> New best value..loss:0.5762507739115734 hm:0.6710678652871334\n",
      " ==> New best value..loss:0.5717600486716445 hm:0.677696389394782\n",
      " ==> New best value..loss:0.5645017350206569 hm:0.6789275835138728\n",
      " ==> New best value..loss:0.5603602577228936 hm:0.6823040797290021\n",
      " ==> New best value..loss:0.5598782075911152 hm:0.6827721265813604\n",
      " ==> New best value..loss:0.554149471375407 hm:0.6840388158154008\n",
      " ==> New best value..loss:0.5538789538704619 hm:0.688708761725081\n",
      " ==> New best value..loss:0.5538345307719951 hm:0.6927443962411359\n",
      " ==> New best value..loss:0.5520184265107525 hm:0.6970512006128354\n",
      " ==> New best value..loss:0.547301148273507 hm:0.6972000290073387\n",
      " ==> New best value..loss:0.5455638370951827 hm:0.7040683292663878\n",
      " ==> New best value..loss:0.5429964065551758 hm:0.7046949277137508\n",
      " ==> New best value..loss:0.5418062909525267 hm:0.7071538004543427\n",
      " ==> New best value..loss:0.5413235219157472 hm:0.7110599075921594\n",
      " ==> New best value..loss:0.5399327977579467 hm:0.7110905964413972\n",
      " ==> New best value..loss:0.5398442617484501 hm:0.7122566161125162\n",
      " ==> New best value..loss:0.5381699253101738 hm:0.7162176239092934\n",
      " ==> New best value..loss:0.5368117756989538 hm:0.7188770142127565\n",
      " ==> New best value..loss:0.5362204191636066 hm:0.7203780252499903\n",
      " ==> New best value..loss:0.5352326065910106 hm:0.7232331096428976\n",
      " ==> New best value..loss:0.5342630141851853 hm:0.7258322709454694\n",
      " ==> New best value..loss:0.531409387077604 hm:0.7264168698450244\n",
      " ==> New best value..loss:0.5257060412241488 hm:0.7278587242121458\n",
      " ==> New best value..loss:0.5246694489401214 hm:0.7303437871611599\n",
      " ==> New best value..loss:0.5231361316174877 hm:0.7305139204476899\n",
      " ==> New best value..loss:0.5220266756962757 hm:0.733972675837485\n",
      " ==> New best value..loss:0.5212044916590866 hm:0.7356104783305337\n",
      "BEST SCORE:  0.7356104783305337\n",
      "TRAINING TOOK:  531  s\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'de_attention'\n",
    "\n",
    "nn_deattention = []\n",
    "scores_deattention = []\n",
    "\n",
    "alpha_de_lst = [1, 0.5, 0.05]\n",
    "beta_de_lst = [1, 0.5, 0.05]\n",
    "lr_lst = [1e-4, 7e-5]\n",
    "\n",
    "params_dict['batch_size'] = 30\n",
    "\n",
    "for lr in lr_lst: \n",
    "    params_dict['lr'] = lr    \n",
    "    \n",
    "    for alpha_de in alpha_de_lst:\n",
    "        params_dict['alpha_de'] = alpha_de\n",
    "\n",
    "        for beta_de in beta_de_lst:\n",
    "            params_dict['beta_de'] = beta_de \n",
    "\n",
    "            print('='*80)\n",
    "            d_start = datetime.now() \n",
    "            best_score, classifier = do_training( df_in1, params_dict, criterion)\n",
    "            nn_deattention.append(classifier)\n",
    "            scores_deattention.append(best_score)\n",
    "\n",
    "            print('BEST SCORE: ', best_score)\n",
    "            print('TRAINING TOOK: ', ( datetime.now() - d_start ).seconds, ' s'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "beta = 0.5\n",
    "\n",
    "# alpha = 0.5\n",
    "# beta = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(scores_softmax)[::-1][:3]\n",
    "np.argsort(scores_tanh)[::-1][:3]\n",
    "np.argsort(scores_deattention)[::-1][ : 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict['lr'] = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Softmax attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.05, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'softmax'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.5412338563040191 hm:0.730445521381458\n",
      " ==> New best value..loss:0.5218880918680453 hm:0.7528477105833071\n",
      " ==> New best value..loss:0.5055333042846006 hm:0.7657710690944849\n",
      " ==> New best value..loss:0.5038266146884245 hm:0.7659613803091914\n",
      " ==> New best value..loss:0.5000223868033465 hm:0.7697282419349677\n",
      " ==> New best value..loss:0.49788349224071876 hm:0.7725601389717935\n",
      " ==> New best value..loss:0.49392979986527386 hm:0.7732124469504126\n",
      " ==> New best value..loss:0.49284276892157164 hm:0.7770352216704832\n",
      " ==> New best value..loss:0.4907572871329738 hm:0.7777377722184333\n",
      " ==> New best value..loss:0.49015331443618326 hm:0.7822663674526094\n",
      " ==> New best value..loss:0.48863863711263616 hm:0.7838340493462058\n",
      " ==> New best value..loss:0.4857511876844892 hm:0.7855730724892341\n",
      " ==> New best value..loss:0.4834512600711748 hm:0.7882475437660583\n",
      " ==> New best value..loss:0.4794478918991837 hm:0.7931925536540411\n",
      " ==> New best value..loss:0.4794403694423975 hm:0.7945600157866731\n",
      " ==> New best value..loss:0.4719764169524698 hm:0.8002678462016278\n",
      " ==> New best value..loss:0.46916210534525854 hm:0.805024773682019\n",
      " ==> New best value..loss:0.464695859189127 hm:0.807171389813636\n",
      " ==> New best value..loss:0.46452776590983075 hm:0.8109459224642093\n",
      " ==> New best value..loss:0.45919936544754925 hm:0.8118891793946877\n",
      " ==> New best value..loss:0.4531147702067506 hm:0.8134744662074483\n",
      " ==> New best value..loss:0.4492243697830275 hm:0.8146635606179806\n",
      " ==> New best value..loss:0.44720469502841725 hm:0.8188476841253449\n",
      " ==> New best value..loss:0.44412941558688296 hm:0.8225151331346721\n",
      " ==> New best value..loss:0.4381243615758185 hm:0.8280499941632897\n",
      " ==> New best value..loss:0.43618950802905887 hm:0.8287290104154171\n",
      " ==> New best value..loss:0.43445640159588234 hm:0.8298597352620883\n",
      " ==> New best value..loss:0.43436621217166677 hm:0.8302213663018889\n",
      " ==> New best value..loss:0.4260183642892277 hm:0.8355083257907349\n",
      " ==> New best value..loss:0.4229080118969375 hm:0.8355641650116112\n",
      " ==> New best value..loss:0.4201214988442028 hm:0.8358892694788266\n",
      " ==> New best value..loss:0.41794343672546685 hm:0.8391599601624704\n",
      " ==> New best value..loss:0.4145678752193264 hm:0.8400520363058108\n",
      " ==> New best value..loss:0.41118067298449723 hm:0.8427764455304712\n",
      " ==> New best value..loss:0.41008466832778034 hm:0.8429427500931189\n",
      " ==> New best value..loss:0.40731990980167015 hm:0.8453242664122465\n",
      " ==> New best value..loss:0.40431783479802746 hm:0.849591799642094\n",
      " ==> New best value..loss:0.3954284083025128 hm:0.8560503843784255\n",
      " ==> New best value..loss:0.39017657438913983 hm:0.856400623781444\n",
      " ==> New best value..loss:0.38601864319221646 hm:0.8590509452983324\n",
      " ==> New best value..loss:0.38527944128887326 hm:0.8591947971979457\n",
      " ==> New best value..loss:0.3841487405931248 hm:0.8603237817569256\n",
      " ==> New best value..loss:0.3818007342371286 hm:0.8646928955078013\n",
      " ==> New best value..loss:0.38008856744158503 hm:0.8649781526602633\n"
     ]
    }
   ],
   "source": [
    "params_dict['attention'] = 'softmax'\n",
    "\n",
    "best_score, nn_soft = do_training( df_in1, params_dict, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 1, \n",
      "Predicted: 0.388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Attention Visualization</h2><p><span style=\"margin:1px; padding:2px; background-color: #9fcae1\"><span class = \"barcode\"; style =\"color: black; background-color: #eaf2fb\">&nbsp봄&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp이랑&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #deebf7\">&nbsp어울리는&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #1663aa\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp이에요&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #58a1cf\"><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp당근&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp과&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f6faff\">&nbsp단감&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp의&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f5fafe\">&nbsp중간&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f3f8fe\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f4f9fe\">&nbsp착색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f2f8fd\">&nbsp핑크&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp가&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #dfebf7\">&nbsp아니라&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #afd1e7\">&nbsp주황색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #77b5d9\">&nbsp입니다&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #e9f2fa\"><span class = \"barcode\"; style =\"color: black; background-color: #d8e7f5\">&nbsp추천&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #0e59a2\">&nbsp해&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp요&nbsp</span></span><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEXCAYAAACgUUN5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7wVdb3/8debi+IFb0ApIkKGJqaSIpYXQI285qVTv6SrepLQOOoxC62Tecmj1OmYHTUOklp5wUuaHCMvnQQ0NQFDFBXjKMkWVEQT1Ijb5/fHfLeOi31ZwJq9Nsz7+Xisx14z813f+czsWfOZ+c6s7ygiMDOz8upQ7wDMzKy+nAjMzErOicDMrOScCMzMSs6JwMys5JwIzMxKzomgHZE0VtL36h1HeyDpQEl/kfSWpOPrHMsFkm6oZwwpju9IGt/C9C9Kuq8tY0rzbXb9SDpY0py2jsnWTukTgaTJkt6QtGnF+HmSPpkb7iMpJHWq0XxPkvRQflxEjIyIi2tRf8W8tpF0raSXJS2V9Jyk0bWeT41dBFwZEVtGxG/yEySdJ2lSxbi/NDPuxDaItUlpG/p7SmavSLpO0pbrWl9E/HtEfC3Vvcb2GBE3RsSnahF7rUTEgxGxW1vMS9JxkmZKWiLpNUn/K6lPDeptFwcCRSp1IkgbycFAAMfWNZhiXQ5sCewObE22rP9XyxnUKkHm7AzMbmbaVOBASR3TvLcHOgP7VIz7cCpbtQKW49MRsSWwD7Af8G81rt8ASR8Gfgl8k2wb7wtcDayuZ1wbjIgo7Qs4H/gj8J/A3bnxvyLbgP4OvAV8G3iRLGG8lV6fSGVPAZ4B3gDuBXbO1RPASOAvafpVgMh2yMuAVamuv6Xy1wM/yH3+VGAu8DowEejZWt3NLOdTwPEtrIc9gPvTfF4BvpPGbwr8BFiQXj8BNk3ThgINwGjg5bTOOgDnkiWZxcCtwHYtzLfJ5Uufz6//TSs+twnwDrBvGv5/wHXAlIpxc9P7nqn+19P8Ts3VdQFwO3ADsAT4GtlOZAqwNK2XK4EbUvkuqexi4G/ANOCDzSzfPOCTueEfkbYzsmQ8O9UxGdg9V2408FKa/xzgsFysjXGssT0CJwEP5eo5IMX3Zvp7QG7aZOBisu1/KXAf0D03/ePAwym+J4ChuWnNrp8m1sFQoKFinZwDzEpx3QJ0aeazuwB/SOv6NeBGYJtmyn4WmNnCttbstgn0Sevyq2m9vgZ8N007AlgOrEjr+Yk0fmvg58DC9L/6AdAxTTsJeAj4D7Lv5gvAkblYtiPbXhek6b/JTTsGmJnW+8PAXm2yL2yLmbTXF9lO4XRg3/SP/mBu2jze/yVu3Fg65cYdn+rYHehEdrT3cG56AHcD2wC9gUXAEfmNpSKe60mJADg0bZD7kO2Q/wuYWk3dTSzneLKdzslAv4ppXdPG/E2ynVxXYP807SLgUeADQI+0YV6cpg0FVgJjUnybAWel8r3SuP8Gbm4mptaW733rv4nPPwD8a3p/JVlCvqRi3LXp/RSyo8MuwIC0rvI71xXpf9khLccjZAcHmwKDyXZ4jTvgrwP/A2wOdEzbzlbNxPjuMgA7pf/BxcCuwNvAMLIzmW+n7WgTYDdgPu8lxT7ALrlYb8iNr9weTyJtU2Q7mzeAL5Ntm8PTcLc0fTLZTnHXtMyTgcvStB3JdpZHpXUyLA33SNObXT9NrIOhrJkIHiNLztuRHUSNbOazH07z3pRs+5sK/KSZsh8iO7i6HDgE2LJierPbZm5dXpPWxd7AP0jJOb/ec/X9JtWxBdn34zHg67n/wwqyA52OwGlkO32l6b8lS4Dbpv//kDR+H+BVYP/0ua+m9bVpU8tc031h0TNory/goPTP6p6GnyXtRCq/xC188X4H/HNuuAPZkerOaTiAg3LTbwXOzW0sLSWCnwM/zE3bMsXbp7W6m1jWzYDvADNSHXNJRyhkO4g/N/O5/wOOyg0fDsxL74eSHSl1yU1/hrSDTcM7pPl1aqLu1pbvfeu/ic9fANyZ3j8B9CM7esuP+yrZDngV0DX32UuB63P15BNQb7IEt0Vu3E28twM+hSqP1NIyvEV2dPdXsmS0GfA94NaK7ealtE4/TLYz+CTQuYllrjYRfBl4rOLzjwAnpfeTgX/LTTsduCe9Hw38quKz96b12eL6aWIdDGXNRPCl3PAPgbFVfmePp5ltNU3/ONn3YBFZUrielBBoYdvMrcteuemPASdWrvc0/EGyRLFZbtxw4IHc/2Fubtrmqf7t03xXA9s2Ef/PSAdauXFzSImiyFeZrxF8FbgvIl5LwzelcWtjZ+AKSX+T9DeypgeRHVE1ejn3/h2yHV41epLtPACIiLfIjsrWuu6I+HtkFxr3BbqRfVluk7Qd2Y6yuesF74shve+ZG14UEctywzsDd+bWxzNkO+EPruPytWQqcJCkbcmOVP9CtoM+II37aCrTE3g9IpZWLEd+PvMr4nojIt6uKN/oV2Q7xQmSFkj6oaTOLcR5fERsExE7R8TpEfF31lz21SmGHSNiLtnR6wXAq5ImSOrZVMWtqPzfNS5HNdvPzsDnGv+P6X95ENlOrLX1U42qtltJH0jL/5KkJWRNct2bqzQiHo2I/xcRPciu/Q0Gvptbpta2zWq/qzuTHckvzNX332RnBmvUFRHvpLdbkn3fXo+IN5qp95sV630n3v+dK0QpE4GkzcjakIekO2leBv4V2FvS3qlYVHyschiyL+/X0xe98bVZRDxcRRhN1Ze3gGzDaIx5C7Kd+EtV1N38TCOWAP9Odkrbl2wZdqkmBrKjwQX56irKzyc708ivjy4R0VTM67t8j5C1044ga+duXLYFadyCiHghDW8nqWvFcuTnk1+OhcC2KZ58edI8VkTEhRHRn6wN/hjgK1XG3Khy2UX2hX8pzeOmiDgolQmy5rdKa7X95JajmvU7n+yMIP9/3CIiLqOV9VNjl5It514RsRXwJbIDrVZFxDTgDrIDAli7bXON6iqG55OdEXTP1bVVROxRRV3zybbHbZqZdklFjJtHxM1V1LteSpkIyE4xVwH9ydqMB5C18z/Ie1/qV8jaHRstIjuly48bC5wnaQ8ASVtL+lyVMbwC9JK0STPTbwJOljQg3dr678CfImJelfW/S9L3JO0naRNJXYAzyZor5pBdZ9he0lmSNpXUVdL+6aM3A/8mqYek7mQX11u6jW4scImkndN8e0g6rojlS0fW04Gzyf5vjR5K46amcvPJzhQuldRF0l7AP5NdeGyq3r+mei9M6+sg4NON0yUdImnPdHfSErLmhVXVxJxzK3C0pMPS2cQ3yXYsD0vaTdKhaZ0sI7tg3lT9TW2PeZOAXSV9QVInSZ8n297vriK+G4BPSzpcUse03oZK6tXa+qmxrqSmNUk7At9qrqCkgySdKukDafgjZBfkH01F1mbbrPQK0EdSB4CIWEh2cf3HkraS1EHSLpKGtFZR+uzvgKslbSups6TBafI1wEhJ+yuzhaSjKw5iClHWRPBV4LqIeDEiXm58kV1g/GK6hfBSsp3g3ySdk07vLgH+mMZ9PCLuJDtam5BOXZ8Cjqwyhj+QXTx8WdJrlRMj4n/J2pJ/TXYUtguwrvfEB9ldCq+RHSkOA46OiLdSk8kwsi/zy2R3IR2SPvcDsi/9LOBJ4PE0rjlXkN2dc5+kpWRfwv2bKlij5ZtCdjqe/z3Gg2lc/rbR4WTtwAuAO4HvR8T9LdT7hRT368D3yW5LbLQ92V1GS8iaF6bQcnJcQ0TMITu6/S+y/8mnyW4zXU52IfOyNP7ltCzfaaKONbbHiumLyc5WvknW5PZt4JhcU2hL8c0HjkvzXUR2pPot3ttftLR+aulCsguob5JdYL2jhbJ/I9vxPynpLeAesv/1D9P0qrfNJtyW/i6W9Hh6/xWyi/tPk12Ev52s6awaXyY7gHiW7HrQWQARMZ3sAvOVqc65ZNcbCtd4FdvMzEqqrGcEZmaWOBGYmZWcE4GZWck5EZiZlVytO9gqXPfu3aNPnz71DsPMbIMyY8aM19KP7dawwSWCPn36MH369HqHYWa2QZHU7C/A3TRkZlZyTgRmZiXnRGBmVnIb3DWCpqxYsYKGhgaWLVvWeuGNTJcuXejVqxedO7fUAaaZWfM2ikTQ0NBA165d6dOnD1lHjuUQESxevJiGhgb69u1b73DMbAO1UTQNLVu2jG7dupUqCQBIolu3bqU8EzKz2tkoEgFQuiTQqKzLbWa1s9EkAjMzWzdOBGZmJedEsBZmzpzJpEmTWiwzceJELrvssrWq96STTuL2229vdvrKpa+2+Fq9bClvTLl6reZpZtbIiWAtVJMIjj32WM4999w2isjMbP2VJhG8/fbbHH300ey999589KMf5ZZbbmHGjBkMGTKEfffdl8MPP5yFCxcCMHToUEaPHs2gQYPYddddefDBB1m+fDnnn38+t9xyCwMGDOCWW25pcj7XX389o0aNArIj/TPOOIMDDjiAD33oQ+8e9UcEo0aNon///hx99NG8+uqrALz55pvstttuzJkzB4Dhw4dzzTXXFL1qzKzkNorfEVTjnnvuoWfPnvz2t78Fsp3ukUceyV133UWPHj245ZZb+O53v8u1114LwMqVK3nssceYNGkSF154Ib///e+56KKLmD59OldeeWXV8124cCEPPfQQzz77LMceeyyf/exnufPOO5kzZw5PPvkkr7zyCv379+eUU05h66235sorr+Skk07izDPP5I033uDUU09l5dJXC1knZmZQokSw5557cs455zB69GiOOeYYtt12W5566imGDRsGwKpVq9hhh/eePf2Zz3wGgH333Zd58+at83yPP/54OnToQP/+/XnllVcAmDp1KsOHD6djx4707NmTQw899N3yw4YN47bbbuMb3/gGTzzxxDrP18ysWqVJBLvuuiszZsxg0qRJnHfeeQwbNow99tiDRx55pMnym266KQAdO3Zk5cqV6zzfxnogaxJq1Nz9/6tXr+aZZ55hs8024/XXX6dXr17rPG8zs2qU5hrBggUL2HzzzfnSl77EOeecw5/+9CcWLVr0biJYsWIFs2fPbrGOrl27snTp0vWOZfDgwUyYMIFVq1axcOFCHnjggXenXX755ey+++7cfPPNnHLKKaxYsWK952dm1pJCE4GkIyTNkTRX0hq30kjaWtL/SHpC0mxJJxcVy5NPPsmgQYMYMGAAl1xyCRdddBG33347o0ePZu+992bAgAE8/PDDLdZxyCGH8PTTT7d4sbgaJ5xwAv369WPPPffktNNOY8iQIQA899xzjB8/nh//+MccfPDBDB48mB/84AfrPB8zs2oo31xR04qljsBzwDCgAZgGDI+Ip3NlvgNsHRGjJfUA5gDbR8Ty5uodOHBgVD6h7JlnnmH33XcvYCnah9YuFs+ZO4+eS6az7ZDT2ygiM9vQSJoREQObmlbkNYJBwNyIeD4FMQE4Dng6VyaArsoazLcEXgfWvUHemjVmypiqyo0eMrrgSMysvSkyEewIzM8NNwD7V5S5EpgILAC6Ap+PiNWVFUkaAYwA6N27dyHBrq3rrruOK6644n3jDjzwQK666qo6RWRmtm6KTARN3RZT2Q51ODATOBTYBbhf0oMRseR9H4oYB4yDrGmogFjX2sknn8zJJxd2ScPMrM0UebG4AdgpN9yL7Mg/72TgjsjMBV4APlJgTGZmVqHIRDAN6Cepr6RNgBPJmoHyXgQOA5D0QWA34PkCYzIzswqFNQ1FxEpJo4B7gY7AtRExW9LINH0scDFwvaQnyZqSRkfEa0XFZGZmayr0l8URMQmYVDFubO79AuBTtZ5vtXfIVKut7qSZOXMmCxYs4KijjgLg2Wef5eSTT+bxxx/n4vPP4+wzfHuomdVeaX5ZvCGo7OZ6u+2246c//Slnn3FaHaMys42dE0GNFNHN9Qc+8AH2228/OnfqXOelM7ONWWk6nStavbq5NjNbX04ENVKvbq7NzNaXE0GN1KubazOz9eVrBDXSnrq5NjNbGxvlGUE9Ok578skn+da3vkWHDh3o3LkzP/vZz+jUqRNnnHEGb775JitXruSss85ijz32aLaOQw45hMsuu4wBAwZw3nnnMWTIEAYOHMiSJW/SoUMHfnr1OGY99iBbbdW1DZfMzDZ2G2UiqIfDDz+cww8/fI3xU6dOXWPc5MmT333fvXv3d68RbLfddkybNu19ZRsaGvzMYjMrlJuGzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5DbK20cn3z2zpvUNPWZATetrTmU31DfeeCNjxowhVq9kyy224MrLf8jeezb/OwQzs3VR6BmBpCMkzZE0V9K5TUz/lqSZ6fWUpFWStisypvasshvqvn37MmXKFP78yGS+++2zOe2Mb9YxOjPbWBWWCCR1BK4CjgT6A8Ml9c+XiYgfRcSAiBgAnAdMiYjXi4qpSEV0Q33AAQew7bbbArD/fvvy0oKF9VxEM9tIFdk0NAiYGxHPA0iaABwHPN1M+eHAzQXGU6iiu6G+7lc3cfiwQ9t0mcysHIpMBDsC83PDDcD+TRWUtDlwBDCqwHgKVWQ31JOnPsR1v7yJyfdOLCx+MyuvIhOBmhgXzZT9NPDH5pqFJI0ARgD07t27NtHVWFHdUM+aNYuvjzqb//n1zXTrVtrLJ2ZWoCIvFjcAO+WGewELmil7Ii00C0XEuIgYGBEDe/ToUcMQa6eIbqhffPFFPvOZz3DdNVexa79dCo3fzMqryDOCaUA/SX2Bl8h29l+oLCRpa2AI8KVazbitbvfMK6Ib6vvvv5/FixfzL2dn3Wp36tSJP025r60WycxKorBEEBErJY0C7gU6AtdGxGxJI9P0sanoCcB9EfF2UbG0hSK6of785z/P+PHj3Q21mRWq0B+URcQkYFLFuLEVw9cD1xcZh5mZNc9dTJiZlZwTgZlZyTkRmJmVnBOBmVnJORGYmZXcRtkN9RtTrq5pfdsOOb2m9TWnshvqu+66i+9973uI1XTq1IkfX3YxB32iyV46zMzWmc8I2pHKbqgPO+wwnnjiCWb88Q9cc9XljBx1dh2jM7ONlRNBjRTRDfWWW26JpFT/O+++NzOrpY2yaageiuqG+s477+S80d/m1UWvcddtN9Rl2cxs4+ZEUCNFdUN9wgkn8OlPHsiDf3yECy4Zw70Tby90OcysfJwIaqSobqgbHXzgJ3j+hXm8tngx3bt1q2nsZlZuvkZQI0V0Qz137lwiskc4PD5zFsuXr6Dbdn4mgZnV1kZ5RtBWt3vmFdEN9bx58/jlL39Jp45isy5duPH6cb5gbGY1t1EmgnooohtqgNGjR7sbajMrlJuGzMxKzonAzKzkCk0Eko6QNEfSXEnnNlNmqKSZkmZLmrKu82q8qFo22XKXc9nNrDYKSwSSOgJXAUcC/YHhkvpXlNkGuBo4NiL2AD63LvPq0qULixcvLl0yiAhef/MtOq96p96hmNkGrMiLxYOAuRHxPICkCcBxwNO5Ml8A7oiIFwEiYp2uivbq1YuGhgYWLVq0niG3T6uXLW1mStB51Tts985f2jQeM9u4FJkIdgTm54YbgMquM3cFOkuaDHQFroiIX1ZWJGkEMAKgd+/ea8yoc+fO9O3btzZRt0O17k3VzCyvyGsETd3wXtl20wnYFzgaOBz4nqRd1/hQxLiIGBgRA3v06FH7SM3MSqzIM4IGYKfccC9gQRNlXouIt4G3JU0F9gaeKzAuMzPLKfKMYBrQT1JfSZsAJwITK8rcBRwsqZOkzcmajp4pMCYzM6tQ2BlBRKyUNAq4F+gIXBsRsyWNTNPHRsQzku4BZgGrgfER8VRRMZmZ2ZoK7WIiIiYBkyrGja0Y/hHwoyLjMDOz5vmXxWZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgRmZiXnRGBmVnJOBGZmJedEYGZWclV1Qy2pB3Aq0Cf/mYg4pZiwzMysrVT7PIK7gAeB3wOrigvHzMzaWrWJYPOIGL22lUs6AriC7All4yPisorpQ8mSzAtp1B0RcdHazsfMzNZdtYngbklHpSeOVUVSR+AqYBjZQ+qnSZoYEU9XFH0wIo6ptl4zM6utai8Wn0mWDJZJWppeS1r5zCBgbkQ8HxHLgQnAcesTrJmZ1V5ViSAiukZEh4jokt53jYitWvnYjsD83HBDGlfpE5KekPQ7SXs0VZGkEZKmS5q+aNGiakI2M7MqVf3weknHAoPT4OSIuLu1jzQxLiqGHwd2joi3JB0F/Abot8aHIsYB4wAGDhxYWYeZma2Hqs4IJF1G1jz0dHqdmca1pAHYKTfcC1iQLxARSyLirfR+EtBZUvcqYzczsxqo9ozgKGBARKwGkPQL4M/AuS18ZhrQT1Jf4CXgROAL+QKStgdeiYiQNIgsMS1eu0UwM7P1UXXTELAN8Hp6v3VrhSNipaRRwL1kt49eGxGzJY1M08cCnwVOk7QS+DtwYkS46cfMrA1VmwguBf4s6QGytv/BwHmtfSg190yqGDc29/5K4MqqozUzs5qrKhFExM2SJgP7kSWC0RHxcpGBmZlZ22gxEUj6SEQ8K2mfNKoh/e0pqWdEPF5seGZm5TD57plVlRt6zICaz7u1M4KzgRHAj5uYFsChNY/IzMzaVIuJICJGpLdHRsSy/DRJXQqLyszM2ky1XUw8XOU4MzPbwLR2jWB7sm4hNpP0Md77tfBWwOYFx2ZmZm2gtWsEhwMnkf0q+D9z45cC3ykoJjMza0OtXSP4BfALSf8UEb9uo5jMzKwNrc3zCL7Amo+q9ENkzMw2cGvzqMo3gRnAP4oLx8zM2lq1iaBXRBxRaCRmZlYXVd8+KmnPQiMxM7O6qPaM4CDgJEkvkDUNCYiI2KuwyMzMrE1UmwiOLDQKMzOrm2qfWfxXsqeNHZrev1PtZ83MrH2r9lGV3wdG894zCDoDN1TxuSMkzZE0V1KzTzOTtJ+kVZI+W008ZmZWO9Ue1Z8AHAu8DRARC4CuLX1AUkfgKrJmpf7AcEn9myk3huxJZmZm1saqTQTL0yMkA0DSFlV8ZhAwNyKej4jlwATguCbK/Qvwa+DVKmMxM7MaqjYR3Crpv4FtJJ0K/B4Y38pndgTm54Yb0rh3SdqR7GxjLC2QNELSdEnTFy1aVGXIZmZWjWofVfkfkoYBS4DdgPMj4v5WPqYmxlU+mP4nZI+9XCU1Vfzd+Y8DxgEMHDjQD7c3M6uhqhKBpDERMRq4v4lxzWkgu9OoUS9gQUWZgcCElAS6A0dJWhkRv6kmLjMzW3/VNg0Na2Jca78tmAb0k9RX0ibAicDEfIGI6BsRfSKiD3A7cLqTgJlZ22rtwTSnAacDu0ialZvUlVaeUBYRKyWNIrsbqCNwbUTMljQyTW/xuoCZmbWN1pqGbgJ+B1wK5H8HsDQiXm+t8oiYBEyqGNdkAoiIk1qrz8zMaq+1B9O8CbyZ2u3/mp8m6VcR8eVCozMzs8JVe41gj/yApE7AvrUPx8zM2lqLiUDSeZKWAntJWtL4Al4he1iNmZlt4FprGroUuFTSpcAPgV2BLo2TC47NzMzaQLXdUD8PTCX7LcBM4OPAI8ChBcVlZmZtpNprBGcA+wF/jYhDgI8B7uvBzGwjUG0iWBYRywAkbRoRz5J1NWFmZhu4apuGGiRtA/wGuF/SG6zZXYSZmW2Aqu107oT09gJJDwBbA/cUFpWZmbWZas8I3hURU4oIxMzM6sPPHTYzKzknAjOzknMiMDMrOScCM7OSW+uLxWZmG7rJd8+sqtzQYwYUHEn74DMCM7OSKzQRSDpC0hxJcyWd28T04yTNkjRT0nRJBxUZj5mZramwpiFJHYGryJ533ABMkzQxIp7OFftfYGJEhKS9gFuBjxQVk5mZranIM4JBwNyIeD4ilgMTgOPyBSLirYho7M56C9y1tZlZmysyEewIzM8NN6Rx7yPpBEnPAr8FTmmqIkkjUtPR9EWL3OmpmVktFZkI1MS4NY74I+LOiPgIcDxwcVMVRcS4iBgYEQN79OhR4zDNzMqtyETQAOyUG+5FCz2WRsRUYBdJ3QuMyczMKhSZCKYB/ST1lbQJcCIwMV9A0oclKb3fB9gEWFxgTGZmVqGwu4YiYqWkUcC9QEfg2oiYLWlkmj4W+CfgK5JWAH8HPp+7eGxmZm2g0F8WR8QkYFLFuLG592OAMUXGYGZmLfMvi83MSs6JwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs6JwMys5JwIzMxKrtBEIOkISXMkzZV0bhPTvyhpVno9LGnvIuMxM7M1FZYIJHUErgKOBPoDwyX1ryj2AjAkIvYie3D9uKLiMTOzphV5RjAImBsRz0fEcmACcFy+QEQ8HBFvpMFHyR5wb2ZmbajIRLAjMD833JDGNeefgd8VGI+ZmTWhyGcWq4lxTT6YXtIhZIngoGamjwBGAPTu3btW8ZmZGcWeETQAO+WGewELKgtJ2gsYDxwXEYubqigixkXEwIgY2KNHj0KCNTMrqyITwTSgn6S+kjYBTgQm5gtI6g3cAXw5Ip4rMBYzM2tGYU1DEbFS0ijgXqAjcG1EzJY0Mk0fC5wPdAOulgSwMiIGFhWTmZmtqchrBETEJGBSxbixufdfA75WZAxmZtYy/7LYzKzknAjMzErOicDMrOScCMzMSs6JwMys5Aq9a2hD9MaUq6sqt+2Q0wuOxMysbfiMwMys5JwIzMxKzonAzKzknAjMzErOicDMrOScCMzMSs63jxZgzJQxVZUbPWR0wZGYmbXOZwRmZiXnMwIzK9Tku2dWVW7oMQMKjsSa4zMCM7OSKzQRSDpC0hxJcyWd28T0j0h6RNI/JJ1TZCxmZta0wpqGJHUErgKGkT3IfpqkiRHxdK7Y68AZwPFFxWFmZi0r8oxgEDA3Ip6PiOXABOC4fIGIeDUipgErCozDzMxaUGQi2BGYnxtuSOPWmqQRkqZLmr5o0aKaBGdmZpkiE4GaGBfrUlFEjIuIgRExsB8wpm4AAAe4SURBVEePHusZlpmZ5RWZCBqAnXLDvYAFBc7PzMzWQZGJYBrQT1JfSZsAJwITC5yfmZmtg8LuGoqIlZJGAfcCHYFrI2K2pJFp+lhJ2wPTga2A1ZLOAvpHxJKi4jIzs/cr9JfFETEJmFQxbmzu/ctkTUZmZlYn/mWxmVnJORGYmZXcBt/pnLt8NjNbPz4jMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzknMiMDMrOScCM7OScyIwMyu5Df6XxWb2nsl3z6yq3NBjBhQciW1IfEZgZlZyPiOwdq+9HuW217jM1pbPCMzMSq7QRCDpCElzJM2VdG4T0yXpp2n6LEn7FBmPmZmtqbCmIUkdgauAYWQPsp8maWJEPJ0rdiTQL732B36W/lqduLnDrHyKvEYwCJgbEc8DSJoAHAfkE8FxwC8jIoBHJW0jaYeIWFjrYKrdwe3dtdZzbl57jMnMyqfIRLAjMD833MCaR/tNldkReF8ikDQCGJEG35I0Z+3DWaNlCqA78Nra1wXwjXX72PuUIabCtMeYoH3G5Ziqs7HHtHNzE4pMBGpiXKxDGSJiHDCuFkG9b+bS9IgYWOt614djqk57jAnaZ1yOqTpljqnIi8UNwE654V7AgnUoY2ZmBSoyEUwD+knqK2kT4ERgYkWZicBX0t1DHwfeLOL6gJmZNa+wpqGIWClpFHAv0BG4NiJmSxqZpo8FJgFHAXOBd4CTi4qnGTVvbqoBx1Sd9hgTtM+4HFN1ShuTsht2zMysrPzLYjOzknMiMDMruVImAknXSnpV0lP1jqWRpJ0kPSDpGUmzJZ3ZDmLqIukxSU+kmC6sd0yNJHWU9GdJd9c7FgBJ8yQ9KWmmpOn1jgcg/UDzdknPpu3qE+0gpt3SOmp8LZF0VjuI61/TNv6UpJsldWkHMZ2Z4pld9Doq5TUCSYOBt8h+1fzRescDIGkHYIeIeFxSV2AGcHxFlxxtHZOALSLiLUmdgYeAMyPi0XrF1EjS2cBAYKuIOKYdxDMPGBgR7eYHSZJ+ATwYEePTnXubR8Tf6h1Xo9QNzUvA/hHx1zrGsSPZtt0/Iv4u6VZgUkRcX8eYPgpMIOuhYTlwD3BaRPyliPmV8owgIqYCr9c7jryIWBgRj6f3S4FnyH5lXc+YIiLeSoOd06vuRw6SegFHA+PrHUt7JWkrYDDwc4CIWN6ekkByGPB/9UwCOZ2AzSR1Ajan/r9n2h14NCLeiYiVwBTghKJmVspE0N5J6gN8DPhTfSN5twlmJvAqcH9E1D0m4CfAt4HV9Q4kJ4D7JM1IXaLU24eARcB1qQltvKQt6h1UhROBm+sdRES8BPwH8CJZ9zZvRsR99Y2Kp4DBkrpJ2pzsNvudWvnMOnMiaGckbQn8GjgrIpbUO56IWBURA8h+9T0onbLWjaRjgFcjYkY942jCgRGxD1mPut9IzY/11AnYB/hZRHwMeJtmOpKqh9RUdSxwWzuIZVuyDjD7Aj2BLSR9qZ4xRcQzwBjgfrJmoSeAlUXNz4mgHUnt8L8GboyIO+odT15qVpgMHFHnUA4Ejk1t8hOAQyXdUN+QICIWpL+vAneSte3WUwPQkDuDu50sMbQXRwKPR8Qr9Q4E+CTwQkQsiogVwB3AAXWOiYj4eUTsExGDyZqyC7k+AE4E7Ua6MPtz4JmI+M96xwMgqYekbdL7zci+MM/WM6aIOC8iekVEH7KmhT9ERF2P3iRtkS7wk5pfPkV2al83EfEyMF/SbmnUYby/C/h6G047aBZKXgQ+Lmnz9D08jOwaXV1J+kD62xv4DAWur1I+s1jSzcBQoLukBuD7EfHz+kbFgcCXgSdTmzzAdyJiUh1j2gH4Rbq7owNwa0S0i9s125kPAndm+xA6ATdFxD31DQmAfwFuTM0wz9P2Xbg0KbV5DwO+Xu9YACLiT5JuBx4na375M+2ju4lfS+oGrAC+ERFvFDWjUt4+amZm73HTkJlZyTkRmJmVnBOBmVnJORGYmZWcE4GZWck5EZiZlZwTgVmVJJ0k6coWpo+U9JW1rHOypIHrH53ZuivlD8rMipCew222wfEZgZWapG9LOiO9v1zSH9L7wyTdIOlkSc9JmkL26++W6rpA0jnp/WRJY9KDfZ6TdHAav5mkCZJmSboF2CyN31nSXyR1l9RB0oOSPlXksps1ciKwspsKHJzeDwS2TJ3/HUTWydeFZAlgGNB/LevuFBGDgLOA76dxpwHvRMRewCXAvgCpT/4xwFjgm8DT7aArZCsJJwIruxnAvqnTuH8Aj5AlhIPJ+niZnHqlXA7cspZ1N/YgOwPok94PBm4AiIhZwKzGwhExHugKjATOWZeFMVsXTgRWaqnb4XlkHbI9DDwIHALsQtYD5fp0xvWP9HcV778e12SdqTO2Xmlwy/WYr9lacSIwy5qHzkl/HyQ7Ip8JPAoMTU+J6gx8rkbz+iK8+1zavXLTxgA3AucD19RgXmZVcSIwy3b+OwCPpAelLCN76PtC4AKy5qLfk3VTvL5+RnYdYhbZ4zYfA5A0BNgPGBMRNwLLJbWLbqNt4+duqM3MSs5nBGZmJecflJmtJUnfZc3rBbdFxCX1iMdsfblpyMys5Nw0ZGZWck4EZmYl50RgZlZyTgRmZiX3/wFRf9Ik/kgM2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_soft.to('cpu')\n",
    "nn_soft.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(nn_soft, df_test, 442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 0, \n",
      "Predicted: 0.654\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Attention Visualization</h2><p><span style=\"margin:1px; padding:2px; background-color: #9fcae1\"><span class = \"barcode\"; style =\"color: black; background-color: #d0e1f2\">&nbsp부드럽게&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #ddeaf7\">&nbsp발리&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp고&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #dfebf7\">&nbsp뽀송하게&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #cde0f1\">&nbsp마무리&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #abd0e6\">&nbsp되고요&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp.&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #7fb9da\"><span class = \"barcode\"; style =\"color: black; background-color: #79b5d9\">&nbsp발색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #60a7d2\">&nbsp괜찮은데&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp.&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #d5e5f4\"><span class = \"barcode\"; style =\"color: black; background-color: #f1f7fd\">&nbsp그리&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #edf4fc\">&nbsp티&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #ebf3fb\">&nbsp나&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #e7f0fa\">&nbsp가는&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #dfebf7\">&nbsp색상&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #ddeaf7\">&nbsp아니고&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f7fbff\">&nbsp엄청&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #d7e6f5\">&nbsp이쁘지도&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #a4cce3\">&nbsp않네요&nbsp</span></span><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEXCAYAAACgUUN5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeoklEQVR4nO3de7wVdb3/8debi4CCV7YGbhXy5wWQ5CeElhxEi4eChvcL2VHU5HiOJFb2Q7M6Yab5O13U5CdpoR0rJeuYHCU93s1LIiQqFzEyyy2oiILgBbl8fn/MbFtu92X2Zs1amz3v5+MxD9bMfNf3+5m12PNZM9+Z7ygiMDOz4upU7QDMzKy6nAjMzArOicDMrOCcCMzMCs6JwMys4JwIzMwKzonA2gVJ0yV9s9pxtAeSDpb0Z0lrJR1T7Xis43MiKDBJD0p6U1K3BstflPTZkvl+kkJSlzK1O0HSI6XLIuKciPhOOepv0Nb2kmZIekXSGknPS5pS7nbK7BLgmojoGRG/a7hS0ghJj0laLekNSY9K+uTmNtrY92LF4ERQUJL6Af8EBDCuqsHk60dAT2AAsB3Jtv6lnA2UK0GW2ANY2ERb2wJ3AD8GdgR2BaYC68ocgxVJRHgq4AR8C3gU+CFwR8nym4BNwLvAWuD/AH8nSRhr0+lTadkzgcXAm8DdwB4l9QRwDvDndP00QCQ75PeAjWldq9LyNwKXlrz/bGAp8AYwC+jbUt1NbOcC4JhmPodBwD1pO68CX0+XdwOuBJal05VAt3TdKKAOmAK8kn5mnYALSZLMSuDXwI7NtNvo9qXvL/38uzV437D6z6yZusv5vXQDvp/+H3gVmA70aPA5fBV4DVgOnFHSVg/gB8DfgNXAIyXvPQh4DFgFPA2MKnnfBOAFYA3wV+DUav+9dPSp6gF4qtIXn+yE/g0YCqwHdilZ9yLw2ZL5fukOpEvJsmPSOgYAXYBvAI+VrA+SX67bA7sDK4Aj0nUTgEcaxHMjaSIADgNeBw5Id0Q/Bh7OUncj2/lTkl/XZwB7NVjXK915fRXons4fmK67BPgjsDNQk+60vpOuGwVsAK5I4+sBnJ+Wr02X/QS4uYmYWtq+D33+Dd67LUmi+TkwBtihwfpyfy9XkiSqHdPP57+Byxt8DpcAXYGxwDv1MZEkmQdJjlo6A59Ot3fXdBvGkiTQ0el8DbAN8BawT1pHH2BQtf9eOvpU9QA8VeFLhxEkO//e6fxzwJdL1n9oR0TjieD3wFkl853SncAe6XwAI0rW/xq4MH3d2A7nRv6RCH4G/N+SdT3TePu1VHcj29oD+DowL61jKTAmXTceeKqJ9/0FGFsyfzjwYvp6FPA+0L1k/WLgMyXzfdL2ujRSd0vb96HPv5H3D0g/r7p0RzyLNJGX83shOVJ4G9izZNmngL+WfA7vNvh/8RrJr/1O6br9G4l/CnBTg2V3A6eTJIJVwPGkRw+e8p/cR1BMpwP/ExGvp/O/Spe1xh7AVZJWSVpFcopDJL/26r1S8vodkh1eFn1JTicAEBFrSX4xtrruiHg3Ii6LiKHATiQ7vlsl7QjsRtP9BR+KIX3dt2R+RUS8VzK/B3BbyeexmOQ0yy5t3L4mRcTiiJgQEbXAfml9V5bEUa7vpQbYGphXUt9d6fJ6KyNiQyP19SY5ymrs890DOLG+zrTeEUCfiHgbOJnk9NVySXdK2rfZD8Q2mxNBwUjqAZwEHJJeSfMK8GVgf0n7p8UaDknb2BC1LwH/EhHbl0w9IuKxDGG0NOTtMpKdRX3M25DsxF/OUHfTjUa8BVxG8quzP8k27JklBpLTKMtKq2tQ/iWSI43Sz6N7RDQWc9m2LyKeIzk62K8kjnJ9L6+T/KofVFLXdhGRJaG/TtLn0Njn+xLJEUFpjNtExPfSbbo7IkaTHFU9B1yfoT3bDE4ExXMMyS/VgcCQdBoA/AE4LS3zKvDxkvesIOnALF02HbhI0iAASdtJOjFjDK8CtZK2amL9r4AzJA1JL229DHgiIl7MWP8HJH1T0iclbSWpOzCZ5NTDEpJz5R+TdL6kbpJ6STowfevNwDck1UjqTdK5/otmmpoOfFfSHmm7NZKOLvf2SdpX0lcl1abzu5Gc4vpjSRxl+V4iYhPJTvhHknZO69tV0uEtVZS+dwbwQ0l9JXWW9Kl0e38BfE7S4eny7pJGSaqVtIukcWlyXEfScb0xY/zWRk4ExXM6cENE/D0iXqmfgGuAU9NLIS8n2QmuknRBRLwDfBd4NF12UETcRtJZeoukt0iuzhmTMYb7STpwX5H0esOVEXEf8E3gtySduXsCp7RxewO4geQX6jKSjskjI2JtRKxJ5z9Hcrrkz8Ch6fsuBeYCzwDPAn9KlzXlKpJz9f8jaQ3JjvnAxgpu5vatSet9QtLbaTsLSDq8yeF7mULSr/LHtL57gX0y1ncByWf3JMkpqiuAThHxEnA0Sd/NCpIjhK+R7I86pduyLH3PISQXNViOFOEH05iZFZmPCMzMCs6JwMys4JwIzMwKzonAzKzgyj1YVu569+4d/fr1q3YYZmZblHnz5r0eETWNrdviEkG/fv2YO3dutcMwM9uiSPpbU+t8asjMrOCcCMzMCs6JwMys4La4PgIzs821fv166urqeO+991ouvIXp3r07tbW1dO3aNfN7nAjMrHDq6uro1asX/fr1Q1K1wymbiGDlypXU1dXRv3//zO/zqSEzK5z33nuPnXbaqUMlAQBJ7LTTTq0+0nEiMLNC6mhJoF5btsuJwMys4JwIzMwKzp3FZg28Mu28irf5sXOvrnibVl7z589n2bJljB07tskys2bNYtGiRVx44YWZ650wYQJHHXUUJ5xwQjnCbJSPCMzMymD+/PnMnj272TLjxo1rVRKoFCcCMyu8t99+myOPPJL999+f/fbbj5kzZzJv3jwOOeQQhg4dyuGHH87y5csBGDVqFFOmTGH48OHsvffe/OEPf+D999/nW9/6FjNnzmTIkCHMnDmz0XZuvPFGJk2aBCS/9M877zw+/elP8/GPf5zf/OY3QHIJ6KRJkxg4cCBHHnkkr732GgCrV69mn332YcmSJQCMHz+e66+/vizb71NDZlZ4d911F3379uXOO+8Ekp3umDFjuP3226mpqWHmzJlcfPHFzJgxA4ANGzYwZ84cZs+ezdSpU7n33nu55JJLmDt3Ltdcc03mdpcvX84jjzzCc889x7hx4zjhhBO47bbbWLJkCc8++yyvvvoqAwcO5Mwzz2S77bbjmmuuYcKECUyePJk333yTs88+uyzb70RgZoU3ePBgLrjgAqZMmcJRRx3FDjvswIIFCxg9ejQAGzdupE+fPh+UP+644wAYOnQoL774YpvbPeaYY+jUqRMDBw7k1VdfBeDhhx9m/PjxdO7cmb59+3LYYYd9UH706NHceuutnHvuuTz99NNtbrchJwIzK7y9996befPmMXv2bC666CJGjx7NoEGDePzxxxst361bNwA6d+7Mhg0b2txufT2QnBKq19S9AJs2bWLx4sX06NGDN954g9ra2ja3Xcp9BGZWeMuWLWPrrbfmC1/4AhdccAFPPPEEK1as+CARrF+/noULFzZbR69evVizZs1mxzJy5EhuueUWNm7cyPLly3nggQc+WPejH/2IAQMGcPPNN3PmmWeyfv36zW4PfERgZsazzz7L1772NTp16kTXrl259tpr6dKlC+eddx6rV69mw4YNnH/++QwaNKjJOg499FC+973vMWTIEC666CJOPvnkNsVy7LHHcv/99zN48GD23ntvDjnkEACef/55fvrTnzJnzhx69erFyJEjufTSS5k6dWqb2iml0sORLcGwYcPCTyizPPk+go5v8eLFDBgwoNph5Kax7ZM0LyKGNVbep4bMzArOp4bMzMrshhtu4KqrrvrQsoMPPphp06ZVKaLmORGYmZXZGWecwRlnnFHtMDLzqSEzs4JzIjAzKzgnAjOzgnMfgZlZM9569tay1rft4BNbLHPmmWdyxx13sPPOO7NgwYKytt8YHxGYmbUzEyZM4K677qpYe04EZmbtzMiRI9lxxx0r1p4TgZlZwTkRmJkVXK6JQNIRkpZIWiqpyeezSfqkpI2S8nsop5mZNSq3RCCpMzANGAMMBMZLGthEuSuAu/OKxczMmpbn5aPDgaUR8QKApFuAo4FFDcp9Cfgt8MkcYzEza5Msl3uW2/jx43nwwQd5/fXXqa2tZerUqZx11lm5tZdnItgVeKlkvg44sLSApF2BY4HDaCYRSJoITATYfffdyx6omVl7cvPNN1e0vTz7CBp71lrDhx9cCUyJiI3NVRQR10XEsIgYVlNTU7YAzcws3yOCOmC3kvlaYFmDMsOAW9Lnc/YGxkraEBG/yzEuMzMrkWcieBLYS1J/4GXgFODzpQUion/9a0k3Anc4CZiZVVZuiSAiNkiaRHI1UGdgRkQslHROun56Xm2bmVl2uQ46FxGzgdkNljWaACJiQp6xmJlZ43xnsZlZwXkYajOzZrwy7byy1vexc69uscxLL73EaaedxiuvvEKnTp2YOHEikydPLmscpZwIzMzamS5duvCDH/yAAw44gDVr1jB06FBGjx7NwIEfGZyhLHxqyMysnenTpw8HHHAAAL169WLAgAG8/PLLubXnRGBm1o69+OKLPPXUUxx44IEtF24jJwIzs3Zq7dq1HH/88Vx55ZVsu+22ubXTofsIyv2s0ayqMUiVmXUs69ev5/jjj+fUU0/luOOOy7UtHxGYmbUzEcFZZ53FgAED+MpXvpJ7ex36iMDMbHNludyz3B599FFuuukmBg8ezJAhQwC47LLLGDt2bC7tORGYmbUzI0aMIKLhYM358akhM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgnMiMDMrOF8+ambWjAc/M7ys9Y26b06z69977z1GjhzJunXr2LBhAyeccAJTp04tawwNORGYmbUj3bp14/7776dnz56sX7+eESNGMGbMGA466KDc2vSpITOzdkQSPXv2BJLxhtavX4+kXNt0IjAza2c2btzIkCFD2HnnnRk9enSuQ1CDE4GZWbvTuXNn5s+fT11dHXPmzGHBggW5tudEYGbWTm2//faMGjWKu+66K9d2nAjMzNqRFStWsGrVKgDeffdd7r33Xvbdd99c2/RVQ2ZmzWjpcs9yW758OaeffjobN25k06ZNnHTSSRx11FG5ttliIpDUDTge6FdaPiIuyS8sM7Ni+sQnPsFTTz1V0TazHBHcDqwG5gHr8g3HzMwqLUsiqI2II3KPxMzMqiJLZ/FjkgbnHomZWQVV8glgldSW7cqSCEYA8yQtkfSMpGclPdPqlszM2onu3buzcuXKDpcMIoKVK1fSvXv3Vr0vy6mhMW0LycysfaqtraWuro4VK1ZUO5Sy6969O7W1ta16T4uJICL+Jml/4J/SRX+IiKfbEJ+ZWbvQtWtX+vfvX+0w2o0WTw1Jmgz8Etg5nX4h6Ut5B2ZmZpWR5dTQWcCBEfE2gKQrgMeBH+cZmJmZVUaWzmIBG0vmN6bLzMysA8hyRHAD8ISk29L5Y4Cf5ReSmZlVUpbO4h9KepDkMlIBZ0REZe9/NjOz3DSZCCRtGxFvSdoReDGd6tftGBFv5B+emZnlrbk+gl+l/84D5pZM9fMtknREeiPaUkkXNrL+6PQmtfmS5koa0cr4zcxsMzV5RBARR6X/tuliW0mdgWnAaKAOeFLSrIhYVFLsPmBWRISkTwC/BvIdeNvMzD4ky30E92VZ1ojhwNKIeCEi3gduAY4uLRARa+Mf93hvA3Ss+73NzLYAzfURdAe2BnpL2oF/XDK6LdA3Q927Ai+VzNcBH3kCs6RjgctJblY7solYJgITAXbfffcMTZuZWVbNHRH8C0l/wL7pv/XT7SSnfFrS2L0GH/nFHxG3RcS+JJelfqexiiLiuogYFhHDampqMjRtZmZZNddHcBVwlaQvRURb7iKuA3Yrma8FljXT3sOS9pTUOyJeb0N7ZmbWBlnuI/ixpE/z0UdV/mcLb30S2EtSf+Bl4BTg86UFJP0v4C9pZ/EBwFbAylZtgZmZbZYszyy+CdgTmM8/hpoIoNlEEBEbJE0C7gY6AzMiYqGkc9L100mehXyapPXAu8DJJZ3HZmZWAVmGmBgGDGzLDjoiZgOzGyybXvL6CuCK1tZrZmblk2XQuQXAx/IOxMzMqiPLEUFvYJGkOcC6+oURMS63qMzMrGKyJIJv5x2EmZlVT5arhh6StAewV0TcK2lrks5fMzPrALIMMXE28BvgJ+miXYHf5RmUmZlVTpbO4nOBg4G3ACLizyTDQZiZWQeQJRGsSweNA0BSFzw4nJlZh5ElETwk6etAD0mjgVuB/843LDMzq5QsieBCYAXwLMlAdLMj4uJcozIzs4rJcvnol9IB6K6vXyBpcrrMzMy2cFmOCE5vZNmEMsdhZmZV0tyDacaTjBbaX9KsklW98AihZmYdRnOnhh4DlpMMMfGDkuVrgGfyDMrMzCqnuQfT/A34m6SHI+Kh0nWSrgCm5B2cmZnlL0sfwehGlo0pdyBmZlYdzfUR/Cvwb8CekkpPBfUCHs07MDMzq4zm+gh+BfweuJzkXoJ6ayLijVyjMjOzimmuj2A1sBoYDyBpZ6A70FNSz4j4e2VCNDOzPGUZffRzkv4M/BV4CHiR5EjBzMw6gCydxZcCBwHPR0R/4DO4j8DMrMPIkgjWR8RKoJOkThHxADAk57jMzKxCsow1tEpST+Bh4JeSXgM25BuWmZlVSpYjgqOBd4AvA3cBfwE+l2dQZmZWOVmeWfx2+nIT8PN8wzEzs0rLckRgZmYdmBOBmVnBZUoEknpI2ifvYMzMrPIy3VAGzCfpKEbSkAbPJzAzsy1YliOCbwPDgVUAETEf6JdfSGZmVklZEsGGdNwhMzPrgLLcULZA0ueBzpL2As4jeXqZmZl1AFmOCL4EDALWkQxNvRo4P8+gzMyscrLcUPYOcHE6mZlZB5PlqqF7JG1fMr+DpLvzDcvMzColy6mh3hGxqn4mIt4Eds4vJDMzq6QsiWCTpN3rZyTtAUR+IZmZWSVluWroYuARSQ+l8yOBifmFZGZmldTiEUFE3AUcAMwEfg0MjYhMfQSSjpC0RNJSSRc2sv5USc+k02OS9m/tBpiZ2ebJckQA0A14Iy0/UBIR8XBzb5DUGZgGjAbqgCclzYqIRSXF/gocEhFvShoDXAcc2NqNMDOztmsxEUi6AjgZWEjyTAJI+giaTQQkw1IsjYgX0npuIXnIzQeJICJKb0z7I1CbOXIzMyuLLEcExwD7RMS6Vta9K/BSyXwdzf/aPwv4fWMrJE0k7ZfYfffdGytiZmZtlOWqoReArm2oW40sa/RqI0mHkiSCKY2tj4jrImJYRAyrqalpQyhmZtaULEcE7wDzJd1HMswEABFxXgvvqwN2K5mvBZY1LCTpE8BPgTERsTJDPGZmVkZZEsGsdGqtJ4G9JPUHXgZOAT5fWiC9P+G/gH+OiOfb0IaZmW2mLGMN/VxSD2D3iFiSteKI2CBpEnA30BmYERELJZ2Trp8OfAvYCfh/kiAZ8npYG7bDzMzaKMtVQ58Dvg9sBfSXNAS4JCLGtfTeiJgNzG6wbHrJ6y8CX2xt0GZmVj5tfUJZ/xxjMjOzCmrrE8o81pCZWQfhJ5SZmRVcW59QNjnPoMzMrHKyHBEcGREfekKZpBOBW3OLyszMKibLEcFFGZeZmdkWqMkjgnQ00LHArpKuLlm1LbAh78DMzLYUD35meFXaHXXfnLLU09ypoWXAXGAcMK9k+Rrgy2Vp3czMqq7JRBARTwNPS/pVRKyvYExmZlZBWTqLh0v6NrBHWl5ARMTH8wzMzMwqI0si+BnJqaB5wMZ8wzEzs0rLkghWR0SjD4wxM7MtX5ZE8ICk/yAZLrr0eQR/yi0qMzOrmCyJoP7xkqXDQwdwWPnDMTOzSsvyPIJDKxGImZlVR4t3FkvaRdLPJP0+nR8o6az8QzMzs0rIMsTEjSRPGeubzj8PnJ9XQGZmVllZEkHviPg1sAmSR1Diy0jNzDqMLIngbUk7kT6MRtJBJENRm5lZB5DlqqGvALOAPSU9CtQAJ+QalZmZVUyWq4b+JOkQYB+S4SWWeOwhM7OOI8tVQycCPSJiIXAMMFPSAblHZmZmFZGlj+CbEbFG0gjgcODnwLX5hmVmZpWSJRHUXyF0JHBtRNwObJVfSGZmVklZEsHLkn4CnATMltQt4/vMzGwLkGWHfhLJDWVHRMQqYEfga7lGZWZmFZPlqqF3SEYerZ9fDizPMygzM6scn+IxMys4JwIzs4JzIjAzKzgnAjOzgnMiMDMrOCcCM7OCcyIwMys4JwIzs4JzIjAzKzgnAjOzgss1EUg6QtISSUslXdjI+n0lPS5pnaQL8ozFzMwal+VRlW0iqTMwDRgN1AFPSpoVEYtKir0BnEfywBszM6uCPI8IhgNLI+KFiHgfuAU4urRARLwWEU8CfvSlmVmV5JkIdgVeKpmvS5e1mqSJkuZKmrtixYqyBGdmZok8E4EaWRZtqSgirouIYRExrKamZjPDMjOzUnkmgjpgt5L5WmBZju2ZmVkb5JkIngT2ktRf0lbAKcCsHNszM7M2yO2qoYjYIGkSyWMuOwMzImKhpHPS9dMlfQyYC2wLbJJ0PjAwIt7KKy4zM/uw3BIBQETMBmY3WDa95PUrJKeMzMysSnxnsZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcE5EZiZFZwTgZlZweWaCCQdIWmJpKWSLmxkvSRdna5/RtIBecZjZmYflVsikNQZmAaMAQYC4yUNbFBsDLBXOk0Ers0rHjMza1yeRwTDgaUR8UJEvA/cAhzdoMzRwH9G4o/A9pL65BiTmZk10CXHuncFXiqZrwMOzFBmV2B5aSFJE0mOGADWSlpS3lDbld7A69UOwtqsbd/fpB+XPxJrrS3vb09qTek9mlqRZyJoLMJoQxki4jrgunIE1d5JmhsRw6odh7WNv78tV5G/uzxPDdUBu5XM1wLL2lDGzMxylGcieBLYS1J/SVsBpwCzGpSZBZyWXj10ELA6IpY3rMjMzPKT26mhiNggaRJwN9AZmBERCyWdk66fDswGxgJLgXeAM/KKZwtSiFNgHZi/vy1XYb87RXzklLyZmRWI7yw2Mys4JwIzs4JzImgnJM2Q9JqkBdWOxVpH0m6SHpC0WNJCSZOrHZNlJ6m7pDmSnk6/v6nVjqnS3EfQTkgaCawludN6v2rHY9mld8P3iYg/SeoFzAOOiYhFVQ7NMpAkYJuIWCupK/AIMDkd7aAQfETQTkTEw8Ab1Y7DWi8ilkfEn9LXa4DFJHfI2xYgHeJmbTrbNZ0K9QvZicCsjCT1A/438ER1I7HWkNRZ0nzgNeCeiCjU9+dEYFYmknoCvwXOj4i3qh2PZRcRGyNiCMnoBsMlFer0rBOBWRmk55Z/C/wyIv6r2vFY20TEKuBB4Igqh1JRTgRmmyntbPwZsDgifljteKx1JNVI2j593QP4LPBcdaOqLCeCdkLSzcDjwD6S6iSdVe2YLLODgX8GDpM0P53GVjsoy6wP8ICkZ0jGSLsnIu6ockwV5ctHzcwKzkcEZmYF50RgZlZwTgRmZgXnRGBmVnBOBGZmBedEYGZWcE4EZq0kaUhL9wlIGifpwlbWe6OkEzYvOrPWcyIwa70hJM/ablJEzIqI71UoHrPN4kRghSJpG0l3pg8hWSDpZElDJT0kaZ6ku9PnCyDpQUlXpA8teV7SP0naCrgEODm9g/jkJtqZIOma9PWNkq6W9JikF+p/9StxjaRFku4Edk6XbydpiaR90vmbJZ1dgY/HCqpLtQMwq7AjgGURcSQkO13g98DREbEi3bF/FzgzLd8lIoanp4L+PSI+K+lbwLCImNSKdvsAI4B9gVnAb4BjgX2AwcAuwCJgRkSsljQJuFHSVcAOEXH9Zm63WZOcCKxongW+L+kK4A7gTWA/4J5k7Dg6A8tLytePJDoP6LcZ7f4uIjYBiyTtki4bCdwcERuBZZLury8cEfdIOhGYBuy/Ge2atciJwAolIp6XNJTkHP/lwD3Awoj4VBNvWZf+u5HN+3tZV/JapSE1VlhSJ2AA8C6wI1C3GW2bNct9BFYokvoC70TEL4DvAwcCNZI+la7vKmlQC9WsAXqVIZyHgVPSp2P1AQ4tWfdlkkdejgdmpM87MMuFjwisaAYD/yFpE7Ae+FdgA3B12l/QBbgSWNhMHQ8AF6aPNrw8Ima2MZbbgMNITlc9DzwEIGlv4IvA8IhYI+lh4BvAv7exHbNmeRhqM7OC86khM7OC86khs80g6QxgcoPFj0bEudWIx6wtfGrIzKzgfGrIzKzgnAjMzArOicDMrOCcCMzMCu7/A1kHYcUJSH19AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_soft.to('cpu')\n",
    "nn_soft.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(nn_soft, df_test, 532)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tanh Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 0.05, 'beta_de': 0.05, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'tanh'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.6124157792329789 hm:0.6309810969559073\n",
      " ==> New best value..loss:0.5865066981315613 hm:0.6841329697784676\n",
      " ==> New best value..loss:0.5638254767656327 hm:0.7100200074244094\n",
      " ==> New best value..loss:0.5581099092960358 hm:0.7185865240601189\n",
      " ==> New best value..loss:0.5450933283567428 hm:0.7296068665999178\n",
      " ==> New best value..loss:0.5285295742750168 hm:0.7443730321234258\n",
      " ==> New best value..loss:0.5218176472187043 hm:0.75881182924792\n",
      " ==> New best value..loss:0.5195604169368744 hm:0.7669636526856048\n",
      " ==> New best value..loss:0.5026221948862076 hm:0.7747699467738252\n",
      " ==> New best value..loss:0.5007812237739563 hm:0.7812090404566736\n",
      " ==> New best value..loss:0.49689495861530303 hm:0.7842087576151247\n",
      " ==> New best value..loss:0.4924886476993561 hm:0.7912742786896055\n",
      " ==> New best value..loss:0.4868162849545479 hm:0.7967727474740919\n",
      " ==> New best value..loss:0.47986393511295317 hm:0.8023241809852375\n",
      " ==> New best value..loss:0.4711190840601921 hm:0.807930069031199\n",
      " ==> New best value..loss:0.4658284372091293 hm:0.8107253479926115\n",
      " ==> New best value..loss:0.46299931943416595 hm:0.8111395647227179\n",
      " ==> New best value..loss:0.4567680996656418 hm:0.8132675142027562\n",
      " ==> New best value..loss:0.4530921584367752 hm:0.8175501332050684\n",
      " ==> New best value..loss:0.44856777012348176 hm:0.8176968614678087\n",
      " ==> New best value..loss:0.4478039884567261 hm:0.8185567946823594\n",
      " ==> New best value..loss:0.44448768138885497 hm:0.8219502212319693\n",
      " ==> New best value..loss:0.44260979652404786 hm:0.8241876292607356\n",
      " ==> New best value..loss:0.4382687383890152 hm:0.8248007978459981\n",
      " ==> New best value..loss:0.4370147892832756 hm:0.8259286550564663\n",
      " ==> New best value..loss:0.4348995196819305 hm:0.8308116627238944\n",
      " ==> New best value..loss:0.4280532535910606 hm:0.8308868112180714\n",
      " ==> New best value..loss:0.42619433760643005 hm:0.8310804090620353\n",
      " ==> New best value..loss:0.42457748770713805 hm:0.8351868229051514\n",
      " ==> New best value..loss:0.42060778230428697 hm:0.8372186073990533\n",
      " ==> New best value..loss:0.41472031354904176 hm:0.8426714959625966\n",
      " ==> New best value..loss:0.4115646356344223 hm:0.8437392054374465\n",
      " ==> New best value..loss:0.40603112399578095 hm:0.8461095418452499\n",
      " ==> New best value..loss:0.40557453215122224 hm:0.8507868690728684\n",
      " ==> New best value..loss:0.3924713796377182 hm:0.8518872351862895\n",
      " ==> New best value..loss:0.3903636735677719 hm:0.8518943025908433\n",
      " ==> New best value..loss:0.3879381176829338 hm:0.8534770673750594\n"
     ]
    }
   ],
   "source": [
    "params_dict['tan_a'] = 0.5\n",
    "params_dict['attention'] = 'tanh'\n",
    "best_score, nn_tanh = do_training( df_in1, params_dict, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 1, \n",
      "Predicted: 0.332\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Attention Visualization</h2><p><span style=\"margin:1px; padding:2px; background-color: #fcf5f1\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp봄&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp이랑&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp어울리는&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp이에요&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #fce3d6\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp당근&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp과&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp단감&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp의&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp중간&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp착색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp핑크&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp가&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp아니라&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp주황색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp입니다&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #f9d3c2\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp추천&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp해&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp요&nbsp</span></span><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_tanh.to('cpu')\n",
    "nn_tanh.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(nn_tanh, df_test, 442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_tanh.to('cpu')\n",
    "nn_tanh.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(nn_tanh, df_test, 532)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CoDA (Quasi- Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training =======>\n",
      "{'embed_dim': 100, 'word_gru_h_dim': 100, 'sent_gru_h_dim': 100, 'word_gru_n_layers': 2, 'sent_gru_n_layers': 2, 'word_att_dim': 200, 'sent_att_dim': 200, 'dropgru_s': 0.2, 'dropgru_w': 0.2, 'dropval': 0.2, 'tan_a': 0.5, 'alpha_de': 1, 'beta_de': 0.5, 'batch_size': 30, 'fc1': 200, 'fc2': 30, 'drop_fc': 0.4, 'fc': Sequential(\n",
      "  (0): Dropout(p=0.4, inplace=False)\n",
      "  (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (2): Dropout(p=0.2, inplace=False)\n",
      "  (3): Linear(in_features=200, out_features=30, bias=True)\n",
      "  (4): Dropout(p=0.2, inplace=False)\n",
      "  (5): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (6): Sigmoid()\n",
      "), 'epochs': 30, 'output_size': 1, 'lr': 0.0001, 'print_every': 19, 'clip_val': 1.5, 'attention': 'de_attention'}\n",
      "================================================================================\n",
      " ==> New best value..loss:0.635382067184059 hm:0.5930419139937746\n",
      " ==> New best value..loss:0.6271741925453653 hm:0.594336209066928\n",
      " ==> New best value..loss:0.6173048165379739 hm:0.6095508611722168\n",
      " ==> New best value..loss:0.6041059396704849 hm:0.6280486445673326\n",
      " ==> New best value..loss:0.5943182408809662 hm:0.6479292007077562\n",
      " ==> New best value..loss:0.5843828758414911 hm:0.6638555475252353\n",
      " ==> New best value..loss:0.581925666453887 hm:0.6760787059888069\n",
      " ==> New best value..loss:0.5801601349091043 hm:0.6869987820263818\n",
      " ==> New best value..loss:0.5729799763280519 hm:0.6936666265881545\n",
      " ==> New best value..loss:0.5678890292741814 hm:0.6996366274136635\n",
      " ==> New best value..loss:0.5583967280631162 hm:0.7063174234809514\n",
      " ==> New best value..loss:0.5559390503533033 hm:0.7095886440645677\n",
      " ==> New best value..loss:0.5551765926030218 hm:0.7122074877964404\n",
      " ==> New best value..loss:0.5531021320090002 hm:0.7159353533184006\n",
      " ==> New best value..loss:0.5523883098242234 hm:0.7207243270789347\n",
      " ==> New best value..loss:0.5479268918232042 hm:0.7212809891026274\n",
      " ==> New best value..loss:0.5475210139946062 hm:0.7240919238930321\n",
      " ==> New best value..loss:0.5412308902156596 hm:0.7252352402584726\n",
      " ==> New best value..loss:0.5398874818062296 hm:0.7259860783748318\n",
      " ==> New best value..loss:0.538969409709074 hm:0.7275081092561925\n",
      " ==> New best value..loss:0.5373009662238919 hm:0.7276926206683949\n",
      " ==> New best value..loss:0.535741957474728 hm:0.7303779514715804\n",
      " ==> New best value..loss:0.53518024816805 hm:0.7320173686515423\n",
      " ==> New best value..loss:0.531502016344849 hm:0.7349999994694153\n",
      " ==> New best value..loss:0.5311964409691947 hm:0.73700001349684\n",
      " ==> New best value..loss:0.5276806178141613 hm:0.7370020086746766\n",
      " ==> New best value..loss:0.5276506458009992 hm:0.7381813768708383\n",
      " ==> New best value..loss:0.5244230980775795 hm:0.741864169588905\n",
      " ==> New best value..loss:0.5221993400126087 hm:0.7431212583721672\n",
      " ==> New best value..loss:0.5217837551418616 hm:0.7438614468897484\n",
      " ==> New best value..loss:0.5206790718497062 hm:0.7445854277788626\n",
      " ==> New best value..loss:0.5185972616380575 hm:0.7451287569978281\n",
      " ==> New best value..loss:0.5184306465849584 hm:0.7464794774495453\n",
      " ==> New best value..loss:0.5166029352314618 hm:0.7510869212102163\n",
      " ==> New best value..loss:0.512722333475035 hm:0.7513474819049818\n"
     ]
    }
   ],
   "source": [
    "params_dict['alpha_de'] = 1\n",
    "params_dict['beta_de'] = 0.5 \n",
    "params_dict['attention'] = 'de_attention'\n",
    "best_score, nn_coda = do_training( df_in1, params_dict, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 0, \n",
      "Predicted: 0.297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Attention Visualization</h2><p><span style=\"margin:1px; padding:2px; background-color: #b3808f\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp부드럽게&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #bb8290\">&nbsp발리&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp고&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp뽀송하게&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #e4a3a0\">&nbsp마무리&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #fbfaf9\">&nbsp되고요&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp.&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #ba8290\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp발색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f6f9fa\">&nbsp괜찮은데&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp.&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #eaf3f8\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp그리&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp티&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp나&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp가는&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp색상&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f8cebd\">&nbsp아니고&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp엄청&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #f6f8fa\">&nbsp이쁘지도&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #99bfdc\">&nbsp않네요&nbsp</span></span><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_coda.to('cpu')\n",
    "nn_coda.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(nn_coda, df_test, 532)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: 1, \n",
      "Predicted: 0.220\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>Attention Visualization</h2><p><span style=\"margin:1px; padding:2px; background-color: #b3808f\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp봄&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp이랑&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp어울리는&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #eaf3f8\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp이에요&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #b3808f\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp당근&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp과&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp단감&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp의&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp중간&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b4808f\">&nbsp착색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b6808f\">&nbsp핑크&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp가&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b68190\">&nbsp아니라&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #fad9c9\">&nbsp주황색&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #c9e2ef\">&nbsp입니다&nbsp</span></span><p><p><span style=\"margin:1px; padding:2px; background-color: #fbfaf9\"><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp추천&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #e8aba4\">&nbsp해&nbsp</span><span class = \"barcode\"; style =\"color: black; background-color: #b3808f\">&nbsp요&nbsp</span></span><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_coda.to('cpu')\n",
    "nn_coda.eval()\n",
    "result, a_it, a_i, g_t = visualize_att(nn_coda, df_test, 442)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdbu = cmap_map(lambda x: x/2 + 0.5, matplotlib.cm.RdBu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test module 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifer = nn_deattention[10]\n",
    "# classifer.to('cpu')\n",
    "# classifer.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['부드럽게 발리고 뽀송하게 마무리되고요.', '발색 괜찮은데.', '그리 티 나 가는 색상 아니고 엄청 이쁘지도 않네요']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = random.randint(0, len(df_test))\n",
    "print(ind)\n",
    "df_test['sent_org'][ind] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['봄이랑 어울리는 색이에요', '당근과 단감의 중간색 착색 핑크가 아니라 주황색입니다', '추천 해요']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 442\n",
    "# ['봄이랑 어울리는 색이에요', '당근과 단감의 중간색 착색 핑크가 아니라 주황색입니다', '추천 해요']\n",
    "\n",
    "\n",
    "\n",
    "# 349\n",
    "# ['색상 전체적으로 다 예쁘고 발림성도 괜찮은 것 같아요', '저렴한 가격에 1플러스1으로 구입해서 만족합니다.']\n",
    "\n",
    "# 532\n",
    "# ['봄이랑 어울리는 색이에요', '당근과 단감의 중간색 착색 핑크가 아니라 주황색입니다', '추천 해요']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['봄이랑 어울리는 색이에요', '당근과 단감의 중간색 착색 핑크가 아니라 주황색입니다', '추천 해요']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sent_org'][442] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['부드럽게 발리고 뽀송하게 마무리되고요.', '발색 괜찮은데.', '그리 티 나 가는 색상 아니고 엄청 이쁘지도 않네요']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['sent_org'][532] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_doc, x_s, g_t = get_test_sample(df_test, ind)\n",
    "sig_out, a_it, a_i = classifer(x_s)\n",
    "\n",
    "#    docs, doc_lengths, sent_lengths = x_s\n",
    "\n",
    "# get attention values with the trained model\n",
    "#  v, a_it, a_i = han_encoder(docs, doc_lengths, sent_lengths)\n",
    "\n",
    "# get raw data\n",
    "raw_sent = df_test.iloc[ind, :]['sent_org']\n",
    "raw_sent_tok = [ okt.pos(elem) for elem in raw_sent ]\n",
    "processed_raw = [ list(zip(*raw_sent_tok[i]))[0] for i in range(len(raw_sent_tok))]\n",
    "processed_raw = [ list(i) for i in processed_raw] \n",
    "x = len(processed_raw)\n",
    "y = max( [len(i) for i in processed_raw] )\n",
    "update_att = np.zeros((x, y)).tolist()\n",
    "\n",
    "# fill in word attentions\n",
    "wd_atts = a_it.data.tolist()[0]\n",
    "diff = y - len(wd_atts[0])\n",
    "wd_atts = [ i + np.zeros(diff).tolist() for i in wd_atts ]\n",
    "\n",
    "# update attention\n",
    "for s, z in enumerate(zip(orig_doc, processed_raw)):\n",
    "    cnt = 0\n",
    "    for wd, val in enumerate(z[1]): \n",
    "        if val in z[0]:\n",
    "            update_att[s][wd] = wd_atts[s][cnt]  \n",
    "            cnt += 1\n",
    "\n",
    "# Vosia;oze\n",
    "words = processed_raw\n",
    "sent_score = a_i.tolist()[0]\n",
    "word_score = update_att# update_att.tolist()[0]\n",
    "result = \"<h2>Attention Visualization</h2>\"\n",
    "for sent, word_att, sent_att in zip(words, word_score, sent_score):\n",
    "    result += map_sentence_to_color( sent, word_att, sent_att)\n",
    "\n",
    "\n",
    "display(HTML(result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_sentence_to_color( sent, word_att, sent_att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencemap = matplotlib.cm.get_cmap('Blues')\n",
    "wordmap = matplotlib.cm.get_cmap('Blues')\n",
    "\n",
    "words, scores, sent_score = sent, word_att, sent_att \n",
    "\n",
    "result = '<p><span style=\"margin:1px; padding:2px; background-color: {}\">'\\\n",
    "   .format(matplotlib.colors.rgb2hex(sentencemap(sent_score)[:3]))\n",
    "template = '<span class = \"barcode\"; style =\"color: black; background-color: {}\">{}</span>'\n",
    "for word, score in zip(words, scores):\n",
    "    color = matplotlib.colors.rgb2hex(wordmap(score)[:3])\n",
    "    result += template.format(color, '&nbsp' + word + '&nbsp')\n",
    "result += '</span><p>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_att(classifier, df_test, ind, random_st = 21 ):\n",
    "    orig_doc, x_s, g_t = get_test_sample(df_test, ind)\n",
    "    sig_out, a_it, a_i = classifier(x_s)\n",
    "    \n",
    "#    docs, doc_lengths, sent_lengths = x_s\n",
    "    \n",
    "    # get attention values with the trained model\n",
    "  #  v, a_it, a_i = han_encoder(docs, doc_lengths, sent_lengths)\n",
    "    \n",
    "    # get raw data\n",
    "    raw_sent = df_test.iloc[ind, :]['sent_org']\n",
    "    raw_sent_tok = [ okt.pos(elem) for elem in raw_sent ]\n",
    "    processed_raw = [ list(zip(*raw_sent_tok[i]))[0] for i in range(len(raw_sent_tok))]\n",
    "    processed_raw = [ list(i) for i in processed_raw] \n",
    "    x = len(processed_raw)\n",
    "    y = max( [len(i) for i in processed_raw] )\n",
    "    update_att = np.zeros((x, y)).tolist()\n",
    "    \n",
    "    # fill in word attentions\n",
    "    wd_atts = a_it.data.tolist()[0]\n",
    "    diff = y - len(wd_atts[0])\n",
    "    wd_atts = [ i + np.zeros(diff).tolist() for i in wd_atts ]\n",
    "    \n",
    "    # update attention\n",
    "    for s, z in enumerate(zip(orig_doc, processed_raw)):\n",
    "        cnt = 0\n",
    "        for wd, val in enumerate(z[1]): \n",
    "            if val in z[0]:\n",
    "                update_att[s][wd] = wd_atts[s][cnt]  \n",
    "                cnt += 1\n",
    "    \n",
    "    # Vosia;oze\n",
    "    words = processed_raw\n",
    "    sent_score = a_i.tolist()[0]\n",
    "    word_score = update_att# update_att.tolist()[0]\n",
    "    result = \"<h2>Attention Visualization</h2>\"\n",
    "    for sent, word_att, sent_att in zip(words, word_score, sent_score):\n",
    "        result += map_sentence_to_color( sent, word_att, sent_att)\n",
    "\n",
    "    display(HTML(result))\n",
    "\n",
    "    with open(f'test_ind{ind}.html', 'w') as f:\n",
    "        f.write(result)\n",
    "    return result, a_it, a_i, g_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "params_dict['batch_size'] = 4\n",
    "#df_train, df_test = train_test_split(df_in)\n",
    "dl1 = HanDataLoader(HAN_dataset(df_train), params_dict)\n",
    "#han_dat = HAN_dataset(df_in)\n",
    "sample_x_s = iter(dl1).__next__()\n",
    "#x_s = get_x_s(sample_x_s)\n",
    "#docs, doc_lengths, sent_lengths = x_s\n",
    "docs, doc_lengths, sent_lengths = sample_x_s[0], sample_x_s[2], sample_x_s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100\n",
    "word_gru_h_dim = 100\n",
    "word_gru_n_layers = 2\n",
    "sent_gru_h_dim = 100\n",
    "sent_gru_n_layers = 2\n",
    "word_att_dim = 200\n",
    "sent_att_dim = 200\n",
    "dropval = 0.2\n",
    "dropgru_s = 0.2\n",
    "dropgru_w = 0.2\n",
    "\n",
    "sent_gru = nn.GRU( 2 * word_gru_h_dim, sent_gru_h_dim, \n",
    "                                num_layers = sent_gru_n_layers, batch_first = True,\n",
    "                                bidirectional = True, dropout = dropgru_s)\n",
    "sent_layer_norm = nn.LayerNorm( 2 * sent_gru_h_dim, elementwise_affine= True)\n",
    "sent_attention = nn.Linear(2 * sent_gru_h_dim, sent_att_dim)\n",
    "sentence_context_vector = nn.Linear(sent_att_dim, 1, bias = False)\n",
    "\n",
    "        # word\n",
    "word_gru = nn.GRU(embed_dim, word_gru_h_dim, num_layers = word_gru_n_layers, \n",
    "                              batch_first = True, bidirectional = True, dropout = dropgru_w)\n",
    "word_layer_norm = nn.LayerNorm( 2*word_gru_h_dim, elementwise_affine=True)\n",
    "word_attention = nn.Linear( 2 * word_gru_h_dim, word_att_dim)\n",
    "word_context_vector = nn.Linear(word_att_dim, 1, bias = False)\n",
    "#word_context_vector = nn.Linear(word_att_dim, word_att_dim, bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_x_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_s = get_x_s(sample_x_s)\n",
    "#docs, doc_lengths, sent_lengths = x_s\n",
    "docs, doc_lengths, sent_lengths = sample_x_s[0], sample_x_s[2], sample_x_s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Packing\n",
    "## 1-1 reorder\n",
    "doc_lengths, doc_perm_idx = doc_lengths.sort(dim = 0, descending = True)\n",
    "docs = docs[doc_perm_idx]\n",
    "sent_lengths = sent_lengths[doc_perm_idx]\n",
    "\n",
    "## 1-2 packing\n",
    "packed_sents = pack_padded_sequence(docs, lengths=doc_lengths.tolist(), batch_first = True)\n",
    "packed_sent_lengths = pack_padded_sequence( sent_lengths, lengths= doc_lengths.tolist(), \n",
    "                                          batch_first=True)\n",
    "valid_bsz_sent = packed_sents.batch_sizes\n",
    "\n",
    "# 2. Word Attention\n",
    "## 2-1. packing input data\n",
    "sents, sent_lengths = packed_sents.data, packed_sent_lengths.data\n",
    "# reorder\n",
    "sent_lengths, sent_perm_idx = sent_lengths.sort(dim = 0, descending = True)\n",
    "sents = sents[sent_perm_idx]\n",
    "\n",
    "# embedding done already, do dropout\n",
    "#sents = self.Dropout(sents)\n",
    "packed_words = pack_padded_sequence( sents, lengths = sent_lengths.tolist(), batch_first=True)\n",
    "valid_bsz_word = packed_words.batch_sizes\n",
    "\n",
    "##2-2 NN\n",
    "# hidden layer\n",
    "h_it, _ = word_gru( packed_words )\n",
    "h_it_normed = word_layer_norm(h_it.data)\n",
    "h_it_pad, _ = pad_packed_sequence ( h_it, batch_first = True )\n",
    "# attention module\n",
    "u_it = torch.tanh( word_attention( h_it_normed.data ))\n",
    "u_it_cv = word_context_vector( u_it ).squeeze(1)\n",
    "\n",
    "## ATTENTION\n",
    "key = u_it\n",
    "query = u_it_cv \n",
    "cv_weight = word_context_vector.weight\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "N_vec = -beta * abs(cv_weight - u_it)\n",
    "N_vec = N_vec.sum(dim = 1, keepdim = True)\n",
    "\n",
    "N_vec_pad, _ = pad_packed_sequence( PackedSequence(N_vec, valid_bsz_word), batch_first = True)\n",
    "value_mask = (1 * (N_vec_pad != 0))\n",
    "N_mean = torch.sum(N_vec_pad, 1) / sent_lengths.unsqueeze(1)\n",
    "\n",
    "N_meaned = N_vec_pad - value_mask*N_mean.unsqueeze(2)\n",
    "\n",
    "E_vec = alpha * torch.matmul( key, cv_weight.T )\n",
    "E_vec_pad, _ = pad_packed_sequence( PackedSequence(E_vec, valid_bsz_word), batch_first = True)\n",
    "E_mean = torch.sum(E_vec_pad, 1) / sent_lengths.unsqueeze(1)\n",
    "\n",
    "E_meaned = E_vec_pad - value_mask*E_mean.unsqueeze(2)\n",
    "A_it = torch.tanh( E_meaned ) * torch.sigmoid( N_meaned)\n",
    "A_it = A_it.squeeze(2)\n",
    "\n",
    "###########\n",
    "\n",
    "s_i = ( h_it_pad * A_it.unsqueeze(2)).sum(dim = 1)\n",
    "\n",
    "_, sent_unperm_idx = sent_perm_idx.sort(dim = 0, descending = False)\n",
    "s_i = s_i[sent_unperm_idx] \n",
    "a_it = A_it[sent_unperm_idx] \n",
    "\n",
    "sents, word_att_weights = s_i, a_it\n",
    "#sents = self.Dropout(sents)\n",
    "\n",
    "# 3-1 NN\n",
    "# hidden layer\n",
    "h_i, _ = sent_gru(PackedSequence(sents, valid_bsz_sent))\n",
    "h_i_normed = sent_layer_norm( h_i.data )\n",
    "h_i_pad, _ = pad_packed_sequence( h_i, batch_first = True )\n",
    "\n",
    "# context mapping\n",
    "u_i = torch.tanh( sent_attention( h_i_normed.data ))\n",
    "\n",
    "# calculate similarity\n",
    "u_i_cv = sentence_context_vector(u_i).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_i_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = u_i\n",
    "query = sentence_context_vector.weight\n",
    "\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "N_vec = -beta * abs(query - key)\n",
    "N_vec = N_vec.sum(dim = 1, keepdim = True)\n",
    "\n",
    "N_vec_pad, _ = pad_packed_sequence( PackedSequence(N_vec, valid_bsz_sent), batch_first = True)\n",
    "value_mask = (1 * (N_vec_pad != 0))\n",
    "N_mean = torch.sum(N_vec_pad, 1) / doc_lengths.unsqueeze(1)\n",
    "\n",
    "N_meaned = N_vec_pad - value_mask*N_mean.unsqueeze(2)\n",
    "\n",
    "E_vec = alpha * torch.matmul( key, query.T )\n",
    "E_vec_pad, _ = pad_packed_sequence( PackedSequence(E_vec, valid_bsz_sent), batch_first = True)\n",
    "E_mean = torch.sum(E_vec_pad, 1) / doc_lengths.unsqueeze(1)\n",
    "\n",
    "E_meaned = E_vec_pad - value_mask*E_mean.unsqueeze(2)\n",
    "A_i = torch.tanh( E_meaned ) * torch.sigmoid( N_meaned)\n",
    "A_i = A_i.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ( h_i_pad * A_i.unsqueeze(2)).sum(dim = 1)\n",
    "\n",
    "# 3-2 reorder\n",
    "word_att_weights, _ = pad_packed_sequence( PackedSequence( word_att_weights, valid_bsz_sent), \n",
    "                                         batch_first = True)\n",
    "_, doc_unperm_idx = doc_perm_idx.sort(dim = 0, descending = False)\n",
    "\n",
    "# 4. Final Output\n",
    "v = v[doc_unperm_idx] \n",
    "a_it = A_it[ doc_unperm_idx ] \n",
    "a_i = A_i[ doc_unperm_idx ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict['attention'] = 'de_attention'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "han = ReviewHAN(params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl1 = HanDataLoader(HAN_dataset(df_train), params_dict)\n",
    "sample_x_s = iter(dl1).__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, doc_lengths, sent_lengths = sample_x_s[0], sample_x_s[2], sample_x_s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, a_it, a_i = han(docs, doc_lengths, sent_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
